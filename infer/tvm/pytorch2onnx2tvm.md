# Pytorch2ONNX2TVM

âŒšï¸:2020å¹´11æœˆ30æ—¥

ğŸ“šå‚è€ƒ

- [å‚è€ƒ-1](https://oldpan.me/archives/the-first-step-towards-tvm-1) ï½œ [å‚è€ƒ-2](https://oldpan.me/archives/the-first-step-towards-tvm-2)|[å‚è€ƒ-3](http://whitelok.github.io/2019/06/25/tvm-tutorials-lesson-1/) ï½œ [å‚è€ƒ-4](https://xmfbit.github.io/2019/06/29/tvm-helloworld/)
- https://github.com/szad670401/tvm_mobilefacenet
- https://github.com/liueo/TVM-deploy  *****
- https://github.com/markson14/Face-Recognition-Cpp
- https://github.com/whitelok/tvm-lesson *****

---

| æ—¶é—´(4000æ¬¡) | pytorch | TVM(python) | TVM(c++/cpu) | TVM(c++/gpu) | TVM(c++/rasp) |
| ------------ | ------- | ----------- | ------------ | ------------ | ------------- |
| å•ä½s/ms     | 1m23s   | 35s         | 35ms         | TODO         | 2ms(10æ¬¡)     |



## 1. å‰è¨€

è¿™æ˜¯ä¸€ä¸ªTVMæ•™ç¨‹ç³»åˆ—ï¼Œè®²è§£ä»**pytorchæ¨¡å‹** åˆ° **ONNXæ¨¡å‹** åˆ°**TVMéƒ¨ç½²**çš„ä½¿ç”¨è¯´æ˜ã€‚



é‚£å•¥æ˜¯TVMï¼Ÿ

ç®€å•æ¥è¯´ï¼ŒTVMå¯ä»¥ç§°ä¸ºè®¸å¤šå·¥å…·é›†çš„é›†åˆï¼Œå…¶ä¸­è¿™äº›å·¥å…·å¯ä»¥ç»„åˆèµ·æ¥ä½¿ç”¨ï¼Œæ¥å®ç°æˆ‘ä»¬çš„ä¸€äº›ç¥ç»ç½‘ç»œçš„åŠ é€Ÿå’Œéƒ¨ç½²åŠŸèƒ½ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå«åš**TVM Stack**äº†ã€‚TVMçš„ä½¿ç”¨é€”å¾„å¾ˆå¹¿ï¼Œå‡ ä¹å¯ä»¥æ”¯æŒå¸‚é¢ä¸Šå¤§éƒ¨åˆ†çš„ç¥ç»ç½‘ç»œæƒé‡æ¡†æ¶(ONNXã€TFã€Caffe2ç­‰)ï¼Œä¹Ÿå‡ ä¹å¯ä»¥éƒ¨ç½²åœ¨ä»»ä½•çš„å¹³å°ï¼Œä¾‹å¦‚Windowsã€Linuxã€Macã€ARMç­‰ç­‰ã€‚

ä»¥ä¸‹é¢ä¸€å¼ å›¾æ¥å½¢å®¹ä¸€ä¸‹ï¼š

![ã€Šä¸€æ­¥ä¸€æ­¥è§£è¯»ç¥ç»ç½‘ç»œç¼–è¯‘å™¨TVM(ä¸€)â€”â€”ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‹](imgs/stack_tvmlang.png)



ä¹çœ‹è¿™ä¹ˆå¤šæ„Ÿè§‰éå¸¸åœ°å¤æ‚ï¼Œä½†æˆ‘ä»¬åªéœ€è¦çŸ¥é“TVMçš„æ ¸å¿ƒåŠŸèƒ½å°±å¯ä»¥ï¼š**TVMå¯ä»¥ä¼˜åŒ–çš„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¹¶å°†ä½ çš„æ¨¡å‹æ‰“åŒ…å¥½ï¼Œç„¶åä½ å¯ä»¥å°†è¿™ä¸ªä¼˜åŒ–å¥½çš„æ¨¡å‹æ”¾åœ¨ä»»ä½•å¹³å°å»è¿è¡Œ**ï¼Œå¯ä»¥è¯´æ˜¯ä¸è½åœ°åº”ç”¨æ¯æ¯ç›¸å…³ã€‚

TVMåŒ…å«çš„ä¸œè¥¿å’ŒçŸ¥è¯†æ¦‚å¿µéƒ½æœ‰å¾ˆå¤šï¼Œä¸ä»…æœ‰ç¥ç»ç½‘ç»œä¼˜åŒ–é‡åŒ–opèåˆç­‰ä¸€ç³»åˆ—æ­¥éª¤ï¼Œè¿˜æœ‰å…¶ä»–æ›´å¤šç»†èŠ‚æŠ€æœ¯çš„æ”¯æŒ(Halideã€LLVM)ï¼Œä»è€Œä½¿TVMæ‹¥æœ‰å¾ˆå¼ºå¤§çš„åŠŸèƒ½â€¦å¥½äº†åºŸè¯ä¸è¯´äº†ï¼Œå†è¯´å°±æ†‹ä¸å‡ºæ¥äº†ï¼Œå¦‚æœæƒ³å¤šäº†è§£TVMçš„å¯ä»¥åœ¨çŸ¥ä¹ä¸Šç›´æ¥æœç´¢TVMå…³é”®å­—ï¼Œé‚£äº›å¤§ä½¬æœ‰å¾ˆå¤šå…³äºTVMçš„ä»‹ç»æ–‡ç« ï¼Œå¤§å®¶å¯ä»¥å»çœ‹çœ‹ã€‚

å…¶å®åšæ¨¡å‹ä¼˜åŒ–è¿™ä¸€æ­¥éª¤çš„åº“å·²ç»å‡ºç°å¾ˆå¤šäº†ï¼Œä¸è®ºæ˜¯Nvidiaè‡ªå®¶çš„TensorRTè¿˜æ˜¯Pytorchè‡ªå®¶çš„`torch.jit`æ¨¡å—ï¼Œéƒ½åœ¨åšä¸€äº›æ¨¡å‹ä¼˜åŒ–çš„å·¥ä½œï¼Œè¿™é‡Œå°±ä¸å¤šè¯´äº†ï¼Œæ„Ÿå…´è¶£çš„å¯ä»¥çœ‹çœ‹ä»¥ä¸‹æ–‡ç« ï¼š

[åˆ©ç”¨Pytorchçš„C++å‰ç«¯(libtorch)è¯»å–é¢„è®­ç»ƒæƒé‡å¹¶è¿›è¡Œé¢„æµ‹](https://oldpan.me/archives/pytorch-c-libtorch-inference)

[åˆ©ç”¨TensorRTå®ç°ç¥ç»ç½‘ç»œæé€Ÿ(è¯»å–ONNXæ¨¡å‹å¹¶è¿è¡Œ)](https://oldpan.me/archives/tensorrt-code-toturial-1)

[åˆ©ç”¨TensorRTå¯¹æ·±åº¦å­¦ä¹ è¿›è¡ŒåŠ é€Ÿ](https://oldpan.me/archives/use-tensorrt-speed-up-deep-learning-1)

## 2. ç¯å¢ƒå‡†å¤‡

| è½¯ä»¶åŒ…              | ç‰ˆæœ¬          |
| ------------------- | ------------- |
| ç³»ç»Ÿ                | ubuntu 18.04  |
| GPU Driver          | 440.64        |
| CUDA&cuDNN          | 10.2 & 7.6    |
| Python              | 3.6.9         |
| cmake               | 3.14.4        |
| opencv              | 4.4.0         |
| tvm                 | 0.8           |
| pytorch&torchvision | 1.7.0 & 0.8.1 |
| onnx                | 1.7.0         |

```
root@567059b7080d:~/deploy_cpp/build# pip list  
Package                Version
---------------------- ---------------
antlr4-python3-runtime 4.9
argon2-cffi            20.1.0
asn1crypto             0.24.0
async-generator        1.10
attrs                  20.3.0
autocfg                0.0.6
autogluon.core         0.0.16b20201210
autograd               1.3
backcall               0.2.0
bcrypt                 3.2.0
bleach                 3.2.1
boto3                  1.16.34
botocore               1.19.34
certifi                2020.11.8
cffi                   1.14.4
chardet                3.0.4
click                  7.1.2
cloudpickle            1.6.0
ConfigSpace            0.4.16
contextvars            2.4
cryptography           3.3.1
cycler                 0.10.0
Cython                 0.29.21
dask                   2020.12.0
dataclasses            0.8
decorator              4.4.2
decord                 0.4.2
defusedxml             0.6.0
dgl                    0.5.3
dill                   0.3.3
distributed            2020.12.0
entrypoints            0.3
future                 0.18.2
gluoncv                0.9.0
graphviz               0.8.4
HeapDict               1.0.1
idna                   2.6
immutables             0.14
importlib-metadata     3.1.0
iniconfig              1.1.1
ipykernel              5.3.4
ipython                7.16.1
ipython-genutils       0.2.0
jedi                   0.17.2
Jinja2                 2.11.2
jmespath               0.10.0
joblib                 0.17.0
json5                  0.9.5
jsonschema             3.2.0
jupyter-client         6.1.7
jupyter-core           4.7.0
jupyterlab             2.2.9
jupyterlab-pygments    0.1.2
jupyterlab-server      1.2.0
keyring                10.6.0
keyrings.alt           3.0
kiwisolver             1.3.1
MarkupSafe             1.1.1
matplotlib             3.3.3
mistune                0.8.4
mlxtend                0.18.0
msgpack                1.0.0
mxnet                  1.6.0
mypy                   0.790
mypy-extensions        0.4.3
nbclient               0.5.1
nbconvert              6.0.7
nbformat               5.0.8
nest-asyncio           1.4.3
networkx               2.5
notebook               6.1.5
numpy                  1.19.4
onnx                   1.7.0
opencv-python          4.4.0.46
orderedset             2.0.3
packaging              20.4
pandas                 1.1.5
pandocfilters          1.4.3
paramiko               2.7.2
parso                  0.7.1
pexpect                4.8.0
pickleshare            0.7.5
Pillow                 8.0.1
pip                    20.3.1
pluggy                 0.13.1
portalocker            2.0.0
prometheus-client      0.9.0
prompt-toolkit         3.0.8
protobuf               3.14.0
psutil                 5.7.3
ptyprocess             0.6.0
py                     1.9.0
pyaml                  20.4.0
pycparser              2.20
pycrypto               2.6.1
Pygments               2.7.2
pygobject              3.26.1
PyNaCl                 1.4.0
pyparsing              2.4.7
pyrsistent             0.17.3
pytest                 6.1.2
python-apt             1.6.5+ubuntu0.4
python-dateutil        2.8.1
pytz                   2020.4
pyxdg                  0.25
PyYAML                 5.3.1
pyzmq                  20.0.0
requests               2.25.0
s3transfer             0.3.3
scikit-learn           0.23.2
scikit-optimize        0.8.1
scipy                  1.4.1
SecretStorage          2.3.1
Send2Trash             1.5.0
setuptools             39.0.1
six                    1.11.0
sklearn                0.0
sortedcontainers       2.3.0
tblib                  1.7.0
tensorboardX           2.1
terminado              0.9.1
testpath               0.4.4
threadpoolctl          2.1.0
toml                   0.10.2
toolz                  0.11.1
torch                  1.7.0
torchvision            0.8.1
tornado                6.1
tqdm                   4.54.1
traitlets              4.3.3
typed-ast              1.4.1
typing-extensions      3.7.4.3
unattended-upgrades    0.1
urllib3                1.26.2
wcwidth                0.2.5
webencodings           0.5.1
wheel                  0.30.0
xgboost                0.7.post4
yacs                   0.1.8
zict                   2.0.0
zipp                   3.4.0
WARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.
You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.

```



## 3 åˆ©ç”¨Pytorchå¯¼å‡ºOnnxæ¨¡å‹

### 3.1 å¯¼å‡ºæ¨¡å‹

é¦–å…ˆæˆ‘ä»¬è¦åšçš„æ˜¯ï¼Œå¾—åˆ°ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¿™é‡Œæˆ‘é€‰æ‹©è¿™ä¸ª[github](https://github.com/FelixFu520/pytorch2onnx2tvm)ä»“åº“ä¸­çš„**mobilenet-v2**ï¼Œmodelä»£ç å’Œåœ¨ImageNetä¸Šè®­ç»ƒå¥½çš„æƒé‡éƒ½å·²ç»æä¾›ã€‚å¥½ï¼Œæˆ‘ä»¬å°†githubä¸­çš„æ¨¡å‹ä»£ç ç§»æ¤åˆ°æœ¬åœ°ï¼Œç„¶åè°ƒç”¨å¹¶åŠ è½½å·²ç»è®­ç»ƒå¥½çš„æƒé‡ï¼š

```python
import torch
import time
from MobileNetV2 import mobilenet_v2


model = mobilenet_v2(pretrained=True)
example = torch.rand(1, 3, 224, 224)   

with torch.no_grad():
    model.eval()
    since = time.time()
    for i in range(4000):
        model(example)
    time_elapsed = time.time() - since
    print('Time elapsed is {:.0f}m {:.0f}s'.
          format(time_elapsed // 60, time_elapsed % 60))
```

è¿™é‡Œæˆ‘ä»¬åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ï¼Œå¹¶è®¾å®šäº†è¾“å…¥ï¼Œåœ¨pythonç«¯è¿ç»­è¿è¡Œäº†4000æ¬¡ï¼Œè¿™é‡Œæˆ‘ä»¬æ‰€èŠ±çš„æ—¶é—´ä¸ºï¼š1m 24sã€‚

ç„¶åæˆ‘ä»¬å°†Pytorchæ¨¡å‹å¯¼å‡ºä¸ºONNXæ¨¡å‹ï¼š

```python
import torch
from MobileNetV2 import mobilenet_v2


model = mobilenet_v2(pretrained=True)
example = torch.rand(1, 3, 224, 224)   

torch_out = torch.onnx.export(model,
                              example,
                              "mobilenetv2.onnx",
                              verbose=True,
                              export_params=True   # å¸¦å‚æ•°è¾“å‡º
                              )
```

è¿™æ ·æˆ‘ä»¬å°±å¾—åˆ°äº†`mobilenetv2.onnx`è¿™ä¸ªonnxæ ¼å¼çš„æ¨¡å‹æƒé‡ã€‚æ³¨æ„è¿™é‡Œæˆ‘ä»¬è¦å¸¦å‚æ•°è¾“å‡ºï¼Œå› ä¸ºæˆ‘ä»¬ä¹‹åè¦ç›´æ¥è¯»å–ONNXæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚

å¯¼å‡ºæ¥ä¹‹åï¼Œå»ºè®®ä½¿ç”¨[Netron](https://github.com/lutzroeder/netron)æ¥æŸ¥çœ‹æˆ‘ä»¬æ¨¡å‹çš„ç»“æ„ï¼Œå¯ä»¥çœ‹åˆ°è¿™ä¸ªæ¨¡å‹ç”±Pytorchå¯¼å‡ºï¼Œå…±æœ‰152ä¸ªopï¼Œä»¥åŠè¾“å…¥idå’Œè¾“å…¥æ ¼å¼ç­‰ç­‰ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥æ‹–åŠ¨é¼ æ ‡æŸ¥çœ‹åˆ°æ›´è¯¦ç»†çš„ä¿¡æ¯:

![ã€Šä¸€æ­¥ä¸€æ­¥è§£è¯»ç¥ç»ç½‘ç»œç¼–è¯‘å™¨TVM(ä¸€)â€”â€”ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‹](imgs/mobilenetv2-test.png)

å¥½äº†ï¼Œè‡³æ­¤æˆ‘ä»¬çš„**mobilenet-v2**æ¨¡å‹å·²ç»é¡ºåˆ©å¯¼å‡ºäº†ã€‚

### 3.2 åˆ©ç”¨TVMè¯»å–å¹¶é¢„æµ‹ONNXæ¨¡å‹

åœ¨æˆ‘ä»¬æˆåŠŸç¼–è¯‘å¹¶ä¸”å¯ä»¥åœ¨Pythonç«¯æ­£å¸¸å¼•ç”¨TVMåï¼Œæˆ‘ä»¬é¦–å…ˆå¯¼å…¥æˆ‘ä»¬çš„onnxæ ¼å¼çš„æ¨¡å‹ã€‚è¿™é‡Œæˆ‘ä»¬å‡†å¤‡äº†ä¸€å¼ é£æœºçš„å›¾åƒï¼š

![ã€Šä¸€æ­¥ä¸€æ­¥è§£è¯»ç¥ç»ç½‘ç»œç¼–è¯‘å™¨TVM(ä¸€)â€”â€”ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‹](imgs/tvm_plane.png)

è¿™ä¸ªå›¾åƒåœ¨ImageNetåˆ†ç±»ä¸­å±äº`404: 'airliner'`ï¼Œä¹Ÿå°±æ˜¯èˆªç©ºå®¢æœºã€‚

ä¸‹é¢æˆ‘ä»¬å°†åˆ©ç”¨TVMéƒ¨ç½²onnxæ¨¡å‹å¹¶å¯¹è¿™å¼ å›¾åƒè¿›è¡Œé¢„æµ‹ã€‚

```python
import onnx
import time
import tvm
import numpy as np
import tvm.relay as relay
from PIL import Image

onnx_model = onnx.load('mobilenetv2.onnx')  # å¯¼å…¥æ¨¡å‹

mean = [123., 117., 104.]                   # åœ¨ImageNetä¸Šè®­ç»ƒæ•°æ®é›†çš„meanå’Œstd
std = [58.395, 57.12, 57.375]


def transform_image(image):                # å®šä¹‰è½¬åŒ–å‡½æ•°ï¼Œå°†PILæ ¼å¼çš„å›¾åƒè½¬åŒ–ä¸ºæ ¼å¼ç»´åº¦çš„numpyæ ¼å¼æ•°ç»„
    image = image - np.array(mean)
    image /= np.array(std)
    image = np.array(image).transpose((2, 0, 1))
    image = image[np.newaxis, :].astype('float32')
    return image

img = Image.open('./plane.jpg').resize((224, 224)) # è¿™é‡Œæˆ‘ä»¬å°†å›¾åƒresizeä¸ºç‰¹å®šå¤§å°
x = transform_image(img)
```

è¿™æ ·æˆ‘ä»¬å¾—åˆ°çš„`x`ä¸º`[1,3,224,224]`ç»´åº¦çš„`ndarray`ã€‚è¿™ä¸ªç¬¦åˆNCHWæ ¼å¼æ ‡å‡†ï¼Œä¹Ÿæ˜¯æˆ‘ä»¬é€šç”¨çš„å¼ é‡æ ¼å¼ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬è®¾ç½®ç›®æ ‡ç«¯å£`llvm`ï¼Œä¹Ÿå°±æ˜¯éƒ¨ç½²åˆ°CPUç«¯ï¼Œè€Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯TVMä¸­çš„[Relay IR](https://docs.tvm.ai/dev/relay_intro.html)ï¼Œè¿™ä¸ªIRç®€å•æ¥è¯´å°±æ˜¯å¯ä»¥è¯»å–æˆ‘ä»¬çš„æ¨¡å‹å¹¶æŒ‰ç…§æ¨¡å‹çš„é¡ºåºæ­å»ºå‡ºä¸€ä¸ªå¯ä»¥æ‰§è¡Œçš„è®¡ç®—å›¾å‡ºæ¥ï¼Œå½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹è¿™ä¸ªè®¡ç®—å›¾è¿›è¡Œä¸€ç³»åˆ—ä¼˜åŒ–ã€‚(ç°åœ¨TVMä¸»æ¨Relayè€Œä¸æ˜¯NNVMï¼ŒRelayå¯ä»¥ç§°ä¸ºäºŒä»£NNVM)ã€‚

```python
target = 'llvm'

input_name = '0'  # æ³¨æ„è¿™é‡Œä¸ºä¹‹å‰å¯¼å‡ºonnxæ¨¡å‹ä¸­çš„æ¨¡å‹çš„è¾“å…¥idï¼Œè¿™é‡Œä¸º0
shape_dict = {input_name: x.shape}
# åˆ©ç”¨Relayä¸­çš„onnxå‰ç«¯è¯»å–æˆ‘ä»¬å¯¼å‡ºçš„onnxæ¨¡å‹
sym, params = relay.frontend.from_onnx(onnx_model, shape_dict)
```

ä¸Šè¿°ä»£ç ä¸­å¯¼å‡ºçš„`sym`å’Œ`params`æ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥è¦ä½¿ç”¨çš„æ ¸å¿ƒçš„ä¸œè¥¿ï¼Œå…¶ä¸­paramså°±æ˜¯å¯¼å‡ºæ¨¡å‹ä¸­çš„æƒé‡ä¿¡æ¯ï¼Œåœ¨pythonä¸­ç”¨dicè¡¨ç¤ºï¼š



![ã€Šä¸€æ­¥ä¸€æ­¥è§£è¯»ç¥ç»ç½‘ç»œç¼–è¯‘å™¨TVM(ä¸€)â€”â€”ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‹](imgs/12wer.png)

è€Œ`sym`å°±æ˜¯è¡¨ç¤ºè®¡ç®—å›¾ç»“æ„çš„åŠŸèƒ½å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°ä¸­åŒ…å«äº†è®¡ç®—å›¾çš„æµåŠ¨è¿‡ç¨‹ï¼Œä»¥åŠä¸€äº›è®¡ç®—ä¸­éœ€è¦çš„å„ç§å‚æ•°ä¿¡æ¯ï¼ŒRelay IRä¹‹åå¯¹ç½‘ç»œè¿›è¡Œä¼˜åŒ–å°±æ˜¯ä¸»è¦å¯¹è¿™ä¸ª`sym`è¿›è¡Œä¼˜åŒ–çš„è¿‡ç¨‹ï¼š

```c
fn (%v0: Tensor[(1, 3, 224, 224), float32],
    %v1: Tensor[(32, 3, 3, 3), float32],
    %v2: Tensor[(32,), float32],
    %v3: Tensor[(32,), float32],
    %v4: Tensor[(32,), float32],
    %v5: Tensor[(32,), float32],
    ...
    %v307: Tensor[(1280, 320, 1, 1), float32],
    %v308: Tensor[(1280,), float32],
    %v309: Tensor[(1280,), float32],
    %v310: Tensor[(1280,), float32],
    %v311: Tensor[(1280,), float32],
    %v313: Tensor[(1000, 1280), float32],
    %v314: Tensor[(1000,), float32]) {
  %0 = nn.conv2d(%v0, %v1, strides=[2, 2], padding=[1, 1], kernel_size=[3, 3])
  %1 = nn.batch_norm(%0, %v2, %v3, %v4, %v5, epsilon=1e-05)
  %2 = %1.0
  %3 = clip(%2, a_min=0, a_max=6)
  %4 = nn.conv2d(%3, %v7, padding=[1, 1], groups=32, kernel_size=[3, 3])
  ...
  %200 = clip(%199, a_min=0, a_max=6)
  %201 = mean(%200, axis=[3])
  %202 = mean(%201, axis=[2])
  %203 = nn.batch_flatten(%202)
  %204 = multiply(1f, %203)
  %205 = nn.dense(%204, %v313, units=1000)
  %206 = multiply(1f, %v314)
  %207 = nn.bias_add(%205, %206)
  %207
}
```

å¥½äº†ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦å¯¹è¿™ä¸ªè®¡ç®—å›¾æ¨¡å‹è¿›è¡Œä¼˜åŒ–ï¼Œè¿™é‡Œæˆ‘ä»¬é€‰æ‹©ä¼˜åŒ–çš„ç­‰çº§ä¸º3ï¼š

```python
with relay.build_config(opt_level=3):
    intrp = relay.build_module.create_executor('graph', sym, tvm.cpu(0), target)

dtype = 'float32'
func = intrp.evaluate(sym)
```

æœ€åæˆ‘ä»¬å¾—åˆ°å¯ä»¥ç›´æ¥è¿è¡Œçš„`func`ã€‚

å…¶ä¸­ä¼˜åŒ–çš„ç­‰çº§åˆ†è¿™å‡ ç§ï¼š

```python
OPT_PASS_LEVEL = {
    "SimplifyInference": 0,
    "OpFusion": 1,
    "FoldConstant": 2,
    "CombineParallelConv2D": 3,
    "FoldScaleAxis": 3,
    "AlterOpLayout": 3,
    "CanonicalizeOps": 3,
}
```

æœ€åï¼Œæˆ‘ä»¬å°†ä¹‹å‰å·²ç»è½¬åŒ–æ ¼å¼åçš„å›¾åƒ`x`æ•°ç»„å’Œæ¨¡å‹çš„å‚æ•°è¾“å…¥åˆ°è¿™ä¸ª`func`ä¸­ï¼Œå¹¶ä¸”è¿”å›è¿™ä¸ªè¾“å‡ºæ•°ç»„ä¸­çš„æœ€å¤§å€¼

```python
output = func(tvm.nd.array(x.astype(dtype)), **params).asnumpy()
print(output.argmax())
```

è¿™é‡Œæˆ‘ä»¬å¾—åˆ°çš„è¾“å‡ºä¸º`404`ï¼Œä¸å‰æ–‡æè¿°å›¾åƒåœ¨ImageNetä¸­çš„åˆ†ç±»æ ‡è®°ä¸€è‡´ï¼Œè¯´æ˜æˆ‘ä»¬çš„TVMæ­£ç¡®è¯»å–onnxæ¨¡å‹å¹¶å°†å…¶åº”ç”¨äºé¢„æµ‹é˜¶æ®µã€‚

æˆ‘ä»¬å¦å¤–å•ç‹¬æµ‹è¯•ä¸€ä¸‹æ¨¡å‹ä¼˜åŒ–åè¿è¡Œçš„é€Ÿåº¦å’Œä¹‹å‰ç›´æ¥åˆ©ç”¨pytorchè¿è¡Œé€Ÿåº¦ä¹‹é—´æ¯”è¾ƒä¸€ä¸‹ï¼Œå¯ä»¥å‘ç°æœ€åçš„è¿è¡Œæ—¶é—´ä¸ºï¼š3m20sï¼Œç›¸è¾ƒä¹‹å‰çš„6m2så¿«äº†å°†è¿‘ä¸€å€ã€‚

```python
since = time.time()
for i in range(10000):
    output = func(tvm.nd.array(x.astype(dtype)), **params).asnumpy()
time_elapsed = time.time() - since
print('Time elapsed is {:.0f}m {:.0f}s'.
      format(time_elapsed // 60, time_elapsed % 60))  # æ‰“å°å‡ºæ¥æ—¶é—´
```

å½“ç„¶ï¼Œè¿™ä¸ªæ¯”è¾ƒå¹¶ä¸æ˜¯å¾ˆè§„èŒƒï¼Œä¸è¿‡æˆ‘ä»¬å¯ä»¥å¤§æ¦‚åˆ†æå‡ºTVMçš„ä¸€äº›å¯ç”¨ä¹‹å¤„äº†ã€‚

æ•´ä½“æ—¥å¿—

```
root@0e8554287189:~/pytorch2onnx2tvm# python pytorch2onnx2tvm.py 
Time elapsed is 3m 28s
graph(%input.1 : Float(1:150528, 3:50176, 224:224, 224:1, requires_grad=0, device=cpu),
      %classifier.weight : Float(1000:1280, 1280:1, requires_grad=1, device=cpu),
      %classifier.bias : Float(1000:1, requires_grad=1, device=cpu),
      %468 : Float(32:27, 3:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %469 : Float(32:1, requires_grad=0, device=cpu),
      %471 : Float(32:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %472 : Float(32:1, requires_grad=0, device=cpu),
      %474 : Float(16:32, 32:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %475 : Float(16:1, requires_grad=0, device=cpu),
      %477 : Float(96:16, 16:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %478 : Float(96:1, requires_grad=0, device=cpu),
      %480 : Float(96:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %481 : Float(96:1, requires_grad=0, device=cpu),
      %483 : Float(24:96, 96:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %484 : Float(24:1, requires_grad=0, device=cpu),
      %486 : Float(144:24, 24:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %487 : Float(144:1, requires_grad=0, device=cpu),
      %489 : Float(144:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %490 : Float(144:1, requires_grad=0, device=cpu),
      %492 : Float(24:144, 144:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %493 : Float(24:1, requires_grad=0, device=cpu),
      %495 : Float(144:24, 24:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %496 : Float(144:1, requires_grad=0, device=cpu),
      %498 : Float(144:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %499 : Float(144:1, requires_grad=0, device=cpu),
      %501 : Float(32:144, 144:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %502 : Float(32:1, requires_grad=0, device=cpu),
      %504 : Float(192:32, 32:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %505 : Float(192:1, requires_grad=0, device=cpu),
      %507 : Float(192:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %508 : Float(192:1, requires_grad=0, device=cpu),
      %510 : Float(32:192, 192:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %511 : Float(32:1, requires_grad=0, device=cpu),
      %513 : Float(192:32, 32:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %514 : Float(192:1, requires_grad=0, device=cpu),
      %516 : Float(192:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %517 : Float(192:1, requires_grad=0, device=cpu),
      %519 : Float(32:192, 192:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %520 : Float(32:1, requires_grad=0, device=cpu),
      %522 : Float(192:32, 32:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %523 : Float(192:1, requires_grad=0, device=cpu),
      %525 : Float(192:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %526 : Float(192:1, requires_grad=0, device=cpu),
      %528 : Float(64:192, 192:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %529 : Float(64:1, requires_grad=0, device=cpu),
      %531 : Float(384:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %532 : Float(384:1, requires_grad=0, device=cpu),
      %534 : Float(384:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %535 : Float(384:1, requires_grad=0, device=cpu),
      %537 : Float(64:384, 384:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %538 : Float(64:1, requires_grad=0, device=cpu),
      %540 : Float(384:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %541 : Float(384:1, requires_grad=0, device=cpu),
      %543 : Float(384:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %544 : Float(384:1, requires_grad=0, device=cpu),
      %546 : Float(64:384, 384:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %547 : Float(64:1, requires_grad=0, device=cpu),
      %549 : Float(384:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %550 : Float(384:1, requires_grad=0, device=cpu),
      %552 : Float(384:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %553 : Float(384:1, requires_grad=0, device=cpu),
      %555 : Float(64:384, 384:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %556 : Float(64:1, requires_grad=0, device=cpu),
      %558 : Float(384:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %559 : Float(384:1, requires_grad=0, device=cpu),
      %561 : Float(384:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %562 : Float(384:1, requires_grad=0, device=cpu),
      %564 : Float(96:384, 384:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %565 : Float(96:1, requires_grad=0, device=cpu),
      %567 : Float(576:96, 96:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %568 : Float(576:1, requires_grad=0, device=cpu),
      %570 : Float(576:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %571 : Float(576:1, requires_grad=0, device=cpu),
      %573 : Float(96:576, 576:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %574 : Float(96:1, requires_grad=0, device=cpu),
      %576 : Float(576:96, 96:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %577 : Float(576:1, requires_grad=0, device=cpu),
      %579 : Float(576:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %580 : Float(576:1, requires_grad=0, device=cpu),
      %582 : Float(96:576, 576:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %583 : Float(96:1, requires_grad=0, device=cpu),
      %585 : Float(576:96, 96:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %586 : Float(576:1, requires_grad=0, device=cpu),
      %588 : Float(576:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %589 : Float(576:1, requires_grad=0, device=cpu),
      %591 : Float(160:576, 576:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %592 : Float(160:1, requires_grad=0, device=cpu),
      %594 : Float(960:160, 160:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %595 : Float(960:1, requires_grad=0, device=cpu),
      %597 : Float(960:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %598 : Float(960:1, requires_grad=0, device=cpu),
      %600 : Float(160:960, 960:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %601 : Float(160:1, requires_grad=0, device=cpu),
      %603 : Float(960:160, 160:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %604 : Float(960:1, requires_grad=0, device=cpu),
      %606 : Float(960:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %607 : Float(960:1, requires_grad=0, device=cpu),
      %609 : Float(160:960, 960:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %610 : Float(160:1, requires_grad=0, device=cpu),
      %612 : Float(960:160, 160:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %613 : Float(960:1, requires_grad=0, device=cpu),
      %615 : Float(960:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),
      %616 : Float(960:1, requires_grad=0, device=cpu),
      %618 : Float(320:960, 960:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %619 : Float(320:1, requires_grad=0, device=cpu),
      %621 : Float(1280:320, 320:1, 1:1, 1:1, requires_grad=0, device=cpu),
      %622 : Float(1280:1, requires_grad=0, device=cpu)):
  %467 : Float(1:401408, 32:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%input.1, %468, %469)
  %317 : Float(1:401408, 32:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%467) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %470 : Float(1:401408, 32:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%317, %471, %472)
  %320 : Float(1:401408, 32:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%470) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %473 : Float(1:200704, 16:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%320, %474, %475)
  %476 : Float(1:1204224, 96:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%473, %477, %478)
  %325 : Float(1:1204224, 96:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%476) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %479 : Float(1:301056, 96:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%325, %480, %481)
  %328 : Float(1:301056, 96:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%479) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %482 : Float(1:75264, 24:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%328, %483, %484)
  %485 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%482, %486, %487)
  %333 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%485) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %488 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%333, %489, %490)
  %336 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%488) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %491 : Float(1:75264, 24:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%336, %492, %493)
  %339 : Float(1:75264, 24:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Add(%482, %491) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %494 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%339, %495, %496)
  %342 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%494) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %497 : Float(1:112896, 144:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%342, %498, %499)
  %345 : Float(1:112896, 144:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%497) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %500 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%345, %501, %502)
  %503 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%500, %504, %505)
  %350 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%503) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %506 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%350, %507, %508)
  %353 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%506) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %509 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%353, %510, %511)
  %356 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Add(%500, %509) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %512 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%356, %513, %514)
  %359 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%512) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %515 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%359, %516, %517)
  %362 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%515) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %518 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%362, %519, %520)
  %365 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Add(%356, %518) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %521 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%365, %522, %523)
  %368 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%521) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %524 : Float(1:37632, 192:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%368, %525, %526)
  %371 : Float(1:37632, 192:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%524) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %527 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%371, %528, %529)
  %530 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%527, %531, %532)
  %376 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%530) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %533 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%376, %534, %535)
  %379 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%533) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %536 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%379, %537, %538)
  %382 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%527, %536) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %539 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%382, %540, %541)
  %385 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%539) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %542 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%385, %543, %544)
  %388 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%542) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %545 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%388, %546, %547)
  %391 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%382, %545) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %548 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%391, %549, %550)
  %394 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%548) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %551 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%394, %552, %553)
  %397 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%551) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %554 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%397, %555, %556)
  %400 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%391, %554) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %557 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%400, %558, %559)
  %403 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%557) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %560 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%403, %561, %562)
  %406 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%560) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %563 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%406, %564, %565)
  %566 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%563, %567, %568)
  %411 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%566) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %569 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%411, %570, %571)
  %414 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%569) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %572 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%414, %573, %574)
  %417 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%563, %572) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %575 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%417, %576, %577)
  %420 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%575) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %578 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%420, %579, %580)
  %423 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%578) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %581 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%423, %582, %583)
  %426 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%417, %581) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %584 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%426, %585, %586)
  %429 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%584) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %587 : Float(1:28224, 576:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%429, %588, %589)
  %432 : Float(1:28224, 576:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%587) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %590 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%432, %591, %592)
  %593 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%590, %594, %595)
  %437 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%593) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %596 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%437, %597, %598)
  %440 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%596) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %599 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%440, %600, %601)
  %443 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Add(%590, %599) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %602 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%443, %603, %604)
  %446 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%602) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %605 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%446, %606, %607)
  %449 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%605) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %608 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%449, %609, %610)
  %452 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Add(%443, %608) # /root/pytorch2onnx2tvm/MobileNetV2.py:62:0
  %611 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%452, %612, %613)
  %455 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%611) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %614 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%455, %615, %616)
  %458 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%614) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %617 : Float(1:15680, 320:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%458, %618, %619)
  %620 : Float(1:62720, 1280:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%617, %621, %622)
  %463 : Float(1:62720, 1280:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%620) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0
  %464 : Float(1:8960, 1280:7, 7:1, requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[3], keepdims=0](%463) # /root/pytorch2onnx2tvm/MobileNetV2.py:110:0
  %465 : Float(1:1280, 1280:1, requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2], keepdims=0](%464) # /root/pytorch2onnx2tvm/MobileNetV2.py:110:0
  %466 : Float(1:1000, 1000:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%465, %classifier.weight, %classifier.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1690:0
  return (%466)

Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('dense_nopack.x86', ('TENSOR', (1, 1280), 'float32'), ('TENSOR', (1000, 1280), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 320, 7, 7), 'float32'), ('TENSOR', (1280, 320, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (320, 960, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (960, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 160, 7, 7), 'float32'), ('TENSOR', (960, 160, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (160, 960, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 576, 7, 7), 'float32'), ('TENSOR', (160, 576, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (576, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 96, 14, 14), 'float32'), ('TENSOR', (576, 96, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (96, 576, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (96, 384, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (384, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 64, 14, 14), 'float32'), ('TENSOR', (384, 64, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (64, 384, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 192, 14, 14), 'float32'), ('TENSOR', (64, 192, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (192, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 32, 28, 28), 'float32'), ('TENSOR', (192, 32, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (32, 192, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 144, 28, 28), 'float32'), ('TENSOR', (32, 144, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (144, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 24, 56, 56), 'float32'), ('TENSOR', (144, 24, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (24, 144, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 96, 56, 56), 'float32'), ('TENSOR', (24, 96, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 96, 112, 112), 'float32'), ('TENSOR', (96, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 16, 112, 112), 'float32'), ('TENSOR', (96, 16, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 32, 112, 112), 'float32'), ('TENSOR', (16, 32, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 32, 112, 112), 'float32'), ('TENSOR', (32, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 3, 224, 224), 'float32'), ('TENSOR', (32, 3, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (144, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (192, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (576, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.
404
Time elapsed is 3m 1s
```



### 3.3 åè®°

è¿™ä¸€ç¯‡ä»…ä»…æ˜¯å¸¦å¤§å®¶äº†è§£ä¸€ä¸‹ä»€ä¹ˆæ˜¯TVMä»¥åŠä¸€ä¸ªç®€å•ä¾‹å­çš„ä½¿ç”¨ï¼Œåœ¨æ¥ä¸‹æ¥çš„æ–‡ç« ä¸­ä¼šæ¶‰åŠåˆ°éƒ¨åˆ†TVMè®¾è®¡ç»“æ„å’Œæºç çš„è§£æã€‚å¯èƒ½æ¶‰åŠåˆ°çš„çŸ¥è¯†ç‚¹æœ‰ï¼š

- ç®€å•ç¼–è¯‘å™¨åŸç†
- C++ç‰¹æ®Šè¯­æ³•ä»¥åŠæ¨¡æ¿å…ƒç¼–ç¨‹
- ç¥ç»ç½‘ç»œæ¨¡å‹ä¼˜åŒ–è¿‡ç¨‹
- ä»£ç éƒ¨ç½²

ç­‰ç­‰ï¼Œéšæ—¶å¯èƒ½ä¼šè¿›è¡Œå˜åŒ–ã€‚

äººå·¥æ™ºèƒ½å·²ç»å¼€å§‹è¿›å…¥åµŒå…¥å¼æ—¶ä»£ï¼Œå„å¼å„æ ·çš„AIèŠ¯ç‰‡å³å°†åˆå§‹ï¼Œå°†å¤æ‚çš„ç½‘ç»œæ¨¡å‹è¿è¡Œåœ¨å»‰ä»·ä½åŠŸè€—çš„æ¿å­ä¸Šå¯èƒ½ä¹Ÿä¸å†æ˜¯é¥ä¸å¯åŠçš„å¹»æƒ³ï¼Œä¸çŸ¥é“æœªæ¥ä¼šæ˜¯æ€ä¹ˆæ ·ï¼Œä½†TVMè¿™ä¸ªæ¡†æ¶å·²ç»å¼€å§‹èµ°äº†ä¸€å°æ­¥ã€‚



## 4. å¯¼å‡ºåŠ¨æ€é“¾æ¥åº“ï¼ˆPCï¼‰

ä¸Šé¢è¿™ä¸ªæ­¥éª¤åªæ˜¯å°†.onnxæ¨¡å‹åˆ©ç”¨TVMè¯»å–å¹¶ä¸”é¢„æµ‹å‡ºæ¥ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦éƒ¨ç½²çš„è¯æˆ‘ä»¬å°±éœ€è¦å¯¼å‡ºæ•´ä¸ªæ¨¡å‹çš„åŠ¨æ€é“¾æ¥åº“ï¼Œè‡³äºä¸ºä»€ä¹ˆæ˜¯åŠ¨æ€é“¾æ¥åº“ï¼Œå…¶å®TVMæ˜¯æœ‰å¤šç§çš„å¯¼å‡ºæ¨¡å¼çš„(ä¹Ÿå¯ä»¥å¯¼å‡ºé™æ€åº“)ï¼Œä½†æ˜¯è¿™é‡Œä¸ç»†è¯´äº†ï¼š

![ã€Šä¸€æ­¥ä¸€æ­¥è§£è¯»ç¥ç»ç½‘ç»œç¼–è¯‘å™¨TVM(/Users/fusimeng/README/notes/tvm/imgs/20190326205031.png)â€”â€”åˆ©ç”¨TVMå®ŒæˆC++ç«¯çš„éƒ¨ç½²ã€‹](imgs/20190326205031.png)

æ€»ä¹‹æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯å¯¼å‡º**soåŠ¨æ€é“¾æ¥åº“**ï¼Œè¿™ä¸ªé“¾æ¥åº“ä¸­åŒ…æ‹¬äº†æˆ‘ä»¬ç¥ç»ç½‘ç»œæ‰€éœ€è¦çš„ä¸€åˆ‡æ¨æ–­åŠŸèƒ½ã€‚

è¯·çœ‹ä»¥ä¸‹çš„ä»£ç ï¼š

```python
import onnx
import time
import tvm
import numpy as np
import tvm.relay as relay
from PIL import Image

#å¼€å§‹åŒæ ·æ˜¯è¯»å–.onnxæ¨¡å‹
onnx_model = onnx.load('./mobilenetv2.onnx')  # å¯¼å…¥æ¨¡å‹

# ä»¥ä¸‹çš„å›¾ç‰‡è¯»å–ä»…ä»…æ˜¯ä¸ºäº†æµ‹è¯•
mean = [123., 117., 104.]                   # åœ¨ImageNetä¸Šè®­ç»ƒæ•°æ®é›†çš„meanå’Œstd
std = [58.395, 57.12, 57.375]

def transform_image(image):                # å®šä¹‰è½¬åŒ–å‡½æ•°ï¼Œå°†PILæ ¼å¼çš„å›¾åƒè½¬åŒ–ä¸ºæ ¼å¼ç»´åº¦çš„numpyæ ¼å¼æ•°ç»„
    image = image - np.array(mean)
    image /= np.array(std)
    image = np.array(image).transpose((2, 0, 1))
    image = image[np.newaxis, :].astype('float32')
    return image

img = Image.open('./plane.png').resize((224, 224)) # è¿™é‡Œæˆ‘ä»¬å°†å›¾åƒresizeä¸ºç‰¹å®šå¤§å°
x = transform_image(img)


# è¿™é‡Œé¦–å…ˆåœ¨PCçš„CPUä¸Šè¿›è¡Œæµ‹è¯• æ‰€ä»¥ä½¿ç”¨LLVMè¿›è¡Œå¯¼å‡º
target = tvm.target.create('llvm') # x86
# target = tvm.target.arm_cpu("rasp3b") # raspi
# target = 'llvm'


input_name = "input.1"  # æ³¨æ„è¿™é‡Œä¸ºä¹‹å‰å¯¼å‡ºonnxæ¨¡å‹ä¸­çš„æ¨¡å‹çš„è¾“å…¥idï¼Œè¿™é‡Œä¸º0
shape_dict = {input_name: x.shape}
# åˆ©ç”¨Relayä¸­çš„onnxå‰ç«¯è¯»å–æˆ‘ä»¬å¯¼å‡ºçš„onnxæ¨¡å‹
sym, params = relay.frontend.from_onnx(onnx_model, shape_dict)

# è¿™é‡Œåˆ©ç”¨TVMæ„å»ºå‡ºä¼˜åŒ–åæ¨¡å‹çš„ä¿¡æ¯
with relay.build_config(opt_level=2):
    graph, lib, params = relay.build_module.build(sym, target, params=params)
    

    
dtype = 'float32'
from tvm.contrib import graph_runtime

# ä¸‹é¢çš„å‡½æ•°å¯¼å‡ºæˆ‘ä»¬éœ€è¦çš„åŠ¨æ€é“¾æ¥åº“ åœ°å€å¯ä»¥è‡ªå·±å®šä¹‰
print("Output model files")
libpath = "./mobilenet.so"
lib.export_library(libpath)

# ä¸‹é¢çš„å‡½æ•°å¯¼å‡ºæˆ‘ä»¬ç¥ç»ç½‘ç»œçš„ç»“æ„ï¼Œä½¿ç”¨jsonæ–‡ä»¶ä¿å­˜
graph_json_path = "./mobilenet.json"
with open(graph_json_path, 'w') as fo:
    fo.write(graph)

# ä¸‹é¢çš„å‡½æ•°ä¸­æˆ‘ä»¬å¯¼å‡ºç¥ç»ç½‘ç»œæ¨¡å‹çš„æƒé‡å‚æ•°
param_path = "./mobilenet.params"
with open(param_path, 'wb') as fo:
    fo.write(relay.save_param_dict(params))
# -------------è‡³æ­¤å¯¼å‡ºæ¨¡å‹é˜¶æ®µå·²ç»ç»“æŸ--------



# æ¥ä¸‹æ¥æˆ‘ä»¬åŠ è½½å¯¼å‡ºçš„æ¨¡å‹å»æµ‹è¯•å¯¼å‡ºçš„æ¨¡å‹æ˜¯å¦å¯ä»¥æ­£å¸¸å·¥ä½œ
loaded_json = open(graph_json_path).read()
loaded_lib = tvm.runtime.load_module(libpath)
loaded_params = bytearray(open(param_path, "rb").read())

# è¿™é‡Œæ‰§è¡Œçš„å¹³å°ä¸ºCPU
ctx = tvm.cpu()

module = graph_runtime.create(loaded_json, loaded_lib, ctx)
module.load_params(loaded_params)
module.set_input("input.1", x)
module.run()
out_deploy = module.get_output(0).asnumpy()
print(type(out_deploy))
print(out_deploy.argmax())
# print(out_deploy)
```

ä¸Šè¿°çš„ä»£ç è¾“å‡º404ï¼Œå› ä¸ºè¾“å…¥çš„å›¾åƒæ˜¯`plane.jpg`,æ‰€ä»¥è¾“å‡ºçš„ä¸‰ä¸ªæ•°å­—ç¬¬ä¸€ä¸ªæ•°å­—æœ€å¤§ï¼Œæ²¡æœ‰æ¯›ç—…ã€‚

æ‰§è¡Œå®Œä»£ç ä¹‹åæˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°éœ€è¦çš„ä¸‰ä¸ªæ–‡ä»¶

- [mobilenet.so](http://mobilenet.so/)
- mobilenet.json
- mobilenet.params

å¾—åˆ°ä¸‰ä¸ªæ–‡ä»¶ä¹‹åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬åˆ©ç”¨TVMçš„C++ç«¯è¯»å–å¹¶è¿è¡Œèµ·æ¥ã€‚

## 5.å¯¼å‡ºåŠ¨æ€é“¾æ¥åº“ï¼ˆRaspï¼‰

åœ¨æ ‘è“æ´¾ä¸Šçš„éƒ¨ç½²å…¶å®ä¹Ÿæ˜¯å¾ˆç®€å•çš„ï¼Œä¸ä¸Šè¿°æ­¥éª¤ä¸­ä¸åŒçš„åœ°æ–¹æ˜¯æˆ‘ä»¬éœ€è¦è®¾ç½®`target`ä¸ºæ ‘è“æ´¾ä¸“ç”¨:

```python
target = tvm.target.arm_cpu('rasp3b')
```

æˆ‘ä»¬ç‚¹è¿›å»å…¶å®å¯ä»¥å‘ç°`rasp3b`å¯¹åº”ç€`-target=armv7l-linux-gnueabihf`ï¼š

```python
trans_table = {
    "pixel2":    ["-model=snapdragon835", "-target=arm64-linux-android -mattr=+neon"],
    "mate10":    ["-model=kirin970", "-target=arm64-linux-android -mattr=+neon"],
    "mate10pro": ["-model=kirin970", "-target=arm64-linux-android -mattr=+neon"],
    "p20":       ["-model=kirin970", "-target=arm64-linux-android -mattr=+neon"],
    "p20pro":    ["-model=kirin970", "-target=arm64-linux-android -mattr=+neon"],
    "rasp3b":    ["-model=bcm2837", "-target=armv7l-linux-gnueabihf -mattr=+neon"],
    "rk3399":    ["-model=rk3399", "-target=aarch64-linux-gnu -mattr=+neon"],
    "pynq":      ["-model=pynq", "-target=armv7a-linux-eabi -mattr=+neon"],
    "ultra96":   ["-model=ultra96", "-target=aarch64-linux-gnu -mattr=+neon"],
}
```

> ##### Cross Compiler
>
> äº¤å‰ç¼–è¯‘å™¨æ˜¯ä»€ä¹ˆï¼Œå°±æ˜¯æˆ‘å¯ä»¥åœ¨PCå¹³å°ä¸Šç¼–è¯‘ç”Ÿæˆå¯ä»¥ç›´æ¥åœ¨æ ‘è“æ´¾ä¸Šè¿è¡Œçš„å¯æ‰§è¡Œæ–‡ä»¶ã€‚è€Œåœ¨TVMä¸­ï¼Œæˆ‘ä»¬éœ€è¦åˆ©ç”¨äº¤å‰ç¼–è¯‘å™¨åœ¨PCç«¯ç¼–è¯‘æ¨¡å‹å¹¶ä¸”ä¼˜åŒ–ï¼Œç„¶åç”Ÿæˆé€‚ç”¨äºæ ‘è“æ´¾(armæ„æ¶)ä½¿ç”¨çš„åŠ¨æ€é“¾æ¥åº“ã€‚
>
> æœ‰è¿™ä¸ªåŠ¨æ€é“¾æ¥åº“ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç›´æ¥è°ƒç”¨æ ‘è“æ´¾ç«¯çš„TVMè¿è¡Œæ—¶ç¯å¢ƒå»è°ƒç”¨è¿™ä¸ªåŠ¨æ€é“¾æ¥åº“ï¼Œä»è€Œæ‰§è¡Œç¥ç»ç½‘ç»œçš„å‰å‘æ“ä½œäº†ã€‚
>
> é‚£ä¹ˆæ€ä¹ˆå®‰è£…å‘¢ï¼Ÿè¿™é‡Œæˆ‘ä»¬éœ€è¦å®‰è£…å«åš`/usr/bin/arm-linux-gnueabihf-g++`çš„äº¤å‰ç¼–è¯‘å™¨ï¼Œåœ¨Ubuntuç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬ç›´æ¥`sudo apt-get install g++-arm-linux-gnueabihf`å³å¯ï¼Œæ³¨æ„åç§°ä¸èƒ½é”™ï¼Œæˆ‘ä»¬éœ€è¦çš„æ˜¯hf(Hard-float)ç‰ˆæœ¬ã€‚
>
> å®‰è£…å®Œåï¼Œæ‰§è¡Œ`/usr/bin/arm-linux-gnueabihf-g++ -v`å‘½ä»¤å°±å¯ä»¥çœ‹åˆ°è¾“å‡ºä¿¡æ¯:
>
> ```powershell
> prototype@prototype-X299-UD4-Pro:~/$ /usr/bin/arm-linux-gnueabihf-g++ -v
> Using built-in specs.
> COLLECT_GCC=/usr/bin/arm-linux-gnueabihf-g++
> COLLECT_LTO_WRAPPER=/usr/lib/gcc-cross/arm-linux-gnueabihf/5/lto-wrapper
> Target: arm-linux-gnueabihf
> Configured with: ../src/configure -v --with-pkgversion='Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.9' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-libitm --disable-libquadmath --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-armhf-cross/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-armhf-cross --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-armhf-cross --with-arch-directory=arm --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libgcj --enable-objc-gc --enable-multiarch --enable-multilib --disable-sjlj-exceptions --with-arch=armv7-a --with-fpu=vfpv3-d16 --with-float=hard --with-mode=thumb --disable-werror --enable-multilib --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=arm-linux-gnueabihf --program-prefix=arm-linux-gnueabihf- --includedir=/usr/arm-linux-gnueabihf/include
> Thread model: posix
> gcc version 5.4.0 20160609 (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.9) 
> ```

è¿˜æœ‰ä¸€ç‚¹æ”¹åŠ¨çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨å¯¼å‡º.soçš„æ—¶å€™éœ€è¦åŠ å…¥`cc="/usr/bin/arm-linux-gnueabihf-g++"`ï¼Œæ­¤æ—¶çš„`/usr/bin/arm-linux-gnueabihf-g++`ä¸ºä¹‹å‰ä¸‹è½½çš„äº¤å‰ç¼–è¯‘å™¨ã€‚

```python
path_lib = '../tvm/deploy_lib.so'
lib.export_library(path_lib, cc="/usr/bin/arm-linux-gnueabihf-g++")
```

è¿™æ—¶æˆ‘ä»¬å°±å¯ä»¥å¯¼å‡ºæ¥æ ‘è“æ´¾éœ€è¦çš„å‡ ä¸ªæ–‡ä»¶ï¼Œä¹‹åæˆ‘ä»¬å°†è¿™å‡ ä¸ªæ–‡ä»¶ç§»åˆ°æ ‘è“æ´¾ä¸­ï¼Œéšååˆ©ç”¨ä¸Šé¢è¯´åˆ°çš„C++éƒ¨ç½²ä»£ç å»éƒ¨ç½²å°±å¯ä»¥äº†ã€‚



## 6. åœ¨PCç«¯åˆ©ç”¨TVMéƒ¨ç½²C++æ¨¡å‹

å¦‚ä½•åˆ©ç”¨TVMçš„C++ç«¯å»éƒ¨ç½²ï¼Œå®˜æ–¹ä¹Ÿæœ‰æ¯”è¾ƒè¯¦ç»†çš„[æ–‡æ¡£](https://docs.tvm.ai/deploy/nnvm.html)ï¼Œè¿™é‡Œæˆ‘ä»¬åˆ©ç”¨TVMå’ŒOpenCVè¯»å–ä¸€å¼ å›¾ç‰‡ï¼Œå¹¶ä¸”ä½¿ç”¨ä¹‹å‰å¯¼å‡ºçš„åŠ¨æ€é“¾æ¥åº“å»è¿è¡Œç¥ç»ç½‘ç»œå¯¹è¿™å¼ å›¾ç‰‡è¿›è¡Œæ¨æ–­ã€‚

æˆ‘ä»¬éœ€è¦çš„å¤´æ–‡ä»¶ä¸ºï¼š

```cpp
#include <cstdio>
#include <dlpack/dlpack.h>
#include <opencv4/opencv2/opencv.hpp>
#include <tvm/runtime/module.h>
#include <tvm/runtime/registry.h>
#include <tvm/runtime/packed_func.h>
#include <fstream>
```

å…¶å®è¿™é‡Œæˆ‘ä»¬åªéœ€è¦TVMçš„è¿è¡Œæ—¶ï¼Œå¦å¤–dlpackæ˜¯å­˜æ”¾å¼ é‡çš„ä¸€ä¸ªç»“æ„ã€‚å…¶ä¸­OpenCVç”¨äºè¯»å–å›¾ç‰‡ï¼Œè€Œ`fstream`åˆ™ç”¨äºè¯»å–jsonå’Œå‚æ•°ä¿¡æ¯ï¼š

```cpp
tvm::runtime::Module mod_dylib =
    tvm::runtime::Module::LoadFromFile("../files/mobilenet.so");

std::ifstream json_in("../files/mobilenet.json", std::ios::in);
std::string json_data((std::istreambuf_iterator<char>(json_in)), std::istreambuf_iterator<char>());
json_in.close();

// parameters in binary
std::ifstream params_in("../files/mobilenet.params", std::ios::binary);
std::string params_data((std::istreambuf_iterator<char>(params_in)), std::istreambuf_iterator<char>());
params_in.close();

TVMByteArray params_arr;
params_arr.data = params_data.c_str();
params_arr.size = params_data.length();
```

åœ¨è¯»å–å®Œä¿¡æ¯ä¹‹åï¼Œæˆ‘ä»¬è¦åˆ©ç”¨ä¹‹å‰è¯»å–çš„ä¿¡æ¯ï¼Œæ„å»ºTVMä¸­çš„è¿è¡Œå›¾(Graph_runtime)ï¼š

```cpp
int dtype_code = kDLFloat;
int dtype_bits = 32;
int dtype_lanes = 1;
int device_type = kDLCPU;
int device_id = 0;

tvm::runtime::Module mod = (*tvm::runtime::Registry::Get("tvm.graph_runtime.create"))
        (json_data, mod_dylib, device_type, device_id);
```

ç„¶ååˆ©ç”¨TVMä¸­å‡½æ•°å»ºç«‹ä¸€ä¸ªè¾“å…¥çš„å¼ é‡ç±»å‹å¹¶ä¸”ä¸ºå®ƒåˆ†é…ç©ºé—´ï¼š

```cpp
DLTensor *x;
int in_ndim = 4;
int64_t in_shape[4] = {1, 3, 128, 128};
TVMArrayAlloc(in_shape, in_ndim, dtype_code, dtype_bits, dtype_lanes, device_type, device_id, &x);
```

å…¶ä¸­`DLTensor`æ˜¯ä¸ªçµæ´»çš„ç»“æ„ï¼Œå¯ä»¥åŒ…å®¹å„ç§ç±»å‹çš„å¼ é‡ï¼Œè€Œåœ¨åˆ›å»ºäº†è¿™ä¸ªå¼ é‡åï¼Œæˆ‘ä»¬éœ€è¦å°†OpenCVä¸­è¯»å–çš„å›¾åƒä¿¡æ¯ä¼ å…¥åˆ°è¿™ä¸ªå¼ é‡ç»“æ„ä¸­ï¼š

```cpp
// è¿™é‡Œä¾ç„¶è¯»å–äº†papar.pngè¿™å¼ å›¾
image = cv::imread("/home/prototype/CLionProjects/tvm-cpp/data/paper.png");

cv::cvtColor(image, frame, cv::COLOR_BGR2RGB);
cv::resize(frame, input,  cv::Size(128,128));

float data[128 * 128 * 3];
// åœ¨è¿™ä¸ªå‡½æ•°ä¸­ å°†OpenCVä¸­çš„å›¾åƒæ•°æ®è½¬åŒ–ä¸ºCHWçš„å½¢å¼ 
Mat_to_CHW(data, input);
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå› ä¸ºOpenCVä¸­çš„å›¾åƒæ•°æ®çš„ä¿å­˜é¡ºåºæ˜¯(128,128,3)ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬éœ€è¦å°†å…¶è°ƒæ•´è¿‡æ¥ï¼Œå…¶ä¸­`Mat_to_CHW`å‡½æ•°çš„å…·ä½“å†…å®¹æ˜¯:

```cpp
void Mat_to_CHW(float *data, cv::Mat &frame)
{
    assert(data && !frame.empty());
    unsigned int volChl = 128 * 128;

    for(int c = 0; c < 3; ++c)
    {
        for (unsigned j = 0; j < volChl; ++j)
            data[c*volChl + j] = static_cast<float>(float(frame.data[j * 3 + c]) / 255.0);
    }

}
```

å½“ç„¶åˆ«å¿˜äº†é™¤ä»¥255.0å› ä¸ºåœ¨Pytorchä¸­æ‰€æœ‰çš„æƒé‡ä¿¡æ¯çš„èŒƒå›´éƒ½æ˜¯0-1ã€‚

åœ¨å°†OpenCVä¸­çš„å›¾åƒæ•°æ®è½¬åŒ–åï¼Œæˆ‘ä»¬å°†è½¬åŒ–åçš„å›¾åƒæ•°æ®æ‹·è´åˆ°ä¹‹å‰çš„å¼ é‡ç±»å‹ä¸­:

```cpp
// xä¸ºä¹‹å‰çš„å¼ é‡ç±»å‹ dataä¸ºä¹‹å‰å¼€è¾Ÿçš„æµ®ç‚¹å‹ç©ºé—´
memcpy(x->data, &data, 3 * 128 * 128 * sizeof(float));
```

ç„¶åæˆ‘ä»¬è®¾ç½®è¿è¡Œå›¾çš„è¾“å…¥(x)å’Œè¾“å‡º(y):

```cpp
// get the function from the module(set input data)
tvm::runtime::PackedFunc set_input = mod.GetFunction("set_input");
set_input("0", x);

// get the function from the module(load patameters)
tvm::runtime::PackedFunc load_params = mod.GetFunction("load_params");
load_params(params_arr);

DLTensor* y;
int out_ndim = 2;
int64_t out_shape[2] = {1, 3,};
TVMArrayAlloc(out_shape, out_ndim, dtype_code, dtype_bits, dtype_lanes, device_type, device_id, &y);

// get the function from the module(run it)
tvm::runtime::PackedFunc run = mod.GetFunction("run");

// get the function from the module(get output data)
tvm::runtime::PackedFunc get_output = mod.GetFunction("get_output");
```

æ­¤åˆ»æˆ‘ä»¬å°±å¯ä»¥è¿è¡Œäº†ï¼š

```cpp
run();
get_output(0, y);

// å°†è¾“å‡ºçš„ä¿¡æ¯æ‰“å°å‡ºæ¥
auto result = static_cast<float*>(y->data);
for (int i = 0; i < 3; i++)
    cout<<result[i]<<endl;
```

æœ€åçš„è¾“å‡ºä¿¡æ¯æ˜¯

```powershell
13.8204
-7.31387
-6.8253
```

å¯ä»¥çœ‹åˆ°ï¼ŒæˆåŠŸè¯†åˆ«å‡ºäº†å¸ƒè¿™å¼ å›¾ç‰‡ï¼Œåˆ°åº•ä¸ºæ­¢åœ¨C++ç«¯çš„éƒ¨ç½²å°±å®Œæ¯•äº†ã€‚

## 7. åœ¨æ ‘è“æ´¾ä¸Šçš„éƒ¨ç½²

å‚è€ƒ5å³å¯

## 8. åœ¨GPUä¸Šéƒ¨ç½²

