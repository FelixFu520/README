# TVMæºç å­¦ä¹ 

âŒšï¸:2020å¹´11æœˆ30æ—¥

ğŸ“šå‚è€ƒ

---



## 1. ç®€ä»‹

æœ¬ç³»åˆ—åšå®¢çš„ä¸»è¦ç›®çš„æ˜¯åšä¸»åœ¨æ‰“ç®—å­¦ä¹ TVMæ—¶ï¼Œå‘ç°å¯¹TVMçš„æºç ä»‹ç»å†…å®¹éå¸¸å°‘ï¼Œå› æ­¤æœ¬ç³»åˆ—åšå®¢ä¸»è¦ä»¥å­¦ä¹ TVMæ¡†æ¶ä¸ºå‰æä¸‹ï¼Œæ¥å¯¹TVMçš„æºç å†…å®¹è¿›è¡Œè§£è¯»ï¼Œä»è€Œä¹Ÿèƒ½å¸®åŠ©æ›´å¤šçš„äººæ¥äº†è§£TVMã€‚

## 2. TVMæºç ç›®å½•ç»“æ„

1. 3rdpartyï¼šä¸»è¦æ˜¯TVMä½¿ç”¨åˆ°çš„ç¬¬ä¸‰æ–¹åº“
2. appsï¼šåŒ…å«äº†TVMçš„æ‰©å±•é¡¹ç›®ï¼Œå¹¶æœ‰ä½¿ç”¨TVMçš„ç¤ºä¾‹
3. cmakeï¼šcmakeå·¥ç¨‹æ–‡ä»¶
4. condaï¼šcondaå®‰è£…è„šæœ¬
5. dockerï¼šåŒ…å«TVMçš„dockeræ¨¡å—
6. docsï¼šåŒ…å«TVMçš„æ–‡æ¡£
7. golangï¼šåŒ…å«TVMçš„golangæ¥å£
8. includeï¼šåŒ…å«TVMä¸­Cæºç çš„å¤´æ–‡ä»¶
9. jvmï¼šåŒ…å«TVMçš„javaæ¥å£
10. licensesï¼š åŒ…å«TVMä½¿ç”¨çš„license
11. nnvmï¼šTVMä½¿ç”¨çš„ä¸€ç±»ç¼–è¯‘å™¨å‰ç«¯nnvm
12. pythonï¼šTVMçš„Pythonæºä»£ç 
13. rustï¼šåŒ…å«TVMçš„rustæ¥å£ï¼Ÿ
14. srcï¼šåŒ…å«TVMçš„Cæºä»£ç 
15. testsï¼šåŒ…å«TVMçš„æµ‹è¯•ç”¨ä¾‹
16. topiï¼šåŒ…å«TVMçš„ç›¸å…³ä¼˜åŒ–
17. tutorialï¼šåŒ…å«TVMçš„ç›¸å…³æ•™ç¨‹
18. vtaï¼šåŒ…å«åŸºäºTVMçš„vtaé¡¹ç›®
19. webï¼šåŒ…å«TVMçš„webåç«¯
20. å…¶ä»–æ–‡ä»¶ï¼šç›¸å…³ç¼–è¯‘æ–‡ä»¶



## 3. TVMä»£ç åº“æ¼”ç»ƒç¤ºä¾‹

https://blog.csdn.net/weixin_42164269/article/details/104291677

äº†è§£æ–°çš„ä»£ç åº“å¯èƒ½æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚å¯¹äºåƒTVMè¿™æ ·çš„ä»£ç åº“ï¼Œå°¤å…¶å¦‚æ­¤ï¼Œå…¶ä¸­ä¸åŒçš„ç»„ä»¶ä»¥éæ˜¾è€Œæ˜“è§çš„æ–¹å¼äº¤äº’ã€‚åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°è¯•é€šè¿‡ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹æ¥è¯´æ˜æ„æˆç¼–è¯‘ çš„å…³é”®å…ƒç´ ã€‚å¯¹äºæ¯ä¸ªé‡è¦æ­¥éª¤ï¼Œæˆ‘ä»¬éƒ½ä¼šæ˜¾ç¤ºåœ¨ä»£ç åº“ä¸­çš„å“ªä¸ªä½ç½®ã€‚ç›®çš„æ˜¯è®©æ–°å¼€å‘äººå‘˜å’Œæ„Ÿå…´è¶£çš„ç”¨æˆ·æ›´å¿«åœ°è¿›å…¥ä»£ç åº“ã€‚

### **3.1 ä»£ç åº“ç»“æ„æ¦‚è¿°**

åœ¨TVMåº“çš„æ ¹ç›®å½•ä¸­ï¼Œæˆ‘ä»¬å…·æœ‰ä»¥ä¸‹å­ç›®å½•ï¼Œè¿™äº›å­ç›®å½•ä¸€èµ·æ„æˆäº†å¤§éƒ¨åˆ†ä»£ç åº“ã€‚

- `src` -ç”¨äºæ“ä½œç¬¦ç¼–è¯‘å’Œéƒ¨ç½²è¿è¡Œæ—¶çš„C ++ä»£ç ã€‚
- `src/relay` -Relayå®ç°ï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ–°åŠŸèƒ½IRã€‚
- `python`-Pythonå‰ç«¯ï¼Œå°è£…ã€srcã€‘ä¸­C ++å‡½æ•°å’Œå¯¹è±¡å®ç°ã€‚
- `topi` -è®¡ç®—æ ‡å‡†ç¥ç»ç½‘ç»œæ“ä½œç¬¦çš„å®šä¹‰å’Œåç«¯è°ƒåº¦ã€‚

ä½¿ç”¨æ ‡å‡†çš„æ·±åº¦å­¦ä¹ æœ¯è¯­ï¼Œã€`src/relay`ã€‘æ˜¯ç®¡ç†è®¡ç®—å›¾çš„ç»„ä»¶ï¼Œå¹¶ä¸”å›¾ä¸­çš„èŠ‚ç‚¹æ˜¯ä½¿ç”¨ã€`src`ã€‘å…¶ä½™éƒ¨åˆ†ä¸­å®ç°çš„åŸºç¡€ç»“æ„æ¥ç¼–è¯‘å’Œæ‰§è¡Œçš„ã€‚`python`ä¸ºç”¨æˆ·å¯ç”¨æ¥æ‰§è¡Œç¼–è¯‘çš„C ++ APIå’Œé©±åŠ¨ç¨‹åºä»£ç æä¾›pythonç»‘å®šã€‚æ“ä½œç¬¦å¯¹åº”ã€src/relay/opã€‘ä¸­æ³¨å†Œçš„æ¯ä¸€ä¸ªèŠ‚ç‚¹ã€‚æ“ä½œç¬¦çš„å®ç°ä½äºã€`topi`ã€‘ï¼Œå¹¶ä¸”ä½¿ç”¨C ++æˆ–Pythonè¿›è¡Œç¼–ç ã€‚

å½“ç”¨æˆ·é€šè¿‡ã€`relay.build(...)`ã€‘è°ƒç”¨å›¾ç¼–è¯‘æ—¶ï¼Œå›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½ä¼šå‘ç”Ÿä»¥ä¸‹æ“ä½œåºåˆ—ï¼š

- é€šè¿‡æŸ¥è¯¢æ“ä½œç¬¦æ³¨å†Œè¡¨æ¥æŸ¥æ‰¾æ“ä½œç¬¦å®ç°
- ä¸ºæ“ä½œç¬¦ç”Ÿæˆè®¡ç®—è¡¨è¾¾å¼å’Œè°ƒåº¦
- å°†è¿ç®—ç¬¦ç¼–è¯‘ä¸ºç›®æ ‡ä»£ç 

TVMä»£ç åº“æœ‰è¶£çš„æ–¹é¢ä¹‹ä¸€æ˜¯C ++å’ŒPythonä¹‹é—´çš„äº’æ“ä½œæ€§ä¸æ˜¯å•å‘çš„ã€‚é€šå¸¸ï¼Œæ‰€æœ‰æ‰§è¡Œç¹é‡å·¥ä½œçš„ä»£ç éƒ½æ˜¯ç”¨C ++å®ç°çš„ï¼Œå¹¶ä¸”ä¸ºç”¨æˆ·ç•Œé¢æä¾›äº†Pythonç»‘å®šã€‚åœ¨TVMä¸­ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œä½†æ˜¯åœ¨TVMä»£ç åº“ä¸­ï¼ŒC ++ä»£ç ä¹Ÿå¯ä»¥è°ƒç”¨Pythonæ¨¡å—ä¸­å®šä¹‰çš„å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œå·ç§¯è¿ç®—ç¬¦æ˜¯ç”¨Pythonå®ç°çš„ï¼Œå…¶å®ç°æ˜¯ä»Relayä¸­çš„C ++ä»£ç è°ƒç”¨çš„ã€‚

### **3.2 å‘é‡åŠ æ³•ç¤ºä¾‹**

æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç›´æ¥ä½¿ç”¨ä½çº§TVM APIçš„ç®€å•ç¤ºä¾‹ã€‚è¯¥ç¤ºä¾‹æ˜¯çŸ¢é‡åŠ æ³•ï¼Œ[ã€](https://docs.tvm.ai/tutorials/get_started.html#sphx-glr-tutorials-get-started-py)https://docs.tvm.ai/tutorials/get_started.html#sphx-glr-tutorials-get-started-py[ã€‘](https://docs.tvm.ai/tutorials/get_started.html#sphx-glr-tutorials-get-started-py)è¿›è¡Œè¯¦ç»†ä»‹ç»ã€‚

```html
n = 1024
A = tvm.placeholder((n,), name='A')
B = tvm.placeholder((n,), name='B')
C = tvm.compute(A.shape, lambda i: A[i] + B[i], name="C")
```

åœ¨è¿™é‡Œï¼Œ`A`ï¼Œ`B`ï¼Œ`Cçš„`ç±»å‹æ˜¯ã€`tvm.tensor.Tensor`ã€‘ï¼Œå®šä¹‰åœ¨ã€`python/tvm/tensor.py`ã€‘ä¸­ã€‚Pythonä¸­çš„ã€`Tensor`ã€‘æ˜¯ç”±C ++ä¸­çš„ã€`Tensor`ã€‘åŒ…è£…çš„ï¼Œåœ¨ã€`include/tvm/tensor.h`ã€‘å’Œã€`src/lang/tensor.cc`ã€‘ä¸­å®ç°ã€‚TVMä¸­çš„æ‰€æœ‰Pythonç±»å‹éƒ½å¯ä»¥è§†ä¸ºå…·æœ‰ç›¸åŒåç§°çš„åŸºç¡€C ++ç±»å‹çš„å¥æŸ„ã€‚å¦‚æœæ‚¨åœ¨ä¸‹é¢çœ‹åˆ°Python ã€`Tensor`ã€‘ç±»å‹çš„å®šä¹‰ï¼Œå¯ä»¥çœ‹åˆ°å®ƒæ˜¯ã€`Object`ã€‘çš„å­ç±»ã€‚

```html
@register_object
class Tensor(Object, _expr.ExprOp):
    """Tensor object, to construct, see function.Tensor"""
    def __call__(self, *indices):
       ...
```

å¯¹è±¡åè®®æ˜¯å°†C ++ç±»å‹å…¬å¼€ç»™å‰ç«¯è¯­è¨€ï¼ˆåŒ…æ‹¬Pythonï¼‰çš„åŸºç¡€ã€‚TVMå®ç°PythonåŒ…è£…çš„æ–¹æ³•å¹¶ä¸ç®€å•ã€‚[ã€](https://docs.tvm.ai/dev/runtime.html#tvm-node-and-compiler-stack)https://docs.tvm.ai/dev/runtime.html#tvm-node-and-compiler-stack[ã€‘](https://docs.tvm.ai/dev/runtime.html#tvm-node-and-compiler-stack)ç®€è¦ä»‹ç»äº†[å®ƒ](https://docs.tvm.ai/dev/runtime.html#tvm-node-and-compiler-stack)ï¼Œå¦‚æœæ‚¨æœ‰å…´è¶£ï¼Œè¯·å‚é˜…ã€`python/tvm/_ffi/`ã€‘è¯¦ç»†ä¿¡æ¯ã€‚

æˆ‘ä»¬ä½¿ç”¨ã€`TVM_REGISTER_*`ã€‘å®ï¼Œä»¥[PackedFunc](https://docs.tvm.ai/dev/runtime.html#packedfunc)çš„å½¢å¼å°†C ++å‡½æ•°å…¬å¼€ç»™å‰ç«¯è¯­è¨€ã€‚ã€`PackedFunc`ã€‘ æ˜¯TVMåœ¨C ++å’ŒPythonä¹‹é—´å®ç°äº’æ“ä½œæ€§çš„å¦ä¸€ç§æœºåˆ¶ã€‚ç‰¹åˆ«çš„ï¼Œè¿™ä½¿å¾—ä»C ++ä»£ç åº“è°ƒç”¨Pythonå‡½æ•°éå¸¸å®¹æ˜“ã€‚æ‚¨è¿˜å¯ä»¥æ£€æŸ¥ã€ [FFI Navigator](https://github.com/tqchen/ffi-navigator)ï¼ˆhttps://github.com/tqchen/ffi-navigatorï¼‰ã€‘ï¼Œè¯¥[å¯¼èˆª](https://github.com/tqchen/ffi-navigator)å™¨ä½¿æ‚¨å¯ä»¥åœ¨pythonå’Œc ++ FFIè°ƒç”¨ä¹‹é—´è¿›è¡Œå¯¼èˆªã€‚

ã€`Tensor`ã€‘å¯¹è±¡å…·æœ‰ã€`Operation`ã€‘ä¸å…¶ç›¸å…³è”ï¼Œå®šä¹‰åœ¨ã€`python/tvm/te/tensor.py`ã€‘ï¼Œã€`include/tvm/te/operation.h`ã€‘å’Œã€`src/tvm/te/operation`ã€‘å­ç›®å½•ã€‚ã€`Tensor`ã€‘æ˜¯ã€`Operation`ã€‘å¯¹è±¡çš„è¾“å‡ºã€‚æ¯ä¸ªã€`Operation`ã€‘å¯¹è±¡éƒ½æœ‰ç›¸åº”çš„ã€`input_tensors()`ã€‘æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è¿”å›è¾“å…¥ã€`Tensor`ã€‘åˆ—è¡¨ã€‚è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è·Ÿè¸ªã€`Operation`ã€‘ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚

æˆ‘ä»¬ä¼ é€’ä¸è¾“å‡ºå¼ é‡ã€`C`ã€‘ç›¸å¯¹åº”çš„è¿ç®—ä»¥åˆ°ã€`python/tvm/te/schedule.py`ã€‘ä¸­çš„ã€`tvm.create_schedule()`ã€‘å‡½æ•°ã€‚

```html
s = tvm.create_schedule(C.op)
```

æ­¤å‡½æ•°æ˜ å°„åˆ°ã€`include/tvm/schedule.h`ã€‘ä¸­çš„C ++å‡½æ•°ã€‚

```html
inline Schedule create_schedule(Array<Operation> ops) {
  return ScheduleNode::make(ops);
}
```

`ã€Scheduleã€‘`ç”±ã€`Stage`ã€‘å’Œè¾“å‡ºã€`Operation`ã€‘çš„é›†åˆç»„æˆã€‚

`ã€Stageã€‘`å¯¹åº”ä¸€ä¸ªã€`Operation`ã€‘ã€‚åœ¨ä¸Šé¢çš„çŸ¢é‡åŠ æ³•ç¤ºä¾‹ä¸­ï¼Œæœ‰ä¸¤ä¸ªå ä½ç¬¦æ“ä½œå’Œä¸€ä¸ªè®¡ç®—æ“ä½œï¼Œå› æ­¤è°ƒåº¦ã€`s`ã€‘åŒ…å«ä¸‰ä¸ªé˜¶æ®µã€‚å„ã€`Stage`ã€‘ä¿æŒå…³äºå¾ªç¯åµŒå¥—ç»“æ„çš„ä¿¡æ¯ï¼Œæ¯ä¸ªå¾ªç¯çš„ç±»å‹ï¼ˆ`Parallel`ï¼Œ`Vectorized`ï¼Œ`Unrolled`ï¼‰ï¼Œå¹¶ä¸”ä¸‹ä¸€ä¸ªã€`Stage`ã€‘å¾ªç¯åµŒå¥—æ‰§è¡Œå…¶è®¡ç®—`ï¼Œ`å¦‚æœæœ‰çš„è¯ã€‚

`ã€Scheduleã€‘`å’Œã€`Stage`ã€‘è¢«å®šä¹‰åœ¨ã€`tvm/python/te/schedule.py`ã€‘ï¼Œã€`include/tvm/te/schedule.h`ã€‘å’Œã€`src/te/schedule/schedule_ops.cc`ã€‘ã€‚

ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬åœ¨ä¸Šè¿°ã€create_schedule()ã€‘å‡½æ•°åˆ›å»ºçš„é»˜è®¤è°ƒåº¦ä¸­è°ƒç”¨ã€`tvm.build(...)`ã€‘å‡½æ•°ã€‚

```html
target = "cuda"
fadd = tvm.build(s, [A, B, C], target)
```

`å®šä¹‰åœ¨ã€python/tvm/driver/build_module.pyã€‘ä¸­çš„ã€tvm.build()ã€‘ï¼Œæ¥å—ä¸€ä¸ªè°ƒåº¦`ï¼Œè¾“å…¥å’Œè¾“å‡ºã€`Tensor`ã€‘ä»¥åŠç›®æ ‡ï¼Œç„¶åè¿”å›ä¸€ä¸ªã€[`tvm.runtime.Module`](https://docs.tvm.ai/api/python/runtime.html#tvm.runtime.Module)ã€‘å¯¹è±¡ã€‚ä¸€ä¸ªã€[`tvm.runtime.Module`](https://docs.tvm.ai/api/python/runtime.html#tvm.runtime.Module)ã€‘å¯¹è±¡åŒ…å«ä¸€ä¸ªå¯ä»¥ä½¿ç”¨å‡½æ•°è°ƒç”¨è¯­æ³•è°ƒç”¨çš„å·²ç¼–è¯‘å‡½æ•°ã€‚

ã€`tvm.build()`ã€‘çš„è¿‡ç¨‹å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼š

- é™ä½ï¼Œå°†é«˜çº§åˆ«çš„åˆå§‹å¾ªç¯åµŒå¥—ç»“æ„è½¬æ¢ä¸ºæœ€ç»ˆçš„ä½çº§åˆ«IR
- ä»£ç ç”Ÿæˆï¼Œå…¶ä¸­ä»ä½çº§IRç”Ÿæˆç›®æ ‡æœºå™¨ä»£ç 

é™ä½æ˜¯é€šè¿‡ã€`tvm.lower()`ã€‘å‡½æ•°å®Œæˆçš„ï¼Œå®šä¹‰åœ¨ã€`python/tvm/build_module.py`ã€‘ä¸­ã€‚é¦–å…ˆï¼Œæ‰§è¡Œè¾¹ç•Œæ¨æ–­ï¼Œå¹¶åˆ›å»ºåˆå§‹å¾ªç¯åµŒå¥—ç»“æ„ã€‚

```html
def lower(sch,
          args,
          name="default_function",
          binds=None,
          simple_mode=False):
   ...
   bounds = schedule.InferBound(sch)
   stmt = schedule.ScheduleOps(sch, bounds)
   ...
```

è¾¹ç•Œæ¨æ–­æ˜¯æ¨æ–­æ‰€æœ‰å¾ªç¯è¾¹ç•Œå’Œä¸­é—´ç¼“å†²åŒºå¤§å°çš„è¿‡ç¨‹ã€‚å¦‚æœæ‚¨ä»¥CUDAåç«¯ä¸ºç›®æ ‡å¹¶ä¸”ä½¿ç”¨å…±äº«å†…å­˜ï¼Œåˆ™ä¼šåœ¨æ­¤å¤„è‡ªåŠ¨ç¡®å®šæ‰€éœ€çš„æœ€å°å¤§å°ã€‚ç»‘å®šæ¨ç†åœ¨ã€`src/te/schedule/bound.cc`ã€‘ï¼Œã€`src/te/schedule/graph.cc`ã€‘å’Œã€`src/te/schedule/message_passing.cc`ã€‘ä¸­å®ç°ã€‚æœ‰å…³ç»‘å®šæ¨ç†å¦‚ä½•å·¥ä½œçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ã€http://docs.tvm.ai/dev/inferbound.htmlã€‘ã€‚

`ã€stmtã€‘`ï¼Œæ˜¯ã€`ScheduleOps()`ã€‘çš„è¾“å‡ºï¼Œä»£è¡¨åˆå§‹çš„å¾ªç¯åµŒå¥—ç»“æ„ã€‚å¦‚æœæ‚¨å·²å°†ã€`reorder`ã€‘åŸè¯­å’Œã€`split` ã€‘åŸè¯­åº”ç”¨åˆ°ä½ çš„è°ƒåº¦ä¸­ï¼Œåˆ™åˆå§‹å¾ªç¯åµŒå¥—å·²ç»åæ˜ äº†è¿™äº›æ›´æ”¹ã€‚ã€`ScheduleOps()`ã€‘åœ¨ã€`src/te/schedule/schedule_ops.cc`ã€‘ä¸­å®šä¹‰ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¤šä¸ªé™ä½è½¬æ¢åº”ç”¨äºã€`stmt`ã€‘ã€‚è¿™äº›è¿‡ç¨‹åœ¨ã€`src/tir/pass`ã€‘å­ç›®å½•ä¸­å®ç°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨å·²å¯¹æ—¶é—´è¡¨åº”ç”¨äº†ã€`vectorize`ã€‘æˆ–ã€`unroll`ã€‘åŸè¯­ï¼Œåˆ™å®ƒä»¬å°†è¢«åº”ç”¨åˆ°å¾ªç¯çŸ¢é‡åŒ–å’Œä¸‹é¢çš„å±•å¼€è¿‡ç¨‹ä¸­ã€‚

```html
...
stmt = ir_pass.VectorizeLoop(stmt)
...
stmt = ir_pass.UnrollLoop(
    stmt,
    cfg.auto_unroll_max_step,
    cfg.auto_unroll_max_depth,
    cfg.auto_unroll_max_extent,
    cfg.unroll_explicit)
...
```

é™ä½å®Œæˆåï¼Œã€`build()`ã€‘å‡½æ•°ä»é™ä½çš„å‡½æ•°ç”Ÿæˆç›®æ ‡æœºå™¨ä»£ç ã€‚å¦‚æœä»¥x86ä¸ºç›®æ ‡ï¼Œåˆ™æ­¤ä»£ç å¯ä»¥åŒ…å«SSEæˆ–AVXæŒ‡ä»¤ï¼Œæˆ–ä»¥CUDAä¸ºç›®æ ‡çš„PTXæŒ‡ä»¤ã€‚é™¤äº†ç›®æ ‡ç‰¹å®šçš„æœºå™¨ä»£ç ä¹‹å¤–ï¼ŒTVMè¿˜ç”Ÿæˆä¸»æœºä¾§ä»£ç ï¼Œè¯¥ä»£ç è´Ÿè´£å†…å­˜ç®¡ç†ï¼Œå†…æ ¸å¯åŠ¨ç­‰ã€‚

ä»£ç ç”Ÿæˆç”±ã€`python/tvm/target/codegen.py`ã€‘ä¸­å®šä¹‰çš„ã€`build_module()`ã€‘å‡½æ•°å®Œæˆã€‚åœ¨C ++ä¾§ï¼Œä»£ç ç”Ÿæˆåœ¨`ã€src/target/codegenã€‘`å­ç›®å½•ä¸­å®ç°ã€‚ã€`build_module()`ã€‘Pythonå‡½æ•°å°†è¾¾åˆ°ã€`src/target/codegen/codegen.cc`ã€‘ä¸­çš„ã€`Build()`ã€‘å‡½æ•°ï¼š

```html
runtime::Module Build(const Array<LoweredFunc>& funcs,
                      const std::string& target) {
  std::string build_f_name = "codegen.build_" + target;
  const PackedFunc* bf = runtime::Registry::Get(build_f_name);
  runtime::Module m = (*bf)(funcs, target);
  return m;
}
```

ã€`Build()`ã€‘å‡½æ•°åœ¨ã€`PackedFunc`ã€‘æ³¨å†Œè¡¨ä¸­æŸ¥æ‰¾ç»™å®šç›®æ ‡çš„ä»£ç ç”Ÿæˆå™¨ï¼Œå¹¶è°ƒç”¨æ‰¾åˆ°çš„å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œã€`codegen.build_cuda`ã€‘å‡½æ•°åœ¨ã€`src/codegen/build_cuda_on.cc`ã€‘ä¸­æ³¨å†Œï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```html
TVM_REGISTER_GLOBAL("codegen.build_cuda")
.set_body([](TVMArgs args, TVMRetValue* rv) {
    *rv = BuildCUDA(args[0]);
  });
```

ä¸Šè¿°ä½¿ç”¨ã€`CodeGenCUDA` ã€‘ç±»ä»é™ä½IRç”Ÿæˆçš„CUDAæºç æ ¸ã€`BuildCUDA()`ã€‘å®šä¹‰åœ¨ã€`src/codegen/codegen_cuda.cc`ã€‘ï¼Œå’Œä½¿ç”¨NVRTCå†…æ ¸ç¼–è¯‘ã€‚å¦‚æœæ‚¨é’ˆå¯¹ä½¿ç”¨LLVMï¼ˆåŒ…æ‹¬x86ï¼ŒARMï¼ŒNVPTXå’ŒAMDGPUï¼‰çš„åç«¯ï¼Œåˆ™ä»£ç ç”Ÿæˆä¸»è¦ç”±ã€s`rc/codegen/llvm/codegen_llvm.cc`ã€‘ä¸­å®šä¹‰çš„ç±»ã€`CodeGenLLVM`ã€‘å®Œæˆã€‚ã€`CodeGenLLVM`ã€‘å°†TVM IRè½¬æ¢ä¸ºLLVM IRï¼Œè¿è¡Œå¤§é‡LLVMä¼˜åŒ–éå†ï¼Œå¹¶ç”Ÿæˆç›®æ ‡æœºå™¨ä»£ç ã€‚

ã€`src/codegen/codegen.cc`ã€‘ä¸­çš„ã€`Build()`ã€‘å‡½æ•°è¿”å›å®šä¹‰åœ¨ã€`include/tvm/runtime/module.h`ã€‘å’Œã€`src/runtime/module.cc`ã€‘ä¸­å®šä¹‰çš„å¯¹è±¡ã€`runtime::Module`ã€‘ã€‚ã€`Module`ã€‘å¯¹è±¡æ˜¯ä¸€ä¸ªå®¹å™¨ï¼Œè£…è½½ç‰¹å®šäºç›®æ ‡çš„ã€`ModuleNode`ã€‘å¯¹è±¡ã€‚æ¯ä¸ªåç«¯éƒ½å®ç°ã€`ModuleNode`ã€‘å­ç±»ï¼Œä»¥æ·»åŠ ç›®æ ‡ç‰¹å®šçš„è¿è¡Œæ—¶APIè°ƒç”¨ã€‚ä¾‹å¦‚ï¼ŒCUDAåç«¯åœ¨ã€`src/runtime/cuda/cuda_module.cc`ã€‘ä¸­å®ç°ã€`CUDAModuleNode`ã€‘ç±»ï¼Œè¯¥ç±»ç®¡ç†CUDAé©±åŠ¨ç¨‹åºAPIã€‚ä¸Šé¢çš„ã€`BuildCUDA()`ã€‘å‡½æ•°ç”¨ã€`runtime::Module`ã€‘è£…é¥°ã€`CUDAModuleNode`ã€‘ï¼Œå¹¶è¿”å›åˆ°Pythonç«¯ã€‚LLVMåç«¯ã€`LLVMModuleNode`ã€‘åœ¨ã€`src/codegen/llvm/llvm_module.cc`ã€‘ä¸­å®ç°ï¼Œå®ƒå¤„ç†å·²ç¼–è¯‘ä»£ç çš„JITæ‰§è¡Œã€‚ã€`ModuleNode`ã€‘çš„å…¶ä»–å­ç±»å¯ä»¥åœ¨ã€`src/runtime`ã€‘çš„å­ç›®å½•ä¸‹æ‰¾åˆ°ï¼Œä¸æ¯ä¸ªåç«¯ç›¸å¯¹åº”ã€‚

è¿”å›çš„æ¨¡å—ï¼ˆå¯ä»¥è®¤ä¸ºæ˜¯å·²ç¼–è¯‘å‡½æ•°å’Œè®¾å¤‡APIçš„ç»„åˆï¼‰å¯ä»¥åœ¨TVMçš„NDArrayå¯¹è±¡ä¸Šè°ƒç”¨ã€‚

```html
ctx = tvm.context(target, 0)
a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), ctx)
b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), ctx)
c = tvm.nd.array(np.zeros(n, dtype=C.dtype), ctx)
fadd(a, b, c)
output = c.asnumpy()
```

åœ¨å¹•åï¼ŒTVMä¼šè‡ªåŠ¨åˆ†é…è®¾å¤‡å†…å­˜å¹¶ç®¡ç†å†…å­˜ä¼ è¾“ã€‚ä¸ºæ­¤ï¼Œæ¯ä¸ªåç«¯éƒ½éœ€è¦ç»§æ‰¿ã€`DeviceAPI`ã€‘ç±»ï¼Œå®šä¹‰åœ¨ã€`include/tvm/runtime/device_api.h`ã€‘ä¸­ï¼Œå¹¶é‡å†™å†…å­˜ç®¡ç†æ–¹æ³•ä»¥ä½¿ç”¨ç‰¹å®šäºè®¾å¤‡çš„APIã€‚ä¾‹å¦‚ï¼Œåœ¨ã€src/runtime/cuda/cuda_device_api.ccã€‘ä¸­å®ç°çš„ã€`CUDADeviceAPI`ã€‘CUDAåç«¯ï¼Œä»¥ä½¿ç”¨ã€`cudaMalloc`ã€‘ï¼Œã€`cudaMemcpy`ã€‘ç­‰ã€‚

é¦–æ¬¡ä½¿ç”¨ã€`fadd(a, b, c)`ã€‘è°ƒç”¨å·²ç¼–è¯‘çš„æ¨¡å—æ—¶ï¼Œã€`ModuleNode`ã€‘çš„ã€`GetFunction()`ã€‘æ–¹æ³•è¢«è°ƒç”¨ï¼Œæ¥è·å¾—ä¸€ä¸ªå¯ç”¨äºå†…æ ¸è°ƒç”¨çš„ã€`PackedFunc` ã€‘æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ã€src/runtime/cuda/cuda_device_api.ccã€‘ä¸­ï¼ŒCUDAåç«¯ã€`CUDAModuleNode::GetFunction()`ã€‘å®ç°å¦‚ä¸‹ï¼š

```html
PackedFunc CUDAModuleNode::GetFunction(
      const std::string& name,
      const std::shared_ptr<ModuleNode>& sptr_to_self) {
  auto it = fmap_.find(name);
  const FunctionInfo& info = it->second;
  CUDAWrappedFunc f;
  f.Init(this, sptr_to_self, name, info.arg_types.size(), info.thread_axis_tags);
  return PackFuncVoidAddr(f, info.arg_types);
}
```

ã€`PackedFunc`ã€‘çš„è¶…è½½ã€`operator()`ã€‘å°†è¢«è°ƒç”¨ï¼Œè¿™åè¿‡æ¥åˆè°ƒç”¨å®ç°åœ¨ã€`src/runtime/cuda/cuda_module.cc`ã€‘ä¸­çš„ã€`CUDAWrappedFunc`ã€‘çš„ã€`operator()`ã€‘å‡½æ•°ï¼Œåœ¨è¿™é‡Œç»ˆäºæˆ‘ä»¬çœ‹åˆ°äº†ã€`cuLaunchKernel`ã€‘é©±åŠ¨è°ƒç”¨ï¼š

```html
class CUDAWrappedFunc {
 public:
  void Init(...)
  ...
  void operator()(TVMArgs args,
                  TVMRetValue* rv,
                  void** void_args) const {
    int device_id;
    CUDA_CALL(cudaGetDevice(&device_id));
    if (fcache_[device_id] == nullptr) {
      fcache_[device_id] = m_->GetFunc(device_id, func_name_);
    }
    CUstream strm = static_cast<CUstream>(CUDAThreadEntry::ThreadLocal()->stream);
    ThreadWorkLoad wl = thread_axis_cfg_.Extract(args);
    CUresult result = cuLaunchKernel(
        fcache_[device_id],
        wl.grid_dim(0),
        wl.grid_dim(1),
        wl.grid_dim(2),
        wl.block_dim(0),
        wl.block_dim(1),
        wl.block_dim(2),
        0, strm, void_args, 0);
  }
};
```

æ€»ç»“äº†TVMå¦‚ä½•ç¼–è¯‘å’Œæ‰§è¡Œå‡½æ•°ã€‚å°½ç®¡æˆ‘ä»¬æ²¡æœ‰è¯¦ç»†ä»‹ç»TOPIæˆ–Relayï¼Œä½†æ˜¯æœ€åï¼Œæ‰€æœ‰ç¥ç»ç½‘ç»œæ“ä½œç¬¦éƒ½ç»è¿‡ä¸ä¸Šè¿°ç›¸åŒçš„ç¼–è¯‘è¿‡ç¨‹ã€‚é¼“åŠ±æ‚¨æ·±å…¥ç ”ç©¶å…¶ä½™ä»£ç åº“çš„ç»†èŠ‚ã€‚