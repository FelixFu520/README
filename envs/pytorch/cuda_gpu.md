# GPU&CUDAå¤šæœºé€šä¿¡

âŒšï¸: 2020å¹´8æœˆ9æ—¥

ğŸ“šå‚è€ƒ

---

## ä¸€ã€ç¡¬ä»¶å±‚æ¬¡

**å•æœºå¤šå¡**å†…å­˜å’ŒGPUã€GPUå’ŒGPUä¹‹é—´äº’è”å¯é€šè¿‡PCIEã€NVLinkã€NVSwitchï¼›
**å¤šæœºå¤šå¡**GPUä¹‹é—´ï¼ˆä¸åŒä¸»æœºï¼‰ã€CPUä¸GPUä¹‹é—´äº’è”å¯é€šè¿‡GPUDirect RDMAã€IB/ä¸‡å…†ä»¥å¤ªç½‘ + TCP/IPï¼›

### 1. PCIæ€»çº¿

PCIæ˜¯Peripheral Component Interconnect(å¤–è®¾éƒ¨ä»¶äº’è¿æ ‡å‡†)çš„ç¼©å†™ï¼Œå®ƒæ˜¯ç›®å‰ä¸ªäººç”µè„‘ä¸­ä½¿ç”¨æœ€ä¸ºå¹¿æ³›çš„æ¥å£ï¼Œå‡ ä¹æ‰€æœ‰çš„ä¸»æ¿äº§å“ä¸Šéƒ½å¸¦æœ‰è¿™ç§æ’æ§½ã€‚PCIæ’æ§½ä¹Ÿæ˜¯ä¸»æ¿å¸¦æœ‰æœ€å¤šæ•°é‡çš„æ’æ§½ç±»å‹ï¼Œåœ¨ç›®å‰æµè¡Œçš„å°å¼æœºä¸»æ¿ä¸Šï¼ŒATXç»“æ„çš„ä¸»æ¿ä¸€èˆ¬å¸¦æœ‰5ï½6ä¸ªPCIæ’æ§½ï¼Œè€Œå°ä¸€ç‚¹çš„MATXä¸»æ¿ä¹Ÿéƒ½å¸¦æœ‰2ï½3ä¸ªPCIæ’æ§½ï¼Œå¯è§å…¶åº”ç”¨çš„å¹¿æ³›æ€§ã€‚

PCI-Express(peripheral component interconnect express)æ˜¯ä¸€ç§é«˜é€Ÿä¸²è¡Œè®¡ç®—æœºæ‰©å±•æ€»çº¿æ ‡å‡†ï¼Œå®ƒåŸæ¥çš„åç§°ä¸ºâ€œ3GIOâ€ï¼Œæ˜¯ç”±è‹±ç‰¹å°”åœ¨2001å¹´æå‡ºçš„ï¼Œæ—¨åœ¨æ›¿ä»£æ—§çš„PCIï¼ŒPCI-Xå’ŒAGPæ€»çº¿æ ‡å‡†ã€‚**PCIeå±äºé«˜é€Ÿä¸²è¡Œç‚¹å¯¹ç‚¹åŒé€šé“é«˜å¸¦å®½ä¼ è¾“**ï¼Œæ‰€è¿æ¥çš„è®¾å¤‡åˆ†é…ç‹¬äº«é€šé“å¸¦å®½ï¼Œä¸å…±äº«æ€»çº¿å¸¦å®½ï¼Œä¸»è¦æ”¯æŒä¸»åŠ¨ç”µæºç®¡ç†ï¼Œé”™è¯¯æŠ¥å‘Šï¼Œç«¯å¯¹ç«¯çš„å¯é æ€§ä¼ è¾“ï¼Œçƒ­æ’æ‹”ä»¥åŠæœåŠ¡è´¨é‡(QOS)ç­‰åŠŸèƒ½ã€‚PCIeäº¤ç”±PCI-SIGï¼ˆPCIç‰¹æ®Šå…´è¶£ç»„ç»‡ï¼‰è®¤è¯å‘å¸ƒåæ‰æ”¹åä¸ºâ€œPCI-Expressâ€ï¼Œç®€ç§°â€œPCI-eâ€ã€‚å®ƒçš„ä¸»è¦ä¼˜åŠ¿å°±æ˜¯æ•°æ®ä¼ è¾“é€Ÿç‡é«˜ï¼Œç›®å‰æœ€é«˜çš„16X 2.0ç‰ˆæœ¬å¯è¾¾åˆ°10GB/sï¼Œè€Œä¸”è¿˜æœ‰ç›¸å½“å¤§çš„å‘å±•æ½œåŠ›ã€‚PCI Expressä¹Ÿæœ‰å¤šç§è§„æ ¼ï¼Œä»PCI Express x1åˆ°PCI Express x32ï¼Œèƒ½æ»¡è¶³å°†æ¥ä¸€å®šæ—¶é—´å†…å‡ºç°çš„ä½é€Ÿè®¾å¤‡å’Œé«˜é€Ÿè®¾å¤‡çš„éœ€æ±‚ã€‚PCI-Expressæœ€æ–°çš„æ¥å£æ˜¯PCIe 3.0æ¥å£ï¼Œå…¶æ¯”ç‰¹ç‡ä¸º**8Gbps**ï¼Œçº¦ä¸ºä¸Šä¸€ä»£äº§å“å¸¦å®½çš„ä¸¤å€ï¼Œå¹¶ä¸”åŒ…å«å‘å°„å™¨å’Œæ¥æ”¶å™¨å‡è¡¡ã€PLLæ”¹å–„ä»¥åŠæ—¶é’Ÿæ•°æ®æ¢å¤ç­‰ä¸€ç³»åˆ—é‡è¦çš„æ–°åŠŸèƒ½ï¼Œç”¨ä»¥æ”¹å–„æ•°æ®ä¼ è¾“å’Œæ•°æ®ä¿æŠ¤æ€§èƒ½ã€‚PCIeé—ªå­˜å¡çš„ä¾›åº”å•†åŒ…æ‹¬ï¼šINTELã€IBMã€LSIã€OCZã€ä¸‰æ˜Ÿ(è®¡åˆ’ä¸­)ã€SanDiskã€STECã€SuperTalentå’Œä¸œèŠ(è®¡åˆ’ä¸­)ç­‰ï¼Œè€Œé’ˆå¯¹æµ·é‡çš„æ•°æ®å¢é•¿ä½¿å¾—ç”¨æˆ·å¯¹è§„æ¨¡æ›´å¤§ã€å¯æ‰©å±•æ€§æ›´å¼ºçš„ç³»ç»Ÿæ‰€åº”ç”¨ï¼ŒPCIe 3.0æŠ€æœ¯çš„åŠ å…¥æœ€æ–°çš„LSI MegaRAIDæ§åˆ¶å™¨åŠHBAäº§å“çš„å‡ºè‰²æ€§èƒ½ï¼Œå°±å¯ä»¥å®ç°æ›´å¤§çš„ç³»ç»Ÿè®¾è®¡çµæ´»æ€§ã€‚æˆªæ­¢2019å¹´1æœˆä»½ï¼Œå½“å‰ä¸»æµä¸»æ¿å‡æ”¯æŒpcie 3.0ã€‚

![img](imgs/pcie.png)



**å‡ ä¸ªæ¦‚å¿µï¼š**

ä¼ è¾“é€Ÿç‡ä¸ºæ¯ç§’ä¼ è¾“é‡GT/sï¼Œè€Œä¸æ˜¯æ¯ç§’ä½æ•°Gbpsï¼Œå› ä¸ºä¼ è¾“é‡åŒ…æ‹¬ä¸æä¾›é¢å¤–ååé‡çš„å¼€é”€ä½ï¼› æ¯”å¦‚ PCIe 1.xå’ŒPCIe 2.xä½¿ç”¨8b / 10bç¼–ç æ–¹æ¡ˆï¼Œå¯¼è‡´å ç”¨äº†20% ï¼ˆ= 2/10ï¼‰çš„åŸå§‹ä¿¡é“å¸¦å®½ã€‚

GT/s â€”â€” Giga transation per second ï¼ˆåƒå…†ä¼ è¾“/ç§’ï¼‰ï¼Œå³æ¯ä¸€ç§’å†…ä¼ è¾“çš„æ¬¡æ•°ã€‚é‡ç‚¹åœ¨äºæè¿°ç‰©ç†å±‚é€šä¿¡åè®®çš„é€Ÿç‡å±æ€§ï¼Œå¯ä»¥ä¸å’Œé“¾è·¯å®½åº¦ç­‰å…³è”ã€‚

Gbps â€”â€” Giga Bits Per Second ï¼ˆåƒå…†ä½/ç§’ï¼‰ã€‚GT/s ä¸Gbps ä¹‹é—´ä¸å­˜åœ¨æˆæ¯”ä¾‹çš„æ¢ç®—å…³ç³»ã€‚

**PCIe ååé‡ï¼ˆå¯ç”¨å¸¦å®½ï¼‰è®¡ç®—æ–¹æ³•ï¼š**

**ååé‡ = ä¼ è¾“é€Ÿç‡ \*  ç¼–ç æ–¹æ¡ˆ**

ä¾‹å¦‚ï¼šPCI-e2.0 åè®®æ”¯æŒ 5.0 GT/sï¼Œå³æ¯ä¸€æ¡Lane ä¸Šæ”¯æŒæ¯ç§’é’Ÿå†…ä¼ è¾“ 5Gä¸ªBitï¼›ä½†è¿™å¹¶ä¸æ„å‘³ç€ PCIe 2.0åè®®çš„æ¯ä¸€æ¡Laneæ”¯æŒ 5Gbps çš„é€Ÿç‡ã€‚

ä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´å‘¢ï¼Ÿå› ä¸ºPCIe 2.0 çš„ç‰©ç†å±‚åè®®ä¸­ä½¿ç”¨çš„æ˜¯ 8b/10b çš„ç¼–ç æ–¹æ¡ˆã€‚ å³æ¯ä¼ è¾“8ä¸ªBitï¼Œéœ€è¦å‘é€10ä¸ªBitï¼›è¿™å¤šå‡ºçš„2ä¸ªBitå¹¶ä¸æ˜¯å¯¹ä¸Šå±‚æœ‰æ„ä¹‰çš„ä¿¡æ¯ã€‚

é‚£ä¹ˆï¼Œ PCIe 2.0åè®®çš„æ¯ä¸€æ¡Laneæ”¯æŒ 5 * 8 / 10 = 4 Gbps = 500 MB/s çš„é€Ÿç‡ã€‚

ä»¥ä¸€ä¸ªPCIe 2.0 x8çš„é€šé“ä¸ºä¾‹ï¼Œx8çš„å¯ç”¨å¸¦å®½ä¸º 4 * 8 = 32 Gbps = 4 GB/sã€‚

åŒç†ï¼Œ

PCI-e3.0 åè®®æ”¯æŒ 8.0 GT/s, å³æ¯ä¸€æ¡Lane ä¸Šæ”¯æŒæ¯ç§’é’Ÿå†…ä¼ è¾“ 8Gä¸ªBitã€‚

è€ŒPCIe 3.0 çš„ç‰©ç†å±‚åè®®ä¸­ä½¿ç”¨çš„æ˜¯ 128b/130b çš„ç¼–ç æ–¹æ¡ˆã€‚ å³æ¯ä¼ è¾“128ä¸ªBitï¼Œéœ€è¦å‘é€130ä¸ªBitã€‚

é‚£ä¹ˆï¼Œ PCIe 3.0åè®®çš„æ¯ä¸€æ¡Laneæ”¯æŒ 8 * 128 / 130 = 7.877 Gbps = 984.6 MB/s çš„é€Ÿç‡ã€‚

ä¸€ä¸ªPCIe 3.0 x16çš„é€šé“ï¼Œx16 çš„å¯ç”¨å¸¦å®½ä¸º 7.877 * 16 = 126.031 Gbps = 15.754 GB/sã€‚

ç”±æ­¤å¯è®¡ç®—å‡ºä¸Šè¡¨ä¸­çš„æ•°æ®

### 2. [NVLink](https://baike.baidu.com/item/NVLink/22658185?fr=aladdin)

NVLinkï¼Œæ˜¯è‹±ä¼Ÿè¾¾ï¼ˆNVIDIAï¼‰å¼€å‘å¹¶æ¨å‡ºçš„ä¸€ç§**æ€»çº¿åŠå…¶é€šä¿¡åè®®**ã€‚NVLinké‡‡ç”¨ç‚¹å¯¹ç‚¹ç»“æ„ã€ä¸²åˆ—ä¼ è¾“ï¼Œ**ç”¨äºä¸­å¤®å¤„ç†å™¨ï¼ˆCPUï¼‰ä¸å›¾å½¢å¤„ç†å™¨ï¼ˆGPUï¼‰ä¹‹é—´çš„è¿æ¥ï¼Œä¹Ÿå¯ç”¨äºå¤šä¸ªå›¾å½¢å¤„ç†å™¨ä¹‹é—´çš„ç›¸äº’è¿æ¥**ã€‚å½“å‰é…å¤‡å¹¶ä½¿ç”¨NVLinkçš„äº§å“ä¸šå·²å‘å¸ƒï¼Œå¤šä¸ºé’ˆå¯¹é«˜æ€§èƒ½è¿ç®—åº”ç”¨é¢†åŸŸï¼Œåƒæ˜¯è‹±ä¼Ÿè¾¾ç›®å‰æœ€æ–°çš„Tesla P100è¿ç®—å¡ã€‚

### 3. NVSwitch

åœ¨2018GTCä¸Šï¼Œè€é»„æ¨å‡ºäº†å…¨æ–°çš„NVSwitché«˜é€Ÿäº’è”æŠ€æœ¯ï¼Œé€šè¿‡NVSwitché«˜é€Ÿäº’è”æŠ€æœ¯èƒ½å¤Ÿè®©ä¸åŒçš„GPUä¹‹é—´è¿›è¡Œé«˜é€Ÿäº’è”ã€‚
æ ¹æ®ç›¸å…³ä»‹ç»ï¼Œç›¸æ¯”äºä¹‹å‰NVSLinkèƒ½å¤Ÿæœ€å¤šæ”¯æŒ8å—GPUè¿›è¡Œé«˜é€Ÿäº’è”çš„æˆç»©ï¼Œæœ€æ–°æ¨å‡ºçš„NVSwitchæŠ€æœ¯èƒ½å¤Ÿæœ€å¤šæ”¯æŒ16å—GPUäº’è”ã€‚
åœ¨ä½¿ç”¨NVSwitchè¿›è¡Œäº’è”çš„æ—¶å€™ï¼Œä¸ä»…èƒ½å¤Ÿè¾¾åˆ°é«˜é€Ÿçš„æ•ˆæœï¼ŒåŒæ—¶è¿˜èƒ½å¤Ÿä¿è¯æ¯ä¸€ä¸ªGPUå’Œè¿æ¥GPUä¹‹é—´éƒ½èƒ½å¤Ÿä¿æŒè¶…ä½å»¶è¿Ÿçš„é€šè®¯ã€‚
æ­¤å¤–ï¼ŒNVSwitchè¿˜èƒ½å¤Ÿæ”¯æŒæœ€æ–°çš„DGX-2æŠ€æœ¯ï¼Œç›¸æ¯”äºä¹‹å‰çš„DGX-1æŠ€æœ¯ï¼ŒDGX-2æé€Ÿèƒ½å¤Ÿè¾¾åˆ°10å€ä»¥ä¸Šï¼Œé€Ÿç‡å¤§å¤§æå‡ã€‚

### 4. [InfiniBand](https://baike.baidu.com/item/Infiniband)

InfiniBandï¼ˆç›´è¯‘ä¸ºâ€œæ— é™å¸¦å®½â€æŠ€æœ¯ï¼Œç¼©å†™ä¸ºIBï¼‰æ˜¯**ä¸€ä¸ªç”¨äºé«˜æ€§èƒ½è®¡ç®—çš„è®¡ç®—æœºç½‘ç»œé€šä¿¡æ ‡å‡†**ï¼Œå®ƒå…·æœ‰æé«˜çš„ååé‡å’Œæä½çš„å»¶è¿Ÿï¼Œç”¨äºè®¡ç®—æœºä¸è®¡ç®—æœºä¹‹é—´çš„æ•°æ®äº’è¿ã€‚InfiniBandä¹Ÿç”¨ä½œæœåŠ¡å™¨ä¸å­˜å‚¨ç³»ç»Ÿä¹‹é—´çš„ç›´æ¥æˆ–äº¤æ¢äº’è¿ï¼Œä»¥åŠå­˜å‚¨ç³»ç»Ÿä¹‹é—´çš„äº’è¿ã€‚
InfiniBandæŠ€æœ¯ä¸æ˜¯ç”¨äºä¸€èˆ¬ç½‘ç»œè¿æ¥çš„ï¼Œå®ƒçš„ä¸»è¦è®¾è®¡ç›®çš„æ˜¯é’ˆå¯¹æœåŠ¡å™¨ç«¯çš„è¿æ¥é—®é¢˜çš„ã€‚å› æ­¤ï¼ŒInfiniBandæŠ€æœ¯å°†ä¼šè¢«åº”ç”¨äºæœåŠ¡å™¨ä¸æœåŠ¡å™¨ï¼ˆæ¯”å¦‚å¤åˆ¶ï¼Œåˆ†å¸ƒå¼å·¥ä½œç­‰ï¼‰ï¼ŒæœåŠ¡å™¨å’Œå­˜å‚¨è®¾å¤‡ï¼ˆæ¯”å¦‚SANå’Œç›´æ¥å­˜å‚¨é™„ä»¶ï¼‰ä»¥åŠæœåŠ¡å™¨å’Œç½‘ç»œä¹‹é—´ï¼ˆæ¯”å¦‚LANï¼Œ WANså’Œthe Internetï¼‰çš„é€šä¿¡ã€‚

### 5. [PCIEâ€”>NVLinkâ€”>NVSwitch](https://www.nvidia.com/zh-tw/data-center/nvlink/)

åœ¨2018å¹´gtcä¼šè®®ä¸Šï¼Œè€é»„å…¬å¼€äº†dgx-2ï¼Œè¿™å°å”®ä»·é«˜è¾¾399kç¾å…ƒï¼Œé‡è¾¾350ç£…çš„æ€ªå…½æ˜¯ä¸“é—¨ä¸ºäº†åŠ é€Ÿaiè´Ÿè½½è€Œç ”åˆ¶çš„ï¼Œä»–è¢«æˆäºˆäº†â€œä¸–ç•Œæœ€å¤§çš„gpuâ€ç§°å·ã€‚ä¸ºä»€ä¹ˆå®ƒè¢«èµ‹äºˆè¿™ä¸ªåå­—ï¼Œå®ƒåˆæ˜¯å¦‚ä½•äº§ç”Ÿçš„ï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ—¶é—´å€’é€€åˆ°å‡ å¹´ä¹‹å‰ã€‚

#### 5.1 PCIE Switch

åœ¨nvidiaæ¨å‡ºç›®å‰è¿™ä¸ªæ–¹æ¡ˆä¹‹å‰ï¼Œä¸ºäº†è·å¾—æ›´å¤šçš„å¼ºåŠ›è®¡ç®—èŠ‚ç‚¹ï¼Œå¤šä¸ªGPUé€šè¿‡PCIe Switchç›´æ¥ä¸CPUç›¸è¿ã€‚

![img](imgs/01.png)

ä»–ä»¬ä¹‹é—´çš„pcie 3.0*16æœ‰æ¥è¿‘32GB/sçš„åŒå‘å¸¦å®½ï¼Œä½†æ˜¯å½“è®­ç»ƒæ•°æ®ä¸åœå¢é•¿çš„æ—¶å€™ï¼Œè¿™ä¸ªäº’è”æ–¹æ¡ˆæœ¬èº«å´æˆä¸ºäº†è‡´å‘½çš„ç³»ç»Ÿç“¶é¢ˆã€‚å¦‚æœä¸æ”¹è¿›è¿™ä¸ªäº’è”å¸¦å®½ï¼Œé‚£ä¹ˆæ–°æ—¶ä»£GPUå¸¦æ¥çš„é¢å¤–æ€§èƒ½å°±æ²¡æ³•å‘æŒ¥å‡ºæ¥ï¼Œä»è€Œæ— æ³•æ»¡è¶³ç°å®éœ€æ±‚è´Ÿè½½çš„å¢é•¿ã€‚

ä½¿ç”¨   `nvidia-smi topo -m`   æŸ¥çœ‹GPUæ‹“æ‰‘ç»“æ„ã€‚



#### 5.2 NVLink

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œnvidiaå¼€å‘äº†ä¸€ä¸ªå…¨æ–°çš„äº’è”æ„æ¶nvlinkã€‚å•æ¡nvlinkæ˜¯ä¸€ç§åŒå·¥åŒè·¯ä¿¡é“ï¼Œå…¶é€šè¿‡ç»„åˆ32æ¡é…çº¿ï¼Œä»è€Œåœ¨æ¯ä¸ªæ–¹å‘ä¸Šå¯ä»¥äº§ç”Ÿ8å¯¹ä¸åŒçš„é…å¯¹ï¼ˆ2bi\*8pair\*2wire=32wireï¼‰ï¼Œç¬¬ä¸€ç‰ˆçš„å®ç°è¢«ç§°ä¸ºnvlink 1.0ï¼Œä¸P100 GPUä¸€åŒå‘å¸ƒã€‚ä¸€å—P100ä¸Šï¼Œé›†æˆäº†4æ¡nvlinkã€‚æ¯æ¡linkå…·å¤‡åŒè·¯å…±40GB/sçš„å¸¦å®½ï¼Œæ•´ä¸ªèŠ¯ç‰‡å…·å¤‡æ•´æ•´160GB/sçš„å¸¦å®½ã€‚ 



![img](imgs/02.png)

å½“ç„¶ï¼Œnvlinkä¸ä»…ä»…åªæ˜¯é™å®šåœ¨GPUä¹‹é—´äº’è”ä¸Šã€‚IBMå°†nvlink 1.0æ·»åŠ åˆ°ä»–ä»¬åŸºäºPower8+å¾®æ¶æ„çš„Powerå¤„ç†å™¨ä¸Šï¼Œè¿™ä¸€ä¸¾æªä½¿å¾—P100å¯ä»¥ç›´æ¥é€šè¿‡nvlinkäºCPUç›¸è¿ï¼Œè€Œæ— éœ€é€šè¿‡pcieã€‚é€šè¿‡ä¸æœ€è¿‘çš„power8+ cpuç›¸è¿ï¼Œ4GPUçš„èŠ‚ç‚¹å¯ä»¥é…ç½®æˆä¸€ç§å…¨è¿æ¥çš„meshç»“æ„ã€‚



![img](imgs/03.png)



#### 5.3 DGX-1

ç¬¬ä¸€ç§nvidiaä¸“é—¨ä¸ºAIåŠ é€Ÿè®¢åˆ¶çš„æœºå™¨å«åšdgx1ï¼Œå®ƒé›†æˆäº†å…«å—p100ä¸ä¸¤å—å¿—å¼ºe5 2698v4,ä½†æ˜¯å› ä¸ºæ¯å—GPUåªæœ‰4è·¯nvlinkï¼Œè¿™äº›GPUæ„æˆäº†ä¸€ç§æ··åˆçš„cube-meshç½‘ç»œæ‹“æ‰‘ç»“æ„ï¼ŒGPUè¢«4å—4å—åˆ†ä¸ºä¸¤ç»„ï¼Œç„¶ååœ¨äº’ç›¸è¿æ¥ã€‚

![img](imgs/04.png)


åŒæ—¶ï¼Œå› ä¸ºGPUéœ€è¦çš„pcieé€šé“æ•°é‡è¶…è¿‡äº†èŠ¯ç‰‡ç»„æ‰€èƒ½æä¾›çš„æ•°é‡ï¼Œæ‰€ä»¥æ¯ä¸€å¯¹GPUå°†è¿æ¥åˆ°ä¸€ç»„pcie switchä¸Šä¸å¿—å¼ºç›¸è¿ï¼Œç„¶åä¸¤å—å¿—å¼ºå†é€šè¿‡qpiæ€»çº¿è¿æ¥ã€‚

![img](imgs/05.png)


6å—P100ï¼Œæ¯å—16GB HBM2æ˜¾å­˜ï¼Œæ€»è®¡128GBæ˜¾å­˜å’Œ512GB DDR4-2133ç³»ç»Ÿå†…å­˜ã€‚

#### 5.4.nvlink 2.0

nvlinkçš„ç¬¬äºŒä¸ªç‰ˆæœ¬ä¸gv100ä¸€åŒè€Œæ¥ã€‚IBMè®¡åˆ’åœ¨Power9 cpuä¸Šç»™ä¸æ”¯æŒã€‚nvlink 2.0æå‡äº†ä¿¡å·çš„ä¼ è¾“ç‡ï¼Œä»20Gb/såˆ°äº†25Gb/sï¼ŒåŒä¿¡é“æ€»è®¡50GB/sï¼Œpre nvlinkã€‚åŒæ—¶è¿›ä¸€æ­¥æå‡äº†nvlinkæ•°åˆ°6è·¯ã€‚è¿™äº›ä¸¾æªè®©v100çš„æ€»å¸¦å®½ä»p100çš„160GB/sæå‡åˆ°äº†300GB/sã€‚

é¡ºä¾¿è¯´ä¸‹ï¼Œé™¤äº†å¸¦å®½çš„å¢é•¿ï¼Œnvidiaè¿˜æ·»åŠ äº†æ•°ä¸ªæ–°çš„operational featureåˆ°åè®®æœ¬èº«ã€‚å…¶ä¸­æœ€æœ‰æ„æ€çš„ä¸€ä¸ªç‰¹æ€§æ˜¯å¼•å…¥äº†coherency operationç¼“å­˜ä¸€è‡´æ€§æ“ä½œï¼Œå®ƒå…è®¸CPUåœ¨è¯»å–æ•°æ®æ—¶ç¼“å­˜GPUæ˜¾å­˜ä¿¡å·ï¼Œè¿™å°†æå¤§çš„é™ä½è®¿é—®å»¶è¿Ÿã€‚

å»å¹´nvidiaå°†åŸå§‹dgx-1å‡çº§åˆ°v100æ¶æ„ã€‚å› ä¸ºä¸»è¦çš„cube-meshæ‹“æ‰‘ç»“æ„å¹¶æ²¡æœ‰å˜åŒ–ï¼Œæ‰€ä»¥å¤šå‡ºæ¥çš„linkç”¨æ¥å€åŒ–ä¸€äº›GPUä¹‹é—´çš„äº’è”ã€‚

![img](imgs/06.png)



#### 5.5 DGX-2

æœ€è¿‘çš„GTC2018å‘å¸ƒçš„dgx-2ï¼Œå…¶åŠ å€äº†v100çš„æ•°é‡ï¼Œæœ€ç»ˆé«˜è¾¾16å—v100ã€‚åŒæ—¶hbm2å‡çº§åˆ°32GB/å—ï¼Œä¸€å…±é«˜è¾¾512GBï¼Œcpuå‡çº§ä¸ºåŒè·¯2.7G 24æ ¸ å¿—å¼ºç™½é‡‘8168.

![img](imgs/08.png)

å‡çº§åˆ°16å—GPUï¼Œå¯¹äºç³»ç»Ÿè€Œè¨€ä¹Ÿè¦åšå‡ºå·¨å¤§çš„æ”¹å˜ï¼Œç‰¹åˆ«æ˜¯æ›´å¿«æ›´å¤§çš„äº’è”ç½‘ç»œå¸¦å®½ã€‚

#### 5.6 NVSwitch

é‚£ä¹ˆdgx-2ä¸­è£…è½½çš„æ˜¯ä»€ä¹ˆå‘¢ï¼Œæ˜¯ä¸€å—æ–°çš„asic - nvswitchã€‚nvswitchæ˜¯ä¸€å—ç‹¬ç«‹çš„nvlinkèŠ¯ç‰‡ï¼Œå…¶æä¾›äº†é«˜è¾¾18è·¯nvlinkçš„æ¥å£ã€‚è¿™å—èŠ¯ç‰‡æ®è¯´å·²ç»å¼€å‘äº†ä¸¤å¹´ä¹‹ä¹…ã€‚å…¶æ”¯æŒnvlink 2.0ï¼Œä¹Ÿå°±æ„å‘³ç€æ¯ä¸ªæ¥å£å‡èƒ½æä¾›åŒä¿¡é“é«˜è¾¾50GB/sçš„å¸¦å®½ï¼Œé‚£ä¹ˆè¿™å—èŠ¯ç‰‡æ€»è®¡èƒ½å¤Ÿæä¾›900GB/sçš„å¸¦å®½ã€‚è¿™å—èŠ¯ç‰‡åŠŸç‡100wï¼ŒåŸºäºå°ç§¯ç”µ12nm FinFet FFN nvidiaè®¢åˆ¶å·¥è‰ºï¼Œæ¥æºäºå¢å¼ºçš„16nmèŠ‚ç‚¹ï¼Œæ‹¥æœ‰2bä¸ªæ™¶ä½“ç®¡ã€‚



![img](imgs/09.png)


è¿™å—dieå°è£…åœ¨1940ä¸ªpinå¤§å°ä¸º4cm2çš„BGAèŠ¯ç‰‡ä¸­ï¼Œå…¶ä¸­576ä¸ªé’ˆè„šä¸“é—¨æœåŠ¡äº18è·¯çš„nvlinkï¼Œå‰©ä¸‹çš„é˜µè„šåˆ™ç”¨äºç”µæºï¼Œæˆ–è€…å…¶ä»–I/Oæ¥å£ï¼Œæ¯”å¦‚ç”¨äºç®¡ç†ç«¯å£çš„x4 pcieï¼ŒI2cï¼ŒGPIOç­‰ç­‰ã€‚

![img](imgs/10.png)



é€šè¿‡nvswitchæä¾›çš„18è·¯æ¥å£ï¼Œnvswitchèƒ½å¤Ÿè®©nvidiaè®¾è®¡å‡ºå®Œå…¨æ— é˜»å¡çš„å…¨äº’è”16è·¯GPUç³»ç»Ÿã€‚æ¯å—v100ä¸­çš„6è·¯nvlinkå°†åˆ†åˆ«è¿æ¥åˆ°6å—nvswitchä¸Šé¢ã€‚è¿™æ ·8å—v100ä¸6å—nvsiwtchå®Œå…¨è¿æ¥ï¼Œæ„æˆä¸€ä¸ªåŸºæ¿ã€‚

![img](imgs/11.png)



dgx2æ‹¥æœ‰ä¸¤å—åŸºæ¿ï¼Œè¿™ä¸¤å—åŸºæ¿åˆ™æ˜¯é€šè¿‡nvswitchå‰©ä½™çš„å¦ä¸€ä¾§æ¥å£å®Œå…¨äº’è”åœ¨ä¸€èµ·ï¼Œè¿™å°±æ„æˆäº†ä¸€ä¸ª16è·¯å…¨è¿æ¥çš„GPUæ„æ¶.
![img](imgs/12.png)


ä¸¤å—åŸºæ¿ä¹‹é—´çš„nvswitchä¹‹é—´éƒ½æœ‰å…«è·¯linkäº’è”ï¼Œ16å—GPUæ¯å—æœ‰6è·¯nvlinkçš„æƒ…å†µä¸‹ï¼Œå…¶æ€»åŒè·¯å¸¦å®½è¾¾åˆ°2400GB/sã€‚æœ‰è¶£çš„æ˜¯ï¼Œå…¶å®nvswitchæœ‰18è·¯æ¥å£nvidiaå´åªç”¨åˆ°äº†å…¶ä¸­16è·¯ã€‚ä¸€ç§å¯èƒ½æ€§æ˜¯nvç•™ä¸‹ä¸¤è·¯ç”¨äºæ”¯æŒibmçš„power9å¤„ç†å™¨ï¼ˆdgx1å’Œ2éƒ½æ˜¯ç”¨çš„å¿—å¼ºï¼‰ã€‚åœ¨è¿™ä¸ªå¤æ‚çš„ç»“æ„ä¸­ï¼Œpower9å¤„ç†å™¨å¯èƒ½åˆ†åˆ«æ¥åœ¨ä¸¤å—åŸºæ¿çš„nvsiwtchä¸Šï¼Œè¿™æ ·GPUä¹Ÿä¸Power9å¤„äºå…¨è¿æ¥çŠ¶æ€ã€‚å¦‚æœCPUç›´æ¥ä¸nvswitchç›¸è¿ï¼Œé‚£ä¹ˆpcieå°±ä¸å†æ‹…ä»»cpuä¸gpuç›¸è¿çš„è´£ä»»ã€‚ç›®å‰nvidiaè¿˜æ²¡æœ‰å‘å…¶ä»–å‚å•†å¼€æ”¾nvswitchï¼Œå¦‚æœä»–ä»¬å†³å®šå¼€æ”¾ï¼Œå°†ä¼šäº§ç”Ÿä¸€äº›æ–°å‹æ€çš„ï¼Œå¯èƒ½æ›´åŠ è§„æ¨¡åºå¤§çš„ç»“ç®—èŠ‚ç‚¹ã€‚



![img](imgs/13.png)


åœ¨åŸå§‹çš„dgx-1ä¸­ï¼Œæ‰§è¡ŒGPUä¹‹é—´çš„äº‹åŠ¡å¤„ç†éœ€è¦ä¸€ä¸ªé¢å¤–çš„hopï¼Œè¿™å°†å¯¼è‡´è¿œç¨‹è®¿é—®çš„ä¸ä¸€è‡´æ€§ã€‚åœ¨å¾ˆå¤šè´Ÿè½½ä¸­ï¼Œè¿™ä¼šè®©åˆ©ç”¨ç»Ÿä¸€å¯»å€å˜å¾—å›°éš¾ï¼Œäº§ç”Ÿäº†ä¸€äº›ä¸ç¡®å®šæ€§ã€‚åœ¨dgx2ä¸­ï¼Œæ¯ä¸€å—gpuéƒ½å¯ä»¥äºå¦å¤–ä¸€å—gpuä»¥ç›¸åŒçš„é€Ÿåº¦å’Œä¸€è‡´æ€§å»¶è¿Ÿäº¤æµã€‚å¤§å‹çš„AIè´Ÿè½½èƒ½å¤Ÿé€šè¿‡å¹¶è¡ŒåŒ–çš„æ¨¡å‹æŠ€æœ¯å¾—åˆ°å·¨å¤§çš„æå‡ã€‚å›åˆ°GTCä¸­ï¼Œnvidiaèµ‹äºˆçš„åç§°â€œä¸–ç•Œæœ€å¤§çš„GPUâ€ã€‚åœ¨å®è·µä¸­ï¼Œå› ä¸ºæ¯å—GPUå’Œå…¶ä»–ä¼™ä¼´ç›´æ¥äº’è”ï¼Œç»Ÿä¸€å¯»å€ä¹Ÿå˜çš„ç®€å•æœ‰æ•ˆã€‚ç°åœ¨ï¼Œå¯ä»¥åˆå¹¶512GiBé«˜é€Ÿå¸¦å®½çš„æ˜¾å­˜ï¼Œå°†ä»–è™šæ‹ŸåŒ–æˆä¸€å—ç»Ÿä¸€çš„å†…å­˜ã€‚æ— è®ºæ˜¯GPUæœ¬èº«è¿˜æ˜¯nvswitchéƒ½æœ‰ç›¸åº”çš„ç®—æ³•ç”¨äºå®ç°è¿™ä¸€ç»Ÿä¸€çš„å†…å­˜ç³»ç»Ÿã€‚åœ¨ç¨‹åºå±‚é¢ï¼Œæ•´å°æœºå™¨å°†ä¼šè¢«å½“ä½œä¸€å—GPUå’Œä¸€ä¸ªæ•´ä½“çš„æ˜¾å­˜ï¼Œè¿™ä¸ªæ˜¾å­˜å­ç³»ç»Ÿå°†ä¼šè‡ªè¡Œç®¡ç†æ˜¾å­˜layoutï¼Œæä¾›æœ€ä¼˜åŒ–çš„ç»„ç»‡æ¶æ„ã€‚



### 6. æµ…æGPUé€šä¿¡æŠ€æœ¯GPUDirect

#### **6.1 èƒŒæ™¯**

GPUåœ¨é«˜æ€§èƒ½è®¡ç®—å’Œæ·±åº¦å­¦ä¹ åŠ é€Ÿä¸­æ‰®æ¼”ç€éå¸¸é‡è¦çš„è§’è‰²ï¼Œ GPUçš„å¼ºå¤§çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼Œå¤§å¤§æå‡äº†è¿ç®—æ€§èƒ½ã€‚éšç€è¿ç®—æ•°æ®é‡çš„ä¸æ–­æ”€å‡ï¼ŒGPUé—´éœ€è¦å¤§é‡çš„äº¤æ¢æ•°æ®ï¼ŒGPUé€šä¿¡æ€§èƒ½æˆä¸ºäº†éå¸¸é‡è¦çš„æŒ‡æ ‡ã€‚

![img](imgs/154.png)


![img](imgs/155.png)



NVIDIAæ¨å‡ºçš„GPUDirectå°±æ˜¯ä¸€ç»„æå‡GPUé€šä¿¡æ€§èƒ½çš„æŠ€æœ¯ã€‚ä½†GPUDirectå—é™äºPCI Expresssæ€»çº¿åè®®ä»¥åŠæ‹“æ‰‘ç»“æ„çš„ä¸€äº›é™åˆ¶ï¼Œæ— æ³•åšåˆ°æ›´é«˜çš„å¸¦å®½ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒNVIDIAæå‡ºäº†NVLinkæ€»çº¿åè®®ã€‚

è¿™ä¸ªç³»åˆ—æ–‡ç« ä¼šå¯¹ä»¥ä¸ŠGPUé€šä¿¡æŠ€æœ¯åšè¯¦ç»†çš„ä»‹ç»ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…æ›´å¥½çš„åˆ©ç”¨è¿™äº›æŠ€æœ¯å¯¹è‡ªå·±çš„åº”ç”¨åšç›¸åº”çš„ä¼˜åŒ–ã€‚

æœ¬ç¯‡æ–‡ç« ä¼šå…ˆä»‹ç»ä¸€ä¸‹GPUDirectæŠ€æœ¯ï¼Œå¹¶ç€é‡ä»‹ç»GPUDirect Peer-to-Peer(P2P)æŠ€æœ¯ã€‚

**GPUDirectä»‹ç»**

#### 6.2 ç®€ä»‹

GPUDirectæŠ€æœ¯æœ‰å¦‚ä¸‹å‡ ä¸ªå…³é”®ç‰¹æ€§ï¼š

- åŠ é€Ÿä¸ç½‘ç»œå’Œå­˜å‚¨è®¾å¤‡çš„é€šä¿¡ï¼š
- GPUä¹‹é—´çš„Peer-to-Peer Transers
- GPUä¹‹é—´çš„Peer-to-Peer memory access
- RDMAæ”¯æŒ
- é’ˆå¯¹Videoçš„ä¼˜åŒ–

ä¸‹é¢å¯¹æœ€ä¸»è¦çš„å‡ ä¸ªæŠ€æœ¯åšåˆ†åˆ«ä»‹ç»ã€‚

#### 6.3 Shared Memory

2010å¹´6æœˆæœ€å…ˆå¼•å…¥çš„æ˜¯GPUDirect Shared Memory æŠ€æœ¯ï¼Œæ”¯æŒGPUä¸ç¬¬ä¸‰æ–¹PCI Expressè®¾å¤‡é€šè¿‡å…±äº«çš„pinä½çš„host memoryå®ç°å…±äº«å†…å­˜è®¿é—®ä»è€ŒåŠ é€Ÿé€šä¿¡ã€‚

![image-20210728143713708](imgs/image-20210728143713708.png)

#### 6.4 P2P

2011å¹´ï¼ŒGPUDirectå¢åŠ äº†ç›¸åŒPCI Express root complex ä¸‹çš„GPUä¹‹é—´çš„Peer to Peer(P2P) Direct Accesså’ŒDirect Transersçš„æ”¯æŒã€‚

![img](imgs/157.png)



#### 6.5 RDMA

2013å¹´ï¼ŒGPUDirectå¢åŠ äº†RDMAæ”¯æŒï¼Œä½¿å¾—ç¬¬ä¸‰æ–¹PCI Expressè®¾å¤‡å¯ä»¥bypass CPU host memoryç›´æ¥è®¿é—®GPUã€‚



![img](imgs/158.png)



### 7. GPUDirect P2P

#### 7.1 P2Pç®€ä»‹

GPUDirect Peer-to-Peer(P2P) æŠ€æœ¯ä¸»è¦ç”¨äºå•æœºGPUé—´çš„é«˜é€Ÿé€šä¿¡ï¼Œå®ƒä½¿å¾—GPUå¯ä»¥é€šè¿‡PCI Expressç›´æ¥è®¿é—®ç›®æ ‡GPUçš„æ˜¾å­˜ï¼Œé¿å…äº†é€šè¿‡æ‹·è´åˆ°CPU host memoryä½œä¸ºä¸­è½¬ï¼Œå¤§å¤§é™ä½äº†æ•°æ®äº¤æ¢çš„å»¶è¿Ÿã€‚

ä»¥æ·±åº¦å­¦ä¹ åº”ç”¨ä¸ºä¾‹ï¼Œä¸»æµçš„å¼€æºæ·±åº¦å­¦ä¹ æ¡†æ¶å¦‚TensorFlowã€MXNetéƒ½æä¾›äº†å¯¹GPUDirect P2Pçš„æ”¯æŒï¼ŒNVIDIAå¼€å‘çš„NCCL(NVIDIA Collective Communications Library)ä¹Ÿæä¾›äº†é’ˆå¯¹GPUDirect P2Pçš„ç‰¹åˆ«ä¼˜åŒ–ã€‚

é€šè¿‡ä½¿ç”¨GPUDirect P2PæŠ€æœ¯å¯ä»¥å¤§å¤§æå‡æ·±åº¦å­¦ä¹ åº”ç”¨å•æœºå¤šå¡çš„æ‰©å±•æ€§ï¼Œä½¿å¾—æ·±åº¦å­¦ä¹ æ¡†æ¶å¯ä»¥è·å¾—æ¥è¿‘çº¿æ€§çš„è®­ç»ƒæ€§èƒ½åŠ é€Ÿæ¯”ã€‚



![img](imgs/159.png)

#### 7.2 P2Pè™šæ‹ŸåŒ–

éšç€äº‘è®¡ç®—çš„æ™®åŠï¼Œè¶Šæ¥è¶Šå¤šæŠ€æœ¯è¿ç§»åˆ°äº‘ä¸Šï¼Œåœ¨äº‘ä¸Šä½¿ç”¨GPUDirectæŠ€æœ¯ï¼Œå°±è¦è§£å†³GPUDirectè™šæ‹ŸåŒ–çš„é—®é¢˜ã€‚

è¿™é‡Œæˆ‘ä»¬ç€é‡è®¨è®ºä¸‹GPUDirect Peer-to-Peerè™šæ‹ŸåŒ–çš„é—®é¢˜

ä½¿ç”¨PCI Pass-throughè™šæ‹ŸåŒ–æŠ€æœ¯å¯ä»¥å°†GPUè®¾å¤‡çš„æ§åˆ¶æƒå®Œå…¨æˆæƒç»™VMï¼Œä½¿å¾—è™šæ‹Ÿæœºé‡Œçš„GPU driverå¯ä»¥ç›´æ¥æ§åˆ¶GPUè€Œä¸éœ€è¦Hypervisorå‚ä¸ï¼Œæ€§èƒ½å¯ä»¥æ¥è¿‘ç‰©ç†æœºã€‚

ä½†æ˜¯åŒä¸€ä¸ªè™šæ‹Ÿæœºå†…çš„åº”ç”¨å´æ— æ³•ä½¿ç”¨P2PæŠ€æœ¯ä¸å…¶å®ƒGPUå®ç°é€šä¿¡ã€‚ä¸‹é¢åˆ†æä¸€ä¸‹æ— æ³•ä½¿ç”¨P2Pçš„åŸå› ã€‚

é¦–å…ˆæˆ‘ä»¬éœ€è¦çŸ¥é“ä¸€ä¸ªæŠ€æœ¯é™åˆ¶ï¼Œå°±æ˜¯ä¸åœ¨åŒä¸€ä¸ªIntel IOH(IO Hub)èŠ¯ç‰‡ç»„ä¸‹é¢PCI-e P2Pé€šä¿¡æ˜¯ä¸æ”¯æŒçš„ï¼Œå› ä¸ºIntel CPUä¹‹é—´æ˜¯QPIåè®®é€šä¿¡ï¼ŒPCI-e P2Pé€šä¿¡æ˜¯æ— æ³•è·¨QPIåè®®çš„ã€‚æ‰€ä»¥GPU driverå¿…é¡»è¦çŸ¥é“GPUçš„PCIæ‹“ä¿¡æ¯ï¼ŒåŒä¸€ä¸ªIOHèŠ¯ç‰‡ç»„ä¸‹é¢çš„GPUæ‰èƒ½ä½¿èƒ½GPUDiret P2Pã€‚

ä½†æ˜¯åœ¨è™šæ‹ŸåŒ–ç¯å¢ƒä¸‹ï¼ŒHypervisorè™šæ‹Ÿçš„PCI Expressæ‹“æ‰‘ç»“æ„æ˜¯æ‰å¹³çš„ï¼ŒGPU driveræ— æ³•åˆ¤æ–­çœŸå®çš„ç¡¬ä»¶æ‹“æ‰‘æ‰€ä»¥æ— æ³•å¼€å¯GPUDirect P2Pã€‚

ä¸ºäº†è®©GPU driverè·å–åˆ°çœŸå®çš„GPUæ‹“æ‰‘ç»“æ„ï¼Œéœ€è¦åœ¨Hypervisoræ¨¡æ‹Ÿçš„GPU PCIé…ç½®ç©ºé—´é‡Œå¢åŠ ä¸€ä¸ªPCI Capabilityï¼Œç”¨äºæ ‡è®°GPUçš„P2Päº²å’Œæ€§ã€‚è¿™æ ·GPU driverå°±å¯ä»¥æ ¹æ®è¿™ä¸ªä¿¡æ¯æ¥ä½¿èƒ½P2Pã€‚

å¦å¤–å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨PCI Pass-throughæ—¶ï¼Œæ‰€æœ‰çš„PCI Expressé€šä¿¡éƒ½ä¼šè¢«è·¯ç”±åˆ°IOMMUï¼ŒP2Pé€šä¿¡åŒæ ·ä¹Ÿéœ€è¦è·¯ç”±åˆ°IOMMUï¼Œæ‰€ä»¥Pass-throughä¸‹çš„P2Pè·¯å¾„è¿˜æ˜¯ä¼šæ¯”ç‰©ç†æœºP2Pé•¿ä¸€ç‚¹ï¼Œå»¶è¿Ÿå¤§ä¸€ç‚¹ã€‚

#### 7.3 å®æµ‹

ä¸‹é¢æ˜¯æˆ‘ä»¬åœ¨é˜¿é‡Œäº‘GN5å®ä¾‹(8å¡Tesla P100)ä¸Šå¯¹GPUDirect P2På»¶è¿Ÿåšçš„å®æµ‹æ•°æ®ã€‚

GPU P2PçŸ©é˜µå¦‚ä¸‹ï¼š
`nvidia-smi topo -p2p n`
æˆ–è€…ç”¨CUDASampleé‡Œé¢çš„äº‹ä¾‹ã€‚

![img](imgs/160.png)



**ä½¿ç”¨CUDA Sampleä¸­çš„æ¡ˆä¾‹æ¥æµ‹è¯•**



é€šä¿¡å»¶è¿Ÿå¯¹æ¯”å¦‚ä¸‹ï¼š



![img](imgs/161.png)




æˆ‘ä»¬çœ‹åˆ°ï¼šä½¿èƒ½GPUDirect P2PåGPUé—´é€šä¿¡å»¶è¿Ÿç›¸æ¯”CPUæ‹·è´é™ä½è¿‘ä¸€åŠã€‚

ä¸‹å›¾æ˜¯åœ¨GN5å®ä¾‹ä¸Šä½¿ç”¨MXNetå¯¹ç»å…¸å·ç§¯ç¥ç»ç½‘ç»œçš„å›¾åƒåˆ†ç±»ä»»åŠ¡çš„è®­ç»ƒæ€§èƒ½çš„åŠ é€Ÿæ¯”ï¼š



![img](imgs/162.png)


MXNetåœ¨æ”¯æŒP2Pçš„GN5å®ä¾‹ä¸Šæœ‰éå¸¸å¥½çš„å•æœºæ‰©å±•æ€§ï¼Œè®­ç»ƒæ€§èƒ½æ¥è¿‘çº¿æ€§åŠ é€Ÿã€‚

### 8.æµ…æGPUé€šä¿¡æŠ€æœ¯ï¼šNVLinkæ€»çº¿æŠ€æœ¯

#### 8.1 èƒŒæ™¯

ä¸Šä¸€ç¯‡æ–‡ç« â€œæµ…æGPUé€šä¿¡æŠ€æœ¯ï¼šGPUDirect P2Pâ€ä¸­æˆ‘ä»¬æåˆ°é€šè¿‡GPUDirect P2PæŠ€æœ¯å¯ä»¥å¤§å¤§æå‡GPUæœåŠ¡å™¨å•æœºçš„GPUé€šä¿¡æ€§èƒ½ï¼Œä½†æ˜¯å—é™äºPCI Expresssæ€»çº¿åè®®ä»¥åŠæ‹“æ‰‘ç»“æ„çš„ä¸€äº›é™åˆ¶ï¼Œæ— æ³•åšåˆ°æ›´é«˜çš„å¸¦å®½ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒNVIDIAæå‡ºäº†NVLinkæ€»çº¿åè®®ã€‚

æœ¬ç¯‡æ–‡ç« æˆ‘ä»¬å°±æ¥è°ˆè°ˆNVIDIAæå‡ºçš„NVLinkæ€»çº¿åè®®ï¼Œçœ‹çœ‹å®ƒåˆ°åº•æ˜¯ä½•æ–¹ç¥åœ£ã€‚

#### 8.2. NVlinkä»‹ç»

#####  å‘å¸ƒ

NVLinkæŠ€æœ¯æ˜¯åœ¨2014å¹´3æœˆçš„NVIDIA GTC 2014ä¸Šå‘å¸ƒçš„ã€‚å¯¹æ™®é€šæ¶ˆè´¹è€…æ¥è¯´ï¼Œè¿™ä¸€å±Šçš„GTCä¼¼ä¹æ²¡æœ‰å¤ªå¤šçš„äº®ç‚¹ï¼Œä¹Ÿæ²¡æœ‰ä»€ä¹ˆé©å‘½æ€§çš„äº§å“å‘å¸ƒã€‚è¿™æ¬¡GTCä¸Šï¼Œé»„ä»å‹‹å±•ç¤ºäº†æ–°ä¸€ä»£å•å¡åŒèŠ¯å¡çš‡GeForce Titan Zï¼Œä¸‹ä¸€ä»£GPUæ¶æ„Pascalä¹Ÿåªæ˜¯åˆéœ²å³¥åµ˜ã€‚åœ¨é»„ä»å‹‹æ¼”è®²ä¸­åªç”¨å¤§çº¦äº”å…­é¡µPPTä»‹ç»çš„NVLinkä¹Ÿå¾ˆå®¹æ˜“è¢«æ™®é€šæ¶ˆè´¹è€…å¿½è§†ï¼Œä½†æ˜¯æœ‰å¿ƒçš„ä¸“ä¸šäººå£«ç¡®ä»æ­¤ä¸¾çœ‹åˆ°äº†NVIDIAèƒŒåå·¨å¤§çš„é‡å¿ƒã€‚

é¦–å…ˆæˆ‘ä»¬ç®€å•çœ‹ä¸‹NVIDIAå¯¹NVLinkçš„ä»‹ç»ï¼šNVLinkèƒ½åœ¨å¤šGPUä¹‹é—´å’ŒGPUä¸CPUä¹‹é—´å®ç°éå‡¡çš„è¿æ¥å¸¦å®½ã€‚å¸¦å®½æœ‰å¤šå¤§ï¼Ÿ2016å‘å¸ƒçš„P100æ˜¯æ­è½½NVLinkçš„ç¬¬ä¸€æ¬¾äº§å“ï¼Œå•ä¸ªGPUå…·æœ‰160GB/sçš„å¸¦å®½ï¼Œç›¸å½“äºPCIe Gen3 * 16å¸¦å®½çš„5å€ã€‚å»å¹´GTC 2017ä¸Šå‘å¸ƒçš„V100æ­è½½çš„NVLink 2.0æ›´æ˜¯å°†GPUå¸¦å®½æå‡åˆ°äº†300G/sï¼Œå·®ä¸å¤šæ˜¯PCIeçš„10å€äº†ã€‚

å¥½äº†ï¼Œè¿™ä¸‹æ˜ç™½äº†ä¸ºä»€ä¹ˆNVIDIAçš„NVLinkä¼šå¦‚æ­¤çš„å¼•äººæ³¨æ„äº†ã€‚ä½†æ˜¯NVLinkèƒŒåçš„å¸ƒå±€è¿œä¸åªæ˜¯å¦‚æ­¤ã€‚

##### è§£è¯»

æˆ‘ä»¬æ¥çœ‹çœ‹NVLinkå‡ºç°ä¹‹å‰çš„ç°çŠ¶ï¼š

**1)PCIeï¼š**

PCIe Gen3æ¯ä¸ªé€šé“ï¼ˆæ¯ä¸ªLaneï¼‰çš„åŒå‘å¸¦å®½æ˜¯2B/sï¼ŒGPUä¸€èˆ¬æ˜¯16ä¸ªLaneçš„PCIeè¿æ¥ï¼Œæ‰€ä»¥PCIeè¿æ¥çš„GPUé€šä¿¡åŒå‘å¸¦å®½å¯ä»¥è¾¾åˆ°32GB/sï¼Œè¦çŸ¥é“PCIeæ€»çº¿å ªç§°PCç³»ç»Ÿä¸­ç¬¬äºŒå¿«çš„è®¾å¤‡é—´æ€»çº¿ï¼ˆæ’åç¬¬ä¸€çš„æ˜¯å†…å­˜æ€»çº¿ï¼‰ã€‚ä½†æ˜¯åœ¨NVLink 300GB/sçš„å¸¦å®½é¢å‰ï¼Œåªæœ‰è¢«ç¢¾å‹çš„ä»½å„¿ã€‚

**2)æ˜¾å­˜å¸¦å®½ï¼š**

ä¸Šä¸€ä»£å¡çš‡Geforce Titan XPçš„GDDR5Xæ˜¾å­˜å¸¦å®½å·²ç»è¾¾åˆ°547.7 GB/sï¼Œæ­è½½HBM2æ˜¾å­˜çš„V100çš„å¸¦å®½ç”šè‡³è¾¾åˆ°äº†900GB/sã€‚æ˜¾å¡æ ¸å¿ƒå’Œæ˜¾å­˜ä¹‹é—´çš„æ•°æ®äº¤æ¢é€šé“å·²ç»è¾¾åˆ°å¦‚æ­¤é«˜çš„å¸¦å®½ï¼Œä½†æ˜¯GPUä¹‹é—´ä»¥åŠGPUå’ŒCPUä¹‹é—´çš„æ•°æ®äº¤æ¢ç¡®å—åˆ°PCIeæ€»çº¿çš„å½±å“ï¼Œæˆä¸ºäº†ç“¶é¢ˆã€‚è¿™å½“ç„¶ä¸æ˜¯NVIDIAå¸Œæœ›çœ‹åˆ°çš„ï¼Œè€ŒNVLinkçš„å‡ºç°ï¼Œåˆ™æ˜¯NVIDIAæƒ³æ‰“ç ´è¿™ä¸ªç“¶é¢ˆçš„å®£è¨€ã€‚

**3ï¼‰CPUè¿æ¥ï¼š**

å®é™…ä¸Šï¼ŒNVLinkä¸ä½†å¯ä»¥å®ç°GPUä¹‹é—´ä»¥åŠGPUå’ŒCPUä¹‹é—´çš„äº’è”ï¼Œè¿˜å¯ä»¥å®ç°CPUä¹‹é—´çš„äº’è”ã€‚ä»è¿™ä¸€ç‚¹æ¥çœ‹ï¼ŒNVLinkçš„é‡å¿ƒç€å®ä¸å°ã€‚

æˆ‘ä»¬çŸ¥é“ï¼ŒIntelçš„CPUé—´äº’è”æ€»çº¿æ˜¯QPIï¼Œ20ä½å®½çš„QPIè¿æ¥å¸¦å®½ä¹Ÿåªæœ‰25.6GB/sï¼Œåœ¨NVLinké¢å‰åŒæ ·å·®è·å·¨å¤§ã€‚å¯æƒ³è€ŒçŸ¥ï¼Œå¦‚æœå…¨éƒ¨é‡‡ç”¨NVLinkæ€»çº¿äº’è”ï¼Œä¼šå¯¹ç³»ç»Ÿæ•°æ®äº¤æ¢é€šé“çš„å¸¦å®½æœ‰å¤šå¤§æå‡ã€‚

å½“ç„¶ï¼ŒNVIDIAè‡ªå·±å¹¶æ²¡æœ‰CPUï¼ŒX86ä»ç„¶æ˜¯å½“ä»ŠCPUçš„ä¸»æµæ¶æ„ï¼Œè¢«IntelæŠŠæŒæ–¹å‘å’Œè¶‹åŠ¿ï¼ŒNVLinkç»æ²¡æœ‰å¯èƒ½è¿›å…¥X86 CPUè¿æ¥æ€»çº¿çš„é˜µè¥ã€‚äºæ˜¯ä¾¿æœ‰äº†NVIDIAå’ŒIBMç»„æˆçš„OpenPowerè”ç›Ÿã€‚

NVIDIAæ˜¯å—åˆ¶äºæ²¡æœ‰CPUï¼Œè€ŒIBMåˆ™æ°å¥½ç›¸åï¼ŒIBMæœ‰è‡ªå·±çš„CPUï¼ŒPower å¤„ç†å™¨çš„æ€§èƒ½æƒŠè‰³ï¼Œä½†IBMç¼ºå°‘ç›¸åº”çš„å¹¶è¡Œè®¡ç®—èŠ¯ç‰‡ï¼Œå› æ­¤ä»…ä»…ä¾é è‡ªå·±çš„CPUï¼Œå¾ˆéš¾åœ¨ç›®å‰çš„å¼‚æ„è®¡ç®—ä¸­å‘æŒ¥å‡ºä¼˜ç§€çš„æ€§èƒ½ã€è§„æ¨¡å’Œæ€§èƒ½åŠŸè€—æ¯”ä¼˜åŠ¿ã€‚ä»è¿™ä¸€ç‚¹æ¥çœ‹ï¼ŒIBMå’ŒNVIDIAäº’è¡¥æ€§å°±éå¸¸å¼ºäº†ï¼Œè¿™ä¹Ÿæ˜¯IBMä¸ºä»€ä¹ˆè¦å’ŒNVIDIAç»„å»ºOpenPowerè¶…çº§è®¡ç®—è”ç›Ÿçš„åŸå› äº†ã€‚

è€ƒè™‘åˆ°ç›®å‰POWERç”Ÿæ€çš„é€æ¸èç¼©ï¼Œè¦æƒ³åœ¨äººå·¥æ™ºèƒ½æµªæ½®ä¸‹è¶æœºæŠ¢å X86çš„å¸‚åœºå¹¶ä¸æ˜¯ä»¶å®¹æ˜“çš„äº‹æƒ…ï¼Œä½†è‡³å°‘ç»™äº†NVIDIAå…¨é¢æŠ—è¡¡Intelçš„å¹³å°ã€‚

æ‰€ä»¥æœ‰ç‚¹æ‰¯è¿œäº†ï¼ŒNVLinkç›®å‰æ›´ä¸»è¦çš„è¿˜æ˜¯å¤§å¤§æå‡äº†GPUé—´é€šä¿¡çš„å¸¦å®½ã€‚

##### ç»“æ„å’Œæ‹“æ‰‘

**NVLinkä¿¡å·ä¸åè®®**

NVLinkæ§åˆ¶å™¨ç”±3å±‚ç»„æˆï¼Œå³ç‰©ç†å±‚ï¼ˆPHYï¼‰ã€æ•°æ®é“¾è·¯å±‚ï¼ˆDLï¼‰ä»¥åŠäº¤æ˜“å±‚ï¼ˆTLï¼‰ã€‚ä¸‹å›¾å±•ç¤ºäº†P100 NVLink 1.0çš„å„å±‚å’Œé“¾è·¯ï¼š

![img](imgs/163.png)




P100æ­è½½çš„NVLink 1.0ï¼Œæ¯ä¸ªP100æœ‰4ä¸ªNVLinké€šé“ï¼Œæ¯ä¸ªæ‹¥æœ‰40GB/sçš„åŒå‘å¸¦å®½ï¼Œæ¯ä¸ªP100å¯ä»¥æœ€å¤§è¾¾åˆ°160GB/så¸¦å®½ã€‚

V100æ­è½½çš„NVLink 2.0ï¼Œæ¯ä¸ªV100å¢åŠ äº†50%çš„NVLinké€šé“è¾¾åˆ°6ä¸ªï¼Œä¿¡å·é€Ÿåº¦æå‡28%ä½¿å¾—æ¯ä¸ªé€šé“è¾¾åˆ°50Gçš„åŒå‘å¸¦å®½ï¼Œå› è€Œæ¯ä¸ªV100å¯ä»¥æœ€å¤§è¾¾åˆ°300GB/sçš„å¸¦å®½ã€‚

**æ‹“æ‰‘**

ä¸‹å›¾æ˜¯HGX-1/DGX-1ä½¿ç”¨çš„8ä¸ªV100çš„æ··åˆç«‹æ–¹ç½‘æ ¼æ‹“æ‰‘ç»“æ„ï¼Œæˆ‘ä»¬çœ‹åˆ°è™½ç„¶V100æœ‰6ä¸ªNVlinké€šé“ï¼Œä½†æ˜¯å®é™…ä¸Šå› ä¸ºæ— æ³•åšåˆ°å…¨è¿æ¥ï¼Œ2ä¸ªGPUé—´æœ€å¤šåªèƒ½æœ‰2ä¸ªNVLinké€šé“100G/sçš„åŒå‘å¸¦å®½ã€‚è€ŒGPUä¸CPUé—´é€šä¿¡ä»ç„¶ä½¿ç”¨PCIeæ€»çº¿ã€‚CPUé—´é€šä¿¡ä½¿ç”¨QPIæ€»çº¿ã€‚è¿™ä¸ªæ‹“æ‰‘è™½ç„¶æœ‰ä¸€å®šå±€é™æ€§ï¼Œä½†ä¾ç„¶å¤§å¹…æå‡äº†åŒä¸€CPU Nodeå’Œè·¨CPU Nodeçš„GPUé—´é€šä¿¡å¸¦å®½ã€‚

![img](imgs/164.png)


**NVSwitch**

ä¸ºäº†è§£å†³æ··åˆç«‹æ–¹ç½‘æ ¼æ‹“æ‰‘ç»“æ„çš„é—®é¢˜ï¼ŒNVIDIAåœ¨ä»Šå¹´GTC 2018ä¸Šå‘å¸ƒäº†NVSwitchã€‚

ç±»ä¼¼äºPCIeä½¿ç”¨PCIe Switchç”¨äºæ‹“æ‰‘çš„æ‰©å±•ï¼ŒNVIDIAä½¿ç”¨NVSwitchå®ç°äº†NVLinkçš„å…¨è¿æ¥ã€‚NVSwitchä½œä¸ºé¦–æ¬¾èŠ‚ç‚¹äº¤æ¢æ¶æ„ï¼Œå¯æ”¯æŒå•ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹ä¸­ 16 ä¸ªå…¨äº’è”çš„ GPUï¼Œå¹¶å¯ä½¿å…¨éƒ¨ 8 ä¸ª GPU å¯¹åˆ†åˆ«ä»¥ 300 GB/s çš„æƒŠäººé€Ÿåº¦è¿›è¡ŒåŒæ—¶é€šä¿¡ã€‚è¿™ 16 ä¸ªå…¨äº’è”çš„ GPU ï¼ˆ32Gæ˜¾å­˜V100ï¼‰è¿˜å¯ä½œä¸ºå•ä¸ªå¤§å‹åŠ é€Ÿå™¨ï¼Œæ‹¥æœ‰ 0.5 TB ç»Ÿä¸€æ˜¾å­˜ç©ºé—´å’Œ 2 PetaFLOPS è®¡ç®—æ€§èƒ½ã€‚

å…³äºNVSwitchçš„ç›¸å…³æŠ€æœ¯ç»†èŠ‚å¯ä»¥å‚è€ƒNVIDIAå®˜æ–¹æŠ€æœ¯æ–‡æ¡£ã€‚åº”è¯¥è¯´è¿™ä¸€æŠ€æœ¯çš„å¼•å…¥ï¼Œä½¿å¾—GPUé—´é€šä¿¡çš„å¸¦å®½åˆå¤§å¤§ä¸Šäº†ä¸€ä¸ªå°é˜¶ã€‚

#### 8.3 æ€§èƒ½

NVIDIA NVLink å°†é‡‡ç”¨ç›¸åŒé…ç½®çš„æœåŠ¡å™¨æ€§èƒ½æé«˜ 31%ã€‚

![img](imgs/165.png)


ä½¿ç”¨NVSwitchçš„DGX-2åˆ™èƒ½å¤Ÿè¾¾åˆ°2å€ä»¥ä¸Šçš„æ·±åº¦å­¦ä¹ å’Œé«˜æ€§èƒ½è®¡ç®—çš„åŠ é€Ÿã€‚

![img](imgs/166.png)



### 9.æµ…æGPUé€šä¿¡æŠ€æœ¯ï¼šGPUDirect RDMA

#### 9.1 èƒŒæ™¯

å‰ä¸¤ç¯‡æ–‡ç« æˆ‘ä»¬ä»‹ç»çš„GPUDirect P2På’ŒNVLinkæŠ€æœ¯å¯ä»¥å¤§å¤§æå‡GPUæœåŠ¡å™¨å•æœºçš„GPUé€šä¿¡æ€§èƒ½ï¼Œå½“å‰æ·±åº¦å­¦ä¹ æ¨¡å‹è¶Šæ¥è¶Šå¤æ‚ï¼Œè®¡ç®—æ•°æ®é‡æš´å¢ï¼Œå¯¹äºå¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒä»»åŠ¡ï¼Œå•æœºå·²ç»æ— æ³•æ»¡è¶³è®¡ç®—è¦æ±‚ï¼Œå¤šæœºå¤šå¡çš„åˆ†å¸ƒå¼è®­ç»ƒæˆä¸ºäº†å¿…è¦çš„éœ€æ±‚ï¼Œè¿™ä¸ªæ—¶å€™å¤šæœºé—´çš„é€šä¿¡æˆä¸ºäº†åˆ†å¸ƒå¼è®­ç»ƒæ€§èƒ½çš„é‡è¦æŒ‡æ ‡ã€‚

æœ¬ç¯‡æ–‡ç« æˆ‘ä»¬å°±æ¥è°ˆè°ˆGPUDirect RDMAæŠ€æœ¯ï¼Œè¿™æ˜¯ç”¨äºåŠ é€Ÿå¤šæœºé—´GPUé€šä¿¡çš„æŠ€æœ¯ã€‚

#### 9.2 RDMAä»‹ç»

æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹RDMAæŠ€æœ¯æ˜¯ä»€ä¹ˆï¼ŸRDMAå³Remote DMAï¼Œæ˜¯Remote Direct Memory Accessçš„è‹±æ–‡ç¼©å†™ã€‚

##### DMAåŸç†

åœ¨ä»‹ç»RDMAä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥å¤ä¹ ä¸‹DMAæŠ€æœ¯ã€‚

æˆ‘ä»¬çŸ¥é“DMAï¼ˆç›´æ¥å†…å­˜è®¿é—®ï¼‰æŠ€æœ¯æ˜¯Offload CPUè´Ÿè½½çš„ä¸€é¡¹é‡è¦æŠ€æœ¯ã€‚DMAçš„å¼•å…¥ï¼Œä½¿å¾—åŸæ¥è®¾å¤‡å†…å­˜ä¸ç³»ç»Ÿå†…å­˜çš„æ•°æ®äº¤æ¢å¿…é¡»è¦CPUå‚ä¸ï¼Œå˜ä¸ºäº¤ç»™DMAæ§åˆ¶æ¥è¿›è¡Œæ•°æ®ä¼ è¾“ã€‚

ç›´æ¥å†…å­˜è®¿é—®(DMA)æ–¹å¼ï¼Œæ˜¯ä¸€ç§å®Œå…¨ç”±ç¡¬ä»¶æ‰§è¡ŒI/Oäº¤æ¢çš„å·¥ä½œæ–¹å¼ã€‚åœ¨è¿™ç§æ–¹å¼ä¸­ï¼Œ DMAæ§åˆ¶å™¨ä»CPUå®Œå…¨æ¥ç®¡å¯¹æ€»çº¿çš„æ§åˆ¶ï¼Œæ•°æ®äº¤æ¢ä¸ç»è¿‡CPUï¼Œè€Œç›´æ¥åœ¨å†…å­˜å’ŒIOè®¾å¤‡ä¹‹é—´è¿›è¡Œã€‚DMAå·¥ä½œæ—¶ï¼Œç”±DMA æ§åˆ¶å™¨å‘å†…å­˜å‘å‡ºåœ°å€å’Œæ§åˆ¶ä¿¡å·ï¼Œè¿›è¡Œåœ°å€ä¿®æ”¹ï¼Œå¯¹ä¼ é€å­—çš„ä¸ªæ•°è®¡æ•°ï¼Œå¹¶ä¸”ä»¥ä¸­æ–­æ–¹å¼å‘CPU æŠ¥å‘Šä¼ é€æ“ä½œçš„ç»“æŸã€‚

ä½¿ç”¨DMAæ–¹å¼çš„ç›®çš„æ˜¯å‡å°‘å¤§æ‰¹é‡æ•°æ®ä¼ è¾“æ—¶CPU çš„å¼€é”€ã€‚é‡‡ç”¨ä¸“ç”¨DMAæ§åˆ¶å™¨(DMAC) ç”Ÿæˆè®¿å­˜åœ°å€å¹¶æ§åˆ¶è®¿å­˜è¿‡ç¨‹ã€‚ä¼˜ç‚¹æœ‰æ“ä½œå‡ç”±ç¡¬ä»¶ç”µè·¯å®ç°ï¼Œä¼ è¾“é€Ÿåº¦å¿«ï¼›CPU åŸºæœ¬ä¸å¹²é¢„ï¼Œä»…åœ¨åˆå§‹åŒ–å’Œç»“æŸæ—¶å‚ä¸ï¼ŒCPUä¸å¤–è®¾å¹¶è¡Œå·¥ä½œï¼Œæ•ˆç‡é«˜ã€‚

##### RMDAåŸç†

RDMAåˆ™æ˜¯åœ¨è®¡ç®—æœºä¹‹é—´ç½‘ç»œæ•°æ®ä¼ è¾“æ—¶Offload CPUè´Ÿè½½çš„é«˜ååã€ä½å»¶æ—¶é€šä¿¡æŠ€æœ¯ã€‚



![img](imgs/167.png)


å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œä¼ ç»Ÿçš„TCP/IPåè®®ï¼Œåº”ç”¨ç¨‹åºéœ€è¦è¦ç»è¿‡å¤šå±‚å¤æ‚çš„åè®®æ ˆè§£æï¼Œæ‰èƒ½è·å–åˆ°ç½‘å¡ä¸­çš„æ•°æ®åŒ…ï¼Œè€Œä½¿ç”¨RDMAåè®®ï¼Œåº”ç”¨ç¨‹åºå¯ä»¥ç›´æ¥æ—è·¯å†…æ ¸è·å–åˆ°ç½‘å¡ä¸­çš„æ•°æ®åŒ…ã€‚

RDMAå¯ä»¥ç®€å•ç†è§£ä¸ºåˆ©ç”¨ç›¸å…³çš„ç¡¬ä»¶å’Œç½‘ç»œæŠ€æœ¯ï¼ŒæœåŠ¡å™¨1çš„ç½‘å¡å¯ä»¥ç›´æ¥è¯»å†™æœåŠ¡å™¨2çš„å†…å­˜ï¼Œæœ€ç»ˆè¾¾åˆ°é«˜å¸¦å®½ã€ä½å»¶è¿Ÿå’Œä½èµ„æºåˆ©ç”¨ç‡çš„æ•ˆæœã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåº”ç”¨ç¨‹åºä¸éœ€è¦å‚ä¸æ•°æ®ä¼ è¾“è¿‡ç¨‹ï¼Œåªéœ€è¦æŒ‡å®šå†…å­˜è¯»å†™åœ°å€ï¼Œå¼€å¯ä¼ è¾“å¹¶ç­‰å¾…ä¼ è¾“å®Œæˆå³å¯ã€‚

![img](imgs/168.png)


åœ¨å®ç°ä¸Šï¼ŒRDMAå®é™…ä¸Šæ˜¯ä¸€ç§æ™ºèƒ½ç½‘å¡ä¸è½¯ä»¶æ¶æ„å……åˆ†ä¼˜åŒ–çš„è¿œç«¯å†…å­˜ç›´æ¥é«˜é€Ÿè®¿é—®æŠ€æœ¯ï¼Œé€šè¿‡åœ¨ç½‘å¡ä¸Šå°†RDMAåè®®å›ºåŒ–äºç¡¬ä»¶ï¼Œä»¥åŠæ”¯æŒé›¶å¤åˆ¶ç½‘ç»œæŠ€æœ¯å’Œå†…æ ¸å†…å­˜æ—è·¯æŠ€æœ¯è¿™ä¸¤ç§é€”å¾„æ¥è¾¾åˆ°å…¶é«˜æ€§èƒ½çš„è¿œç¨‹ç›´æ¥æ•°æ®å­˜å–çš„ç›®æ ‡ã€‚

ï¼ˆ1ï¼‰é›¶å¤åˆ¶ï¼šé›¶å¤åˆ¶ç½‘ç»œæŠ€æœ¯ä½¿ç½‘å¡å¯ä»¥ç›´æ¥ä¸åº”ç”¨å†…å­˜ç›¸äº’ä¼ è¾“æ•°æ®ï¼Œä»è€Œæ¶ˆé™¤äº†åœ¨åº”ç”¨å†…å­˜ä¸å†…æ ¸ä¹‹é—´å¤åˆ¶æ•°æ®çš„éœ€è¦ã€‚å› æ­¤ï¼Œä¼ è¾“å»¶è¿Ÿä¼šæ˜¾è‘—å‡å°ã€‚

ï¼ˆ2ï¼‰å†…æ ¸æ—è·¯ï¼šå†…æ ¸åè®®æ ˆæ—è·¯æŠ€æœ¯ä½¿åº”ç”¨ç¨‹åºæ— éœ€æ‰§è¡Œå†…æ ¸å†…å­˜è°ƒç”¨å°±å¯å‘ç½‘å¡å‘é€å‘½ä»¤ã€‚åœ¨ä¸éœ€è¦ä»»ä½•å†…æ ¸å†…å­˜å‚ä¸çš„æ¡ä»¶ä¸‹ï¼ŒRDMAè¯·æ±‚ä»ç”¨æˆ·ç©ºé—´å‘é€åˆ°æœ¬åœ°ç½‘å¡å¹¶é€šè¿‡ç½‘ç»œå‘é€ç»™è¿œç¨‹ç½‘å¡ï¼Œè¿™å°±å‡å°‘äº†åœ¨å¤„ç†ç½‘ç»œä¼ è¾“æµæ—¶å†…æ ¸å†…å­˜ç©ºé—´ä¸ç”¨æˆ·ç©ºé—´ä¹‹é—´ç¯å¢ƒåˆ‡æ¢çš„æ¬¡æ•°ã€‚

åœ¨å…·ä½“çš„è¿œç¨‹å†…å­˜è¯»å†™ä¸­ï¼ŒRDMAæ“ä½œç”¨äºè¯»å†™æ“ä½œçš„è¿œç¨‹è™šæ‹Ÿå†…å­˜åœ°å€åŒ…å«åœ¨RDMAæ¶ˆæ¯ä¸­ä¼ é€ï¼Œè¿œç¨‹åº”ç”¨ç¨‹åºè¦åšçš„åªæ˜¯åœ¨å…¶æœ¬åœ°ç½‘å¡ä¸­æ³¨å†Œç›¸åº”çš„å†…å­˜ç¼“å†²åŒºã€‚è¿œç¨‹èŠ‚ç‚¹çš„CPUé™¤åœ¨è¿æ¥å»ºç«‹ã€æ³¨å†Œè°ƒç”¨ç­‰ä¹‹å¤–ï¼Œåœ¨æ•´ä¸ªRDMAæ•°æ®ä¼ è¾“è¿‡ç¨‹ä¸­å¹¶ä¸æä¾›æœåŠ¡ï¼Œå› æ­¤æ²¡æœ‰å¸¦æ¥ä»»ä½•è´Ÿè½½ã€‚

#### 9.3 RDMAå®ç°

å¦‚ä¸‹å›¾RMDAè½¯ä»¶æ ˆæ‰€ç¤ºï¼Œç›®å‰RDMAçš„å®ç°æ–¹å¼ä¸»è¦åˆ†ä¸ºInfiniBandå’ŒEthernetä¸¤ç§ä¼ è¾“ç½‘ç»œã€‚è€Œåœ¨ä»¥å¤ªç½‘ä¸Šï¼Œåˆå¯ä»¥æ ¹æ®ä¸ä»¥å¤ªç½‘èåˆçš„åè®®æ ˆçš„å·®å¼‚åˆ†ä¸ºiWARPå’ŒRoCEï¼ˆåŒ…æ‹¬RoCEv1å’ŒRoCEv2ï¼‰ã€‚
![img](imgs/169.png)



å…¶ä¸­ï¼ŒInfiniBandæ˜¯æœ€æ—©å®ç°RDMAçš„ç½‘ç»œåè®®ï¼Œè¢«å¹¿æ³›åº”ç”¨åˆ°é«˜æ€§èƒ½è®¡ç®—ä¸­ã€‚ä½†æ˜¯InfiniBandå’Œä¼ ç»ŸTCP/IPç½‘ç»œçš„å·®åˆ«éå¸¸å¤§ï¼Œéœ€è¦ä¸“ç”¨çš„ç¡¬ä»¶è®¾å¤‡ï¼Œæ‰¿æ‹…æ˜‚è´µçš„ä»·æ ¼ã€‚ç›¸æ¯”ä¹‹ä¸‹RoCEå’ŒiWARPçš„ç¡¬ä»¶æˆæœ¬åˆ™è¦ä½çš„å¤šã€‚

#### 9.4 GPUDirect RDMAä»‹ç»

##### **åŸç†**

æœ‰äº†å‰æ–‡RDMAçš„ä»‹ç»ï¼Œä»ä¸‹å›¾æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“æ˜ç™½ï¼Œæ‰€è°“GPUDirect RDMAï¼Œå°±æ˜¯è®¡ç®—æœº1çš„GPUå¯ä»¥ç›´æ¥è®¿é—®è®¡ç®—æœº2çš„GPUå†…å­˜ã€‚è€Œåœ¨æ²¡æœ‰è¿™é¡¹æŠ€æœ¯ä¹‹å‰ï¼ŒGPUéœ€è¦å…ˆå°†æ•°æ®ä»GPUå†…å­˜æ¬ç§»åˆ°ç³»ç»Ÿå†…å­˜ï¼Œç„¶åå†åˆ©ç”¨RDMAä¼ è¾“åˆ°è®¡ç®—æœº2ï¼Œè®¡ç®—æœº2çš„GPUè¿˜è¦åšä¸€æ¬¡æ•°æ®ä»ç³»ç»Ÿå†…å­˜åˆ°GPUå†…å­˜çš„æ¬ç§»åŠ¨ä½œã€‚GPUDirect RDMAæŠ€æœ¯ä½¿å¾—è¿›ä¸€æ­¥å‡å°‘äº†GPUé€šä¿¡çš„æ•°æ®å¤åˆ¶æ¬¡æ•°ï¼Œé€šä¿¡å»¶è¿Ÿè¿›ä¸€æ­¥é™ä½ã€‚

![img](imgs/170.png)

#####  ä½¿ç”¨

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¦æƒ³ä½¿ç”¨GPUDirect RDMAï¼Œéœ€è¦ä¿è¯GPUå¡å’ŒRDMAç½‘å¡åœ¨åŒä¸€ä¸ªROOT COMPLEXä¸‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
![img](imgs/171.png)



##### æ€§èƒ½

Mellanoxç½‘å¡å·²ç»æä¾›äº†GPUDirect RDMAçš„æ”¯æŒï¼ˆæ—¢æ”¯æŒInfiniBandä¼ è¾“ï¼Œä¹Ÿæ”¯æŒRoCEä¼ è¾“ï¼‰ã€‚

ä¸‹å›¾åˆ†åˆ«æ˜¯ä½¿ç”¨OSU micro-benchmarksåœ¨Mellanoxçš„InfiniBandç½‘å¡ä¸Šæµ‹è¯•çš„å»¶æ—¶å’Œå¸¦å®½æ•°æ®ï¼Œå¯ä»¥çœ‹åˆ°ä½¿ç”¨GPUDirect RDMAæŠ€æœ¯åå»¶æ—¶å¤§å¤§é™ä½ï¼Œå¸¦å®½åˆ™å¤§å¹…æå‡ï¼š

![img](imgs/17dgh3.png)



ä¸‹å›¾æ˜¯ä¸€ä¸ªå®é™…çš„é«˜æ€§èƒ½è®¡ç®—åº”ç”¨çš„æ€§èƒ½æ•°æ®ï¼ˆä½¿ç”¨HOOMDåšç²’å­åŠ¨æ€ä»¿çœŸï¼‰ï¼Œå¯ä»¥çœ‹åˆ°éšç€èŠ‚ç‚¹å¢å¤šï¼Œä½¿ç”¨GPUDirect RDMAæŠ€æœ¯çš„é›†ç¾¤çš„æ€§èƒ½æœ‰æ˜æ˜¾æå‡ï¼Œæœ€å¤šå¯ä»¥æå‡è‡³2å€ï¼š
![img](imgs/174.png)



## äºŒã€è½¯ä»¶ï¼ˆåº“ï¼‰å±‚æ¬¡

**å•æœºå¤šå¡**ï¼šNCCLï¼›Glooï¼›
**å¤šæœºå¤šå¡ï¼š**NCCL2.xï¼›MPIï¼›TCP/IPï¼›Glooï¼›

> **MPIã€Glooã€NCCL**
>
> ä½¿ç”¨PyTorché™„å¸¦çš„åç«¯ä¸ºä¾‹æ¥è®²è§£ä¸‰ç§æ–¹å¼
>
> ç›®å‰PyTorchåˆ†å‘ç‰ˆä»…æ”¯æŒLinuxã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒGlooå’ŒNCCLåç«¯æ„å»ºå¹¶åŒ…å«åœ¨PyTorchçš„åˆ†å¸ƒä¹‹ä¸­ï¼ˆä»…åœ¨ä½¿ç”¨CUDAæ„å»ºæ—¶ä¸ºNCCLï¼‰ã€‚MPIæ˜¯ä¸€ä¸ªå¯é€‰çš„åç«¯ï¼Œåªæœ‰ä»æºä»£ç æ„å»ºPyTorchæ—¶æ‰èƒ½åŒ…å«å®ƒã€‚ï¼ˆä¾‹å¦‚ï¼Œåœ¨å®‰è£…äº†MPIçš„ä¸»æœºä¸Šæ„å»ºPyTorchï¼‰
>
> **å“ªä¸ªåç«¯ä½¿ç”¨ï¼Ÿ**
>
> åœ¨è¿‡å»ï¼Œæˆ‘ä»¬ç»å¸¸è¢«é—®åˆ°ï¼šâ€œæˆ‘åº”è¯¥ä½¿ç”¨å“ªä¸ªåç«¯ï¼Ÿâ€ã€‚
>
> **ç»éªŒæ³•åˆ™**
>
> - ä½¿ç”¨NCCLåç«¯è¿›è¡Œåˆ†å¸ƒå¼ GPU è®­ç»ƒã€‚
> - ä½¿ç”¨Glooåç«¯è¿›è¡Œåˆ†å¸ƒå¼ CPU è®­ç»ƒã€‚
>
> **å…·æœ‰InfiniBandäº’è¿çš„GPUä¸»æœº**
>
> - ä½¿ç”¨NCCLï¼Œå› ä¸ºå®ƒæ˜¯ç›®å‰å”¯ä¸€æ”¯æŒInfiniBandå’ŒGPUDirectçš„åç«¯ã€‚
>
> **GPUä¸»æœºä¸ä»¥å¤ªç½‘äº’è¿**
>
> - ä½¿ç”¨NCCLï¼Œå› ä¸ºå®ƒç›®å‰æä¾›æœ€ä½³çš„åˆ†å¸ƒå¼GPUè®­ç»ƒæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤šè¿›ç¨‹å•èŠ‚ç‚¹æˆ–å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒã€‚å¦‚æœæ‚¨é‡åˆ°NCCLçš„ä»»ä½•é—®é¢˜ï¼Œè¯·ä½¿ç”¨Glooä½œä¸ºåå¤‡é€‰é¡¹ã€‚ï¼ˆè¯·æ³¨æ„ï¼ŒGlooç›®å‰è¿è¡Œé€Ÿåº¦æ¯”GPUçš„NCCLæ…¢ã€‚ï¼‰
>
> **å…·æœ‰InfiniBandäº’è¿çš„CPUä¸»æœº**
>
> - å¦‚æœæ‚¨çš„InfiniBandåœ¨IBä¸Šå·²å¯ç”¨IPï¼Œè¯·ä½¿ç”¨Glooï¼Œå¦åˆ™è¯·ä½¿ç”¨MPIã€‚æˆ‘ä»¬è®¡åˆ’åœ¨å³å°†å‘å¸ƒçš„ç‰ˆæœ¬ä¸­ä¸ºGlooæ·»åŠ InfiniBandæ”¯æŒã€‚
>
> **å…·æœ‰ä»¥å¤ªç½‘äº’è¿çš„CPUä¸»æœº**
>
> - é™¤éæ‚¨æœ‰ç‰¹æ®ŠåŸå› è¦ä½¿ç”¨MPIï¼Œå¦åˆ™è¯·ä½¿ç”¨Glooã€‚

### 1. NCCL

[å®˜ç½‘](https://developer.nvidia.com/nccl) || [å®‰è£…æ‰‹å†Œ](https://docs.nvidia.com/deeplearning/sdk/nccl-install-guide/index.html)||[ GitHub](https://github.com/NVIDIA/nccl)

#### 1.1 æ¦‚è¿°

NCCLæ˜¯Nvidia Collective multi-GPU Communication Libraryçš„ç®€ç§°ï¼Œå®ƒæ˜¯ä¸€ä¸ªå®ç°å¤šGPUçš„collective communicationé€šä¿¡ï¼ˆall-gather, reduce, broadcastï¼‰åº“ï¼ŒNvidiaåšäº†å¾ˆå¤šä¼˜åŒ–ï¼Œä»¥åœ¨PCIeã€Nvlinkã€InfiniBandä¸Šå®ç°è¾ƒé«˜çš„é€šä¿¡é€Ÿåº¦ã€‚

æ·±åº¦å­¦ä¹ æ¡†æ¶çš„å¼€å‘äººå‘˜å¯ä»¥ä¾èµ–NCCLé«˜åº¦ä¼˜åŒ–çš„MPIå…¼å®¹å’Œæ‹“æ‰‘æ„ŸçŸ¥ä¾‹ç¨‹ï¼Œä»¥å……åˆ†åˆ©ç”¨å¤šä¸ªèŠ‚ç‚¹å†…å’Œè·¨å¤šä¸ªèŠ‚ç‚¹çš„æ‰€æœ‰å¯ç”¨GPUã€‚é¢†å…ˆçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå¦‚æ¥è‡ªCaffeï¼ŒCaffe2ï¼ŒChainerï¼ŒMxNetï¼ŒTensorFlowå’ŒPyTorch é›†æˆäº†NCCLåŠ é€Ÿåœ¨å¤šGPUç³»ç»Ÿçš„æ·±åº¦å­¦ä¹ åŸ¹è®­ã€‚

ä¸‹é¢åˆ†åˆ«ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢æ¥ä»‹ç»NCCLçš„ç‰¹ç‚¹ï¼ŒåŒ…æ‹¬åŸºæœ¬çš„communication primitiveã€ring-base collectivesã€NCCLåœ¨å•æœºå¤šå¡ä¸Šä»¥åŠå¤šæœºå¤šå¡å®ç°ã€æœ€ååˆ†äº«å®é™…ä½¿ç”¨NCCLçš„ä¸€äº›ç»éªŒã€‚

#### 1.2 .communication primitive

å¹¶è¡Œä»»åŠ¡çš„é€šä¿¡ä¸€èˆ¬å¯ä»¥åˆ†ä¸ºPoint-to-point communicationå’ŒCollective communicationã€‚P2Pé€šä¿¡è¿™ç§æ¨¡å¼åªæœ‰ä¸€ä¸ªsenderå’Œä¸€ä¸ªreceiverï¼Œå®ç°èµ·æ¥æ¯”è¾ƒç®€å•ã€‚ç¬¬äºŒç§Collective communicationåŒ…å«å¤šä¸ªsenderå¤šä¸ªreceiverï¼Œä¸€èˆ¬çš„é€šä¿¡åŸè¯­åŒ…æ‹¬broadcastï¼Œgather,all-gather,scatter,reduce,all-reduce,reduce-scatter,all-to-allç­‰ã€‚ç®€å•ä»‹ç»å‡ ä¸ªå¸¸ç”¨çš„æ“ä½œï¼š

- Reduce
  ä»å¤šä¸ªsenderé‚£é‡Œæ¥æ”¶æ•°æ®ï¼Œæœ€ç»ˆcombineåˆ°ä¸€ä¸ªèŠ‚ç‚¹ä¸Šã€‚
  ![img](imgs/14.png)
- All-reduce
  ä»å¤šä¸ªsenderé‚£é‡Œæ¥æ”¶æ•°æ®ï¼Œæœ€ç»ˆcombineåˆ°æ¯ä¸€ä¸ªèŠ‚ç‚¹ä¸Šã€‚
  ![img](imgs/15.png)



è€Œä¼ ç»ŸCollective communicationå‡è®¾é€šä¿¡èŠ‚ç‚¹ç»„æˆçš„topologyæ˜¯ä¸€é¢—fat treeï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¿™æ ·é€šä¿¡æ•ˆç‡æœ€é«˜ã€‚ä½†å®é™…çš„é€šä¿¡topologyå¯èƒ½æ¯”è¾ƒå¤æ‚ï¼Œå¹¶ä¸æ˜¯ä¸€ä¸ªfat treeã€‚å› æ­¤ä¸€èˆ¬ç”¨ring-based Collective communicationã€‚

![img](imgs/48.png)



#### 1.3 ring-base collectives

ring-base collectiveså°†æ‰€æœ‰çš„é€šä¿¡èŠ‚ç‚¹é€šè¿‡é¦–å°¾è¿æ¥å½¢æˆä¸€ä¸ªå•å‘ç¯ï¼Œæ•°æ®åœ¨ç¯ä¸Šä¾æ¬¡ä¼ è¾“ã€‚ä»¥broadcastä¸ºä¾‹ï¼Œ å‡è®¾æœ‰4ä¸ªGPUï¼ŒGPU0ä¸ºsenderå°†ä¿¡æ¯å‘é€ç»™å‰©ä¸‹çš„GPUï¼ŒæŒ‰ç…§ç¯çš„æ–¹å¼ä¾æ¬¡ä¼ è¾“ï¼ŒGPU0-->GPU1-->GPU2-->GPU3ï¼Œè‹¥æ•°æ®é‡ä¸ºNï¼Œå¸¦å®½ä¸ºBï¼Œæ•´ä¸ªä¼ è¾“æ—¶é—´ä¸ºï¼ˆK-1ï¼‰N/Bã€‚æ—¶é—´éšç€èŠ‚ç‚¹æ•°çº¿æ€§å¢é•¿ï¼Œä¸æ˜¯å¾ˆé«˜æ•ˆã€‚

![img](imgs/16.png)


ä¸‹é¢æŠŠè¦ä¼ è¾“çš„æ•°æ®åˆ†æˆSä»½ï¼Œæ¯æ¬¡åªä¼ N/Sçš„æ•°æ®é‡ï¼Œä¼ è¾“è¿‡ç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š

![img](imgs/17.png)

GPU1æ¥æ”¶åˆ°GPU0çš„ä¸€ä»½æ•°æ®åï¼Œä¹Ÿæ¥ç€ä¼ åˆ°ç¯çš„ä¸‹ä¸ªèŠ‚ç‚¹ï¼Œè¿™æ ·ä»¥æ­¤ç±»æ¨ï¼Œæœ€åèŠ±çš„æ—¶é—´ä¸ºS*(N/S/B) + (k-2)*(N/S/B) = N(S+K-2)/(SB) --> N/Bï¼Œæ¡ä»¶æ˜¯Sè¿œå¤§äºKï¼Œå³æ•°æ®çš„ä»½æ•°å¤§äºèŠ‚ç‚¹æ•°ï¼Œè¿™ä¸ªå¾ˆå®¹æ˜“æ»¡è¶³ã€‚æ‰€ä»¥é€šä¿¡æ—¶é—´ä¸éšèŠ‚ç‚¹æ•°çš„å¢åŠ è€Œå¢åŠ ï¼Œåªå’Œæ•°æ®æ€»é‡ä»¥åŠå¸¦å®½æœ‰å…³ã€‚å…¶å®ƒé€šä¿¡æ“ä½œæ¯”å¦‚reduceã€gatherä»¥æ­¤ç±»æ¨ã€‚é‚£ä¹ˆåœ¨ä»¥GPUä¸ºé€šä¿¡èŠ‚ç‚¹çš„åœºæ™¯ä¸‹ï¼Œæ€ä¹ˆæ„å»ºé€šä¿¡ç¯å‘¢ï¼Ÿå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
å•æœº4å¡é€šè¿‡åŒä¸€ä¸ªPCIe switchæŒ‚è½½åœ¨ä¸€æ£µCPUçš„åœºæ™¯ï¼š



![img](imgs/18.png)

å•æœº8å¡é€šè¿‡ä¸¤ä¸ªCPUä¸‹ä¸åŒçš„PCIe switchæŒ‚è½½çš„åœºæ™¯ï¼š

![img](imgs/19.png)



#### 1.4 NCCLå®ç°

NCCLå®ç°æˆCUDA C++ kernelsï¼ŒåŒ…å«3ç§primitive operationsï¼š Copyï¼ŒReduceï¼ŒReduceAndCopyã€‚ç›®å‰NCCL 1.0ç‰ˆæœ¬åªæ”¯æŒå•æœºå¤šå¡ï¼Œå¡ä¹‹é—´é€šè¿‡PCIeã€NVlinkã€GPU Direct P2Pæ¥é€šä¿¡ã€‚NCCL 2.0ä¼šæ”¯æŒå¤šæœºå¤šå¡ï¼Œå¤šæœºé—´é€šè¿‡Sockets (Ethernet)æˆ–è€…InfiniBand with GPU Direct RDMAé€šä¿¡ã€‚
ä¸‹å›¾æ‰€ç¤ºï¼Œå•æœºå†…å¤šå¡é€šè¿‡PCIeä»¥åŠCPU socketé€šä¿¡ï¼Œå¤šæœºé€šè¿‡InfiniBandé€šä¿¡ã€‚ 

![img](imgs/20.png)

åŒæ ·ï¼Œåœ¨å¤šæœºå¤šå¡å†…éƒ¨ï¼Œä¹Ÿè¦æ„æˆä¸€ä¸ªé€šä¿¡ç¯

![img](imgs/21.png)

ä¸‹é¢æ˜¯å•æœº 4å¡ï¼ˆMaxwel GPUï¼‰ä¸Šå„ä¸ªæ“ä½œéšç€é€šä¿¡é‡å¢åŠ çš„å¸¦å®½é€Ÿåº¦å˜åŒ–ï¼Œå¯ä»¥çœ‹åˆ°å¸¦å®½ä¸Šé™èƒ½è¾¾åˆ°10GB/sï¼Œæ¥è¿‘PCIeçš„å¸¦å®½ã€‚



![img](imgs/22.png)

ä¸‹å›¾æ˜¯Allreduceåœ¨å•æœºä¸åŒæ¶æ„ä¸‹çš„é€Ÿåº¦æ¯”è¾ƒï¼š



![img](imgs/23.png)


å…ˆä¸çœ‹DGX-1æ¶æ„ï¼Œè¿™æ˜¯Nvidiaæ¨å‡ºçš„æ·±åº¦å­¦ä¹ å¹³å°ï¼Œå¸¦å®½èƒ½è¾¾åˆ°60GB/sã€‚å‰é¢ä¸‰ä¸ªæ˜¯å•æœºå¤šå¡å…¸å‹çš„ä¸‰ç§è¿æ¥æ–¹å¼ï¼Œç¬¬ä¸‰ç§æ˜¯å››å¼ å¡éƒ½åœ¨ä¸€ä¸ªPCIe switchä¸Šï¼Œæ‰€ä»¥å¸¦å®½è¾ƒé«˜ï¼Œèƒ½è¾¾åˆ°>10GB/s PCIeçš„å¸¦å®½å¤§å°ï¼Œç¬¬äºŒç§æ˜¯ä¸¤ä¸ªGPUé€šè¿‡switchç›¸è¿åå†ç»è¿‡CPUè¿æ¥ï¼Œé€Ÿåº¦ä¼šç¨å¾®ä½ä¸€ç‚¹ï¼Œç¬¬ä¸€ç§æ˜¯ä¸¤ä¸ªGPUé€šè¿‡CPUç„¶åé€šè¿‡QPIå’Œå¦ä¸€ä¸ªCPUä¸Šçš„ä¸¤å—å¡ç›¸è¿ï¼Œå› æ­¤é€Ÿåº¦æœ€æ…¢ï¼Œä½†ä¹Ÿèƒ½è¾¾åˆ°>5GB/sã€‚

ä¸‹å›¾æ˜¯Allreduceå¤šæœºä¸‹çš„é€Ÿåº¦è¡¨ç°ï¼Œå·¦å›¾ä¸¤æœº8å¡ï¼Œæœºå†…PCIeï¼Œæœºé—´InfiniBandèƒ½è¾¾åˆ°>10GB/sçš„é€Ÿåº¦ï¼ŒInfiniBandåŸºæœ¬ä¸Šèƒ½è¾¾åˆ°æœºå†…çš„é€šä¿¡é€Ÿåº¦ã€‚

![img](imgs/24.png)

ä¸‹å›¾æ˜¯NCCLåœ¨CNTK ResNet50ä¸Šçš„scalabilityï¼Œ32å¡åŸºæœ¬èƒ½è¾¾åˆ°çº¿æ€§åŠ é€Ÿæ¯”ã€‚



![img](imgs/25.png)



#### 1.5 æˆ‘ä»¬çš„å®æµ‹ç»éªŒ

é¦–å…ˆï¼Œåœ¨ä¸€å°K40 GPUçš„æœºå™¨ä¸Šæµ‹è¯•äº†GPUçš„è¿æ¥æ‹“æ‰‘ï¼Œå¦‚ä¸‹ï¼š

![img](imgs/26.png)

å¯ä»¥çœ‹åˆ°å‰å››å¡å’Œåå››å¡åˆ†åˆ«é€šè¿‡ä¸åŒçš„CPUç»„è¿æ¥ï¼ŒGPU0å’ŒGPU1ç›´æ¥é€šè¿‡PCIe switchç›¸è¿ï¼Œç„¶åç»è¿‡CPUä¸GPU2å’ŒGPU3ç›¸è¿ã€‚
ä¸‹é¢æ˜¯æµ‹è¯•PCIeçš„å¸¦å®½ï¼Œå¯ä»¥çœ‹åˆ°GPU0å’ŒGU1é€šä¿¡èƒ½è¾¾åˆ°10.59GB/sï¼ŒGPU0åŒGPU2~~3é€šä¿¡ç”±äºè¦ç»è¿‡CPUï¼Œé€Ÿåº¦ç¨æ…¢ï¼Œå’ŒGPU4~~7çš„é€šä¿¡éœ€è¦ç»è¿‡QPIï¼Œæ‰€ä»¥åˆæ…¢äº†ä¸€ç‚¹ï¼Œä½†ä¹Ÿèƒ½è¾¾åˆ°9.15GB/sã€‚



![img](imgs/27.png)


è€Œé€šè¿‡NVlinkè¿æ¥çš„GPUé€šä¿¡é€Ÿåº¦èƒ½è¾¾åˆ°35GB/sï¼š

![img](imgs/28.png)

NCCLåœ¨ä¸åŒçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆCNTK/Tensorflow/Torch/Theano/Caffeï¼‰ä¸­ï¼Œç”±äºä¸åŒçš„æ¨¡å‹å¤§å°ï¼Œè®¡ç®—çš„batch sizeå¤§å°ï¼Œä¼šæœ‰ä¸åŒçš„è¡¨ç°ã€‚æ¯”å¦‚ä¸Šå›¾ä¸­CNTKä¸­Resnet50èƒ½è¾¾åˆ°32å¡çº¿æ€§åŠ é€Ÿæ¯”ï¼ŒFacebookä¹‹å‰èƒ½ä¸€å°æ—¶è®­ç»ƒå‡ºImageNetï¼Œè€Œåœ¨NMTä»»åŠ¡ä¸­ï¼Œå¯èƒ½ä¸ä¼šæœ‰è¿™ä¹ˆå¤§çš„åŠ é€Ÿæ¯”ã€‚å› ä¸ºå½±å“å¹¶è¡Œè®¡ç®—æ•ˆç‡çš„å› ç´ ä¸»è¦æœ‰å¹¶è¡Œä»»åŠ¡æ•°ã€æ¯ä¸ªä»»åŠ¡çš„è®¡ç®—é‡ä»¥åŠé€šä¿¡æ—¶é—´ã€‚æˆ‘ä»¬ä¸ä»…è¦çœ‹ç»å¯¹çš„é€šä¿¡é‡ï¼Œä¹Ÿè¦çœ‹é€šä¿¡å’Œè®¡ç®—èƒ½ä¸èƒ½åŒæ—¶è¿›è¡Œä»¥åŠè®¡ç®—/é€šä¿¡æ¯”ï¼Œå¦‚æœé€šä¿¡å è®¡ç®—çš„æ¯”é‡è¶Šå°ï¼Œé‚£ä¹ˆå¹¶è¡Œè®¡ç®—çš„ä»»åŠ¡ä¼šè¶Šé«˜æ•ˆã€‚NMTæ¨¡å‹ä¸€èˆ¬è¾ƒå¤§ï¼Œå¤šå¤§å‡ åMä¸Šç™¾Mï¼Œä¸åƒç°åœ¨imageçš„æ¨¡å‹èƒ½åšåˆ°å‡ Må¤§å°ï¼Œé€šä¿¡æ‰€å æ¯”é‡ä¼šè¾ƒé«˜ã€‚
ä¸‹é¢æ˜¯NMTæ¨¡å‹å•æœºå¤šå¡åŠ é€Ÿçš„ä¸€ä¸ªç®€å•å¯¹æ¯”å›¾ï¼š



![img](imgs/29.png)

ä»¥ä¸Šå°±æ˜¯å¯¹NCCLçš„ä¸€äº›ç†è§£ï¼Œå¾ˆå¤šèµ„æ–™ä¹Ÿæ˜¯æ¥è‡ªäºNCCLçš„å®˜æ–¹æ–‡æ¡£ï¼Œæ¬¢è¿äº¤æµè®¨è®ºã€‚

#### 1.6 NCCL æ•…éšœæ’é™¤ 

[å®˜æ–¹API](https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html)    

##### 5. Troubleshooting  NCCL æ•…éšœæ’é™¤

Ensure you are familiar with the following known issues and useful debugging strategies.

**5.1. Errors**

NCCL calls may return a variety of return codes. Ensure that the return codes are always equal to ncclSuccess. If any call fails, and returns a value different from ncclSuccess, setting NCCL_DEBUG to WARN will make NCCL print an explicit warning message before returning the error.   
NCCLè°ƒç”¨å¯èƒ½ä¼šè¿”å›å„ç§è¿”å›ç ã€‚ ç¡®ä¿è¿”å›ç å§‹ç»ˆç­‰äºncclSuccessã€‚ å¦‚æœä»»ä½•è°ƒç”¨å¤±è´¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªä¸åŒäºncclSuccessçš„å€¼ï¼Œå°†NCCL_DEBUGè®¾ç½®ä¸º WARN å°†ä½¿NCCLåœ¨è¿”å›é”™è¯¯ä¹‹å‰æ‰“å°ä¸€ä¸ªæ˜ç¡®çš„è­¦å‘Šæ¶ˆæ¯ã€‚


Errors are grouped into different categories.

* ncclUnhandledCudaError and ncclSystemError indicate that a call to an external library failed.
* ncclInvalidArgument and ncclInvalidUsage indicates there was a programming error in the application using NCCL.

In either case, refer to the NCCL warning message to understand how to resolve the problem.
é”™è¯¯åˆ†ä¸ºä¸åŒçš„ç±»åˆ«ã€‚

* ncclUnhandledCudaError å’Œ ncclSystemError è¡¨ç¤ºå¯¹å¤–éƒ¨åº“çš„è°ƒç”¨å¤±è´¥ã€‚
* ncclInvalidArgument å’Œ ncclInvalidUsage æŒ‡ç¤ºä½¿ç”¨NCCLçš„åº”ç”¨ç¨‹åºä¸­å­˜åœ¨ç¼–ç¨‹é”™è¯¯ã€‚

æ— è®ºå“ªç§æƒ…å†µï¼Œè¯·å‚é˜…NCCLè­¦å‘Šæ¶ˆæ¯ä»¥äº†è§£å¦‚ä½•è§£å†³é—®é¢˜ã€‚

**5.2. Networking Issues ç½‘ç»œé—®é¢˜**

**5.2.1. IP Network Interfaces IP ç½‘ç»œæ¥å£**

NCCL auto-detects which network interfaces to use for inter-node communication. If some interfaces are in state up, however are not able to communicate between nodes, NCCL may try to use them anyway and therefore fail during the init functions or even hang.
For more information about how to specify which interfaces to use, see NCCL Knobs topic, particularly the NCCL_SOCKET_IFNAME knob.   
NCCLè‡ªåŠ¨æ£€æµ‹å“ªäº›ç½‘ç»œæ¥å£ç”¨äºèŠ‚ç‚¹é—´é€šä¿¡ã€‚ å¦‚æœæŸäº›æ¥å£å¤„äºupçŠ¶æ€ï¼Œä½†æ˜¯æ— æ³•åœ¨èŠ‚ç‚¹ä¹‹é—´è¿›è¡Œé€šä¿¡ï¼Œåˆ™NCCLå¯èƒ½ä¼šå°è¯•ä½¿ç”¨å®ƒä»¬ï¼Œä»è€Œåœ¨initå‡½æ•°æœŸé—´å¤±è´¥ç”šè‡³æŒ‚èµ·ã€‚   
æœ‰å…³å¦‚ä½•æŒ‡å®šè¦ä½¿ç”¨å“ªä¸ªæ¥å£çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… NCCL Knobs ä¸»é¢˜ï¼Œç‰¹åˆ«æ˜¯ NCCL_SOCKET_IFNAME æ—‹é’®ã€‚   

**5.2.2. InfiniBand**

Before running NCCL on InfiniBand, running low-level InfiniBand tests (and in particular the ib_write_bw test) can help verify which nodes are able to communicate properly.   
åœ¨InfiniBandä¸Šè¿è¡ŒNCCLä¹‹å‰ï¼Œè¿è¡Œä½çº§InfiniBandæµ‹è¯•ï¼ˆå°¤å…¶æ˜¯ib_write_bwæµ‹è¯•ï¼‰å¯ä»¥å¸®åŠ©éªŒè¯å“ªäº›èŠ‚ç‚¹èƒ½å¤Ÿæ­£å¸¸é€šä¿¡ã€‚

**5.3. Known Issues**

Ensure you are familiar with the following known issues:

**Sharing Data å…±äº«æ•°æ®**

In order to share data between ranks, NCCL may require shared system memory for IPC and pinned (page-locked) system memory resources. The operating systemâ€™s limits on these resources may need to be increased accordingly. Please see your systemâ€™s documentation for details. In particular, DockerÂ® containers default to limited shared and pinned memory resources. When using NCCL inside a container, it is recommended that you increase these resources by issuing:    
ä¸ºäº†åœ¨é˜Ÿåˆ—ä¹‹é—´å…±äº«æ•°æ®ï¼ŒNCCLå¯èƒ½éœ€è¦IPCçš„å…±äº«ç³»ç»Ÿå†…å­˜å’Œå›ºå®šï¼ˆé¡µé¢é”å®šï¼‰ç³»ç»Ÿå†…å­˜èµ„æºã€‚æ“ä½œç³»ç»Ÿå¯¹è¿™äº›èµ„æºçš„é™åˆ¶å¯èƒ½éœ€è¦ç›¸åº”çš„å¢åŠ ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ‚¨çš„ç³»ç»Ÿæ–‡æ¡£ã€‚ç‰¹åˆ«æ˜¯ï¼ŒDockerÂ®å®¹å™¨é»˜è®¤ä¸ºä½¿ç”¨æœ‰é™çš„å…±äº«å’Œå›ºå®šå†…å­˜èµ„æºã€‚åœ¨å®¹å™¨å†…ä½¿ç”¨NCCLæ—¶ï¼Œå»ºè®®æ‚¨é€šè¿‡ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¥å¢åŠ è¿™äº›èµ„æºï¼š
--shm-size=1g --ulimit memlock=-1
in the command line to
nvidia-docker run


Concurrency between NCCL and CUDA calls (NCCL up to 2.0.5 or CUDA 8) NCCLå’ŒCUDAè°ƒç”¨ä¹‹é—´çš„å¹¶å‘æ€§ï¼ˆNCCLç‰ˆæœ¬ä¸ä½äº2.0.5æˆ–CUDA 8ï¼‰
NCCL uses CUDA kernels to perform inter-GPU communication. The NCCL kernels synchronize with each other, therefore, each kernel requires other kernels on other GPUs to be also executed in order to complete. The application should therefore make sure that nothing prevents the NCCL kernels from being executed concurrently on the different devices of a NCCL communicator.    
NCCLä½¿ç”¨CUDAå†…æ ¸æ¥æ‰§è¡ŒGPUé—´é€šä¿¡ã€‚ NCCLå†…æ ¸å½¼æ­¤åŒæ­¥ï¼Œå› æ­¤ï¼Œæ¯ä¸ªå†…æ ¸éƒ½éœ€è¦å…¶ä»–GPUä¸Šçš„å†…æ ¸ä¹Ÿæ‰§è¡Œæ‰èƒ½å®Œæˆã€‚å› æ­¤ï¼Œåº”ç”¨ç¨‹åºåº”è¯¥ç¡®ä¿æ²¡æœ‰é˜»æ­¢åœ¨NCCLé€šä¿¡å™¨çš„ä¸åŒè®¾å¤‡ä¸ŠåŒæ—¶æ‰§è¡ŒNCCLå†…æ ¸ã€‚

For example, let's say you have a process managing multiple CUDA devices, and, also features a thread which calls CUDA functions asynchronously. In this case, CUDA calls could be executed between the enqueuing of two NCCL kernels. The CUDA call may wait for the first NCCL kernel to complete and prevent the second one from being launched, causing a deadlock since the first kernel will not complete until the second one is executed. To avoid this issue, one solution is to have a lock around the NCCL launch on multiple devices (around ncclGroupStart and ncclGroupEnd when using a single thread, around the NCCL launch when using multiple threads, using thread synchronization if necessary) and take this lock when calling CUDA from the asynchronous thread.   
ä¾‹å¦‚ï¼Œå‡è®¾æ‚¨æœ‰ä¸€ä¸ªç®¡ç†å¤šä¸ªCUDAè®¾å¤‡çš„è¿›ç¨‹ï¼Œå¹¶ä¸”è¿˜å…·æœ‰ä¸€ä¸ªå¼‚æ­¥è°ƒç”¨CUDAå‡½æ•°çš„çº¿ç¨‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥åœ¨æ’é˜Ÿçš„ä¸¤ä¸ªNCCLå†…æ ¸ä¹‹é—´æ‰§è¡ŒCUDAè°ƒç”¨ã€‚ CUDAè°ƒç”¨å¯èƒ½ä¼šç­‰å¾…ç¬¬ä¸€ä¸ªNCCLå†…æ ¸å®Œæˆï¼Œå¹¶é˜»æ­¢ç¬¬äºŒä¸ªå†…æ ¸å¯åŠ¨ï¼Œä»è€Œå¯¼è‡´æ­»é”ï¼Œå› ä¸ºç›´åˆ°æ‰§è¡Œç¬¬äºŒä¸ªå†…æ ¸ï¼Œç¬¬ä¸€ä¸ªå†…æ ¸æ‰ä¼šå®Œæˆã€‚ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯é”å®šå¤šä¸ªè®¾å¤‡ä¸Šçš„NCCLå¯åŠ¨ï¼ˆå½“ä½¿ç”¨å•ä¸ªçº¿ç¨‹æ—¶å›´ç»•ncclGroupStartå’ŒncclGroupEndï¼Œåœ¨ä½¿ç”¨å¤šä¸ªçº¿ç¨‹æ—¶å›´ç»•NCCL launchï¼Œå¿…è¦æ—¶ä½¿ç”¨çº¿ç¨‹åŒæ­¥ï¼‰ï¼Œå¹¶åœ¨è°ƒç”¨å¼‚æ­¥çº¿ç¨‹ä¸­çš„CUDAæ—¶ï¼Œä½¿ç”¨æ­¤é”ã€‚

Starting with NCCL 2.1.0, this issue is no longer present when using CUDA 9, unless Cooperative Group Launch is disabled in the NCCL_LAUNCH_MODE = PARALLEL setting.    
ä»NCCL 2.1.0å¼€å§‹ï¼Œä½¿ç”¨CUDA 9æ—¶ï¼Œæ­¤é—®é¢˜ä¸å†å­˜åœ¨ï¼Œé™¤éåœ¨NCCL_LAUNCH_MODE = PARALLELè®¾ç½®ä¸­ç¦ç”¨äº†â€œåˆä½œç»„å¯åŠ¨â€ã€‚

**5.4. NCCL Knobs**

A knob isa type of environment variable that can you can turn on or off by settingspecific values. These environment variables should be set in the context ofrunning NCCL. The following table lists all of the available knobs thatcan be modified in NCCL.    
æ—‹é’®æ˜¯ä¸€ç§ç¯å¢ƒå˜é‡ï¼Œå¯ä»¥é€šè¿‡è®¾ç½®ç‰¹å®šçš„å€¼æ¥æ‰“å¼€æˆ–å…³é—­ã€‚ è¿™äº›ç¯å¢ƒå˜é‡åº”è¯¥åœ¨è¿è¡ŒNCCLçš„ç¯å¢ƒä¸­è¿›è¡Œè®¾ç½®ã€‚ ä¸‹è¡¨åˆ—å‡ºäº†æ‰€æœ‰å¯åœ¨NCCLä¸­ä¿®æ”¹çš„å¯ç”¨æ—‹é’®ã€‚   

Table 1. Knobs available for modification in NCCL

| Environment Variable                    | Description                                                  | Values Accepted                                              |
| :-------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| NCCL_SHM_DISABLE                        | The NCCL_SHM_DISABLE variable disables the Shared Memory (SHM) transports.   SHM is used between devices when peer-to-peer cannot happen, therefore, host memory is used. NCCL uses network (InfiniBand or IP sockets) to communicate between the CPU sockets when SHM is disabled.NCCL_SHM_DISABLEå˜é‡ç¦ç”¨å…±äº«å†…å­˜ï¼ˆSHMï¼‰ä¼ è¾“ã€‚åœ¨å¯¹ç­‰ä¸å¯èƒ½å‘ç”Ÿçš„æƒ…å†µä¸‹åœ¨è®¾å¤‡ä¹‹é—´ä½¿ç”¨SHMï¼Œå› æ­¤ä½¿ç”¨ä¸»æœºå†…å­˜ã€‚ å½“SHMç¦ç”¨æ—¶ï¼ŒNCCLä½¿ç”¨ç½‘ç»œï¼ˆInfiniBandæˆ–IP socketsï¼‰åœ¨CPU socketsä¹‹é—´è¿›è¡Œé€šä¿¡ã€‚ | Define and set to 1 to disable SHM.å®šä¹‰å¹¶è®¾ç½®ä¸º1ä»¥ç¦ç”¨SHMã€‚  |
| NCCL_SOCKET_IFNAME                      | The NCCL_SOCKET_IFNAME variable specifies which IP interface to use for communication.This variable also defines a prefix for the network interfaces to be filtered. NCCL_SOCKET_IFNAMEå˜é‡æŒ‡å®šç”¨äºé€šä¿¡çš„IPæ¥å£ã€‚è¯¥å˜é‡è¿˜å®šä¹‰äº†è¦è¿‡æ»¤çš„ç½‘ç»œæ¥å£çš„å‰ç¼€ã€‚ | Define and set to ib or eth. The value searches for all applicable ib* or eth* named interfaces on the system.Another accepted value is ^eth, which searches for interfaces that do not match eth.å®šä¹‰å¹¶è®¾ç½®ä¸ºibæˆ–ethã€‚ è¯¥å€¼åœ¨ç³»ç»Ÿä¸Šæœç´¢æ‰€æœ‰é€‚ç”¨çš„ib*æˆ–eth*å‘½åçš„æ¥å£ã€‚å¦ä¸€ä¸ªå¯æ¥å—çš„å€¼æ˜¯^ethï¼Œå®ƒæœç´¢ä¸ethä¸åŒ¹é…çš„æ¥å£ã€‚Note: Loopback (lo) is not selected by NCCL unless it is explicitly set in the environment variable.æ³¨æ„ï¼šé™¤éåœ¨ç¯å¢ƒå˜é‡ä¸­æ˜ç¡®è®¾ç½®ï¼Œå¦åˆ™NCCLä¸ä¼šé€‰æ‹©Loopbackï¼ˆloï¼‰ã€‚ |
| NCCL_DEBUG                              | The NCCL_DEBUG variable controls the debug information that is displayed from NCCL. This variable is commonly used for debugging.NCCL_DEBUGå˜é‡æ§åˆ¶ä»NCCLæ˜¾ç¤ºçš„è°ƒè¯•ä¿¡æ¯ã€‚ è¿™ä¸ªå˜é‡é€šå¸¸ç”¨äºè°ƒè¯•ã€‚ | VERSION Prints the NCCL version at the start of the program.åœ¨ç¨‹åºå¼€å§‹æ—¶æ‰“å°NCCLç‰ˆæœ¬ã€‚  WARN  Prints an explicit error message whenever any NCCL call errors out.æ¯å½“å‡ºç°ä»»ä½•NCCLè°ƒç”¨é”™è¯¯æ—¶ï¼Œæ‰“å°ä¸€ä¸ªæ˜ç¡®çš„é”™è¯¯æ¶ˆæ¯ã€‚ |
| NCCL_IB_DISABLE                         | The NCCL_IB_DISABLE variable disables the IB transport that is to be used by NCCL. Instead, NCCL will fallback to using IP sockets. NCCL_IB_DISABLEå˜é‡å°†ç¦ç”¨NCCLè¦ä½¿ç”¨çš„IBä¼ è¾“ã€‚NCCLå°†å›é€€åˆ°ä½¿ç”¨IP sockets ã€‚ | Define and set to 1 to force IP sockets usage.å®šä¹‰å¹¶è®¾ç½®ä¸º1ä»¥å¼ºåˆ¶ä½¿ç”¨IP sockets ã€‚ |
| NCCL_BUFFSIZE                           | The NCCL_BUFFSIZE variable controls the amount of buffer to share data between two GPUs.Use this variable if you encounter memory constraint issues when using NCCL or you think that a different buffer size would improve performance.NCCL_BUFFSIZEå˜é‡æ§åˆ¶ä¸¤ä¸ªGPUä¹‹é—´å…±äº«æ•°æ®çš„ç¼“å†²åŒºå¤§å°ã€‚å¦‚æœåœ¨ä½¿ç”¨NCCLæ—¶é‡åˆ°å†…å­˜é™åˆ¶é—®é¢˜ï¼Œæˆ–è€…æ‚¨è®¤ä¸ºä¸åŒçš„ç¼“å†²åŒºå¤§å°ä¼šæé«˜æ€§èƒ½ï¼Œè¯·ä½¿ç”¨æ­¤å˜é‡ã€‚ | Default is 4194304 (4 MB).Values are integers, in bytes. The recommendation is to use powers of 2. For example, 1024 will give a 1K buffer.é»˜è®¤æ˜¯4194304ï¼ˆ4 MBï¼‰ã€‚å€¼æ˜¯æ•´æ•°ï¼Œä»¥å­—èŠ‚ä¸ºå•ä½ã€‚ å»ºè®®ä½¿ç”¨2çš„è¯ä¹¦å¹‚ã€‚ä¾‹å¦‚ï¼Œ1024ä¼šç»™1Kç¼“å†²åŒºã€‚ |
| NCCL_NTHREADS                           | The NCCL_NTHREADS variable sets the number of CUDA threads per CUDA block. NCCL will launch one block per communication ring.NCCL_NTHREADSå˜é‡è®¾ç½®æ¯ä¸ªCUDAå—çš„CUDAçº¿ç¨‹æ•°ã€‚ NCCLå°†ä¸ºæ¯ä¸ªé€šè®¯ç¯è·¯å¯åŠ¨ä¸€ä¸ªæ¨¡å—ã€‚Use this variable if you think your GPU clocks are low and you want to increase the number of threads.You can also use this variable to reduce the number of threads to decrease the GPU workload.å¦‚æœæ‚¨è®¤ä¸ºæ‚¨çš„GPUæ—¶é’Ÿä¸è¶³ï¼Œå¹¶ä¸”æƒ³è¦å¢åŠ çº¿ç¨‹æ•°ï¼Œè¯·ä½¿ç”¨æ­¤å˜é‡ã€‚æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨æ­¤å˜é‡æ¥å‡å°‘çº¿ç¨‹æ•°é‡ï¼Œä»¥å‡å°‘GPUå·¥ä½œè´Ÿè½½ã€‚ | Default is 512 for Kepler.Default is 256 for Maxwell and Pascal.The values allowed are 128, 256 and 512.Keplerçš„é»˜è®¤å€¼æ˜¯512ã€‚Maxwellå’ŒPascalçš„é»˜è®¤å€¼æ˜¯256ã€‚å…è®¸çš„å€¼æ˜¯128,256å’Œ512ã€‚ |
| NCCL_RINGS                              | The NCCL_RINGS variable overrides the rings that NCCL forms by default. Rings are sequences of ranks. They can be any permutations of ranks.NCCL filters out any rings that do not contain the number of ranks in the NCCL communicator. In general, the ring formation is dependent on the hardware topology connecting the GPUs in your system.NCCL_RINGSå˜é‡è¦†ç›–é»˜è®¤æƒ…å†µä¸‹NCCLå½¢æˆçš„ç¯ã€‚ç¯æ˜¯ranksçš„åºåˆ—ã€‚ ä»–ä»¬å¯ä»¥æ˜¯ranksçš„ä»»ä½•æ’åˆ—ã€‚NCCLè¿‡æ»¤æ‰ä»»ä½•NCCLé€šä¿¡å™¨ä¸­ä¸åŒ…å«çš„ç§©æ•°çš„ç¯ã€‚ ä¸€èˆ¬æ¥è¯´ï¼Œç¯çš„å½¢æˆå–å†³äºç³»ç»Ÿä¸­è¿æ¥GPUçš„ç¡¬ä»¶æ‹“æ‰‘ç»“æ„ã€‚ | Ranks from 0 to n-1, where n is the number of GPUs in your communicator.The ranks can be separated by any non-digit character, for example, " ", "-", except " |
| NCCL_MAX_NRINGS(since 2.0.5)            | The NCCL_MAX_NRINGS variable limits the number of rings NCCL can use. Reducing the number of rings also reduces the number of CUDA blocks used for communication, hence the impact on GPU computing resources.NCCL_MAX_NRINGSå˜é‡é™åˆ¶äº†NCCLå¯ä»¥ä½¿ç”¨çš„ç¯çš„ä¸ªæ•°ã€‚ å‡å°‘ç¯çš„æ•°é‡ä¹Ÿå‡å°‘äº†ç”¨äºé€šä¿¡çš„CUDAå—çš„æ•°é‡ï¼Œä»è€Œå½±å“GPUè®¡ç®—èµ„æºã€‚ | Any value above or equal to 1.ä»»ä½•å¤§äºæˆ–ç­‰äº1çš„å€¼ã€‚          |
| NCCL_CHECKS_DISABLE(since 2.0.5)        | Disable argument checks. Checks are useful during development but can increase the latency. They can be disabled to improve performance in production.ç¦ç”¨å‚æ•°æ£€æŸ¥ã€‚ æ£€æŸ¥åœ¨å¼€å‘è¿‡ç¨‹ä¸­å¾ˆæœ‰ç”¨ï¼Œä½†ä¼šå¢åŠ å»¶è¿Ÿã€‚ ä»–ä»¬å¯ä»¥è¢«ç¦ç”¨ï¼Œä»¥æé«˜ç”Ÿäº§æ€§èƒ½ã€‚ | Default is 0. Set the value to 1 to disable checks.é»˜è®¤å€¼ä¸º0.å°†å€¼è®¾ç½®ä¸º1ä»¥ç¦ç”¨æ£€æŸ¥ã€‚ |
| NCCL_LAUNCH_MODE(since 2.1.0)           | Controls how NCCL launches CUDA kernels.æ§åˆ¶NCCLå¦‚ä½•å¯åŠ¨CUDAå†…æ ¸ã€‚ | The default value is to use cooperative groups (CUDA 9).Setting it to PARALLEL uses the previous launch system which can be faster but is prone to deadlocks.é»˜è®¤å€¼æ˜¯ä½¿ç”¨åˆä½œç»„ï¼ˆCUDA 9ï¼‰ã€‚å°†å…¶è®¾ç½®ä¸ºPARALLELå°†ä½¿ç”¨å…ˆå‰çš„å¯åŠ¨ç³»ç»Ÿï¼Œè¯¥å¯åŠ¨ç³»ç»Ÿå¯èƒ½æ›´å¿«ï¼Œä½†å®¹æ˜“å‡ºç°æ­»é”ã€‚ |
| NCCL_IB_TIMEOUT                         | The NCCL_IB_TIMEOUT variable controls the InfiniBand Verbs Timeout. Refer to the InfiniBand documentation for more information.NCCL_IB_TIMEOUTå˜é‡æ§åˆ¶InfiniBand Verbsè¶…æ—¶ã€‚ æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…InfiniBandæ–‡æ¡£ã€‚ | The default value used by NCCL is 14.The value depends on the size of your InfiniBand network.NCCLä½¿ç”¨çš„é»˜è®¤å€¼æ˜¯14ã€‚è¯¥å€¼å–å†³äºæ‚¨çš„InfiniBandç½‘ç»œçš„å¤§å°ã€‚ |
| NCCL_IB_CUDA_SUPPORT                    | The NCCL_IB_CUDA_SUPPORT variable is used to disable GPU Direct RDMA.NCCL_IB_CUDA_SUPPORTå˜é‡ç”¨äºç¦ç”¨GPU Direct RDMAã€‚ | By default, NCCL enables GPU Direct RDMA, if the topology permits it. This variable can disable this behavior.Define and set to 0 to disable GPU Direct RDMA.é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœæ‹“æ‰‘ç»“æ„å…è®¸ï¼ŒNCCLå¯ç”¨GPU Direct RDMAã€‚ æ­¤å˜é‡å¯ä»¥ç¦ç”¨æ­¤è¡Œä¸ºã€‚å®šä¹‰å¹¶è®¾ç½®ä¸º0ä»¥ç¦ç”¨GPU Direct RDMAã€‚ |
| NCCL_NET_GDR_READ                       | The NCCL_NET_GDR_READ variable enables GPU Direct RDMA when sending data. By default, NCCL uses GPU Direct RDMA to receive data directly in GPU memory. However, when sending data, the data is first stored in CPU memory, then goes to the InfiniBand card.å‘é€æ•°æ®æ—¶ï¼ŒNCCL_NET_GDR_READå˜é‡å¯ç”¨GPU Direct RDMAã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼ŒNCCLä½¿ç”¨GPU Direct RDMAç›´æ¥åœ¨GPUå†…å­˜ä¸­æ¥æ”¶æ•°æ®ã€‚ ä½†æ˜¯ï¼Œåœ¨å‘é€æ•°æ®æ—¶ï¼Œé¦–å…ˆå°†æ•°æ®å­˜å‚¨åœ¨CPUå†…å­˜ä¸­ï¼Œç„¶åè¿›å…¥InfiniBandå¡ã€‚Note: Reading directly GPU memory when sending data is known to be slightly slower than reading from CPU memory.æ³¨æ„ï¼šå‘é€æ•°æ®æ—¶ç›´æ¥è¯»å–GPUå†…å­˜æ¯”CPUå†…å­˜è¯»å–è¦æ…¢ä¸€äº›ã€‚Default value is 0.Define and set to 1 to use GPU Direct RDMA to send data to the NIC directly (bypassing CPU).é»˜è®¤å€¼æ˜¯0ã€‚å®šä¹‰å¹¶è®¾ç½®ä¸º1ï¼Œä»¥ä½¿ç”¨GPU Direct RDMAå°†æ•°æ®ç›´æ¥å‘é€åˆ°NICï¼ˆç»•è¿‡CPUï¼‰ã€‚ |                                                              |
| NCCL_SINGLE_RING_THRESHOLD(since 2.1.0) | Set the limit under which NCCL will only use one ring. This will limit bandwidth but improve latency.è®¾ç½®NCCLåªä½¿ç”¨ä¸€ä¸ªç¯çš„é™åˆ¶ã€‚ è¿™ä¼šé™åˆ¶å¸¦å®½ï¼Œä½†ä¼šæé«˜å»¶è¿Ÿã€‚ | Default value is 256kB on GPUs with compute capability 7 and above. Otherwise, the default value is 128kB on others.Values are integers, in bytes.åœ¨è®¡ç®—èƒ½åŠ›ä¸º7ä»¥ä¸Šçš„GPUä¸Šï¼Œé»˜è®¤å€¼ä¸º256kBã€‚ å¦åˆ™ï¼Œå…¶ä»–çš„é»˜è®¤å€¼æ˜¯128kBã€‚å€¼æ˜¯æ•´æ•°ï¼Œä»¥å­—èŠ‚ä¸ºå•ä½ã€‚ |
| NCCL_LL_THRESHOLD(since 2.1.0)          | Set the size limit under which NCCL uses low-latency algorithms.è®¾ç½®NCCLä½¿ç”¨ä½å»¶è¿Ÿç®—æ³•çš„å¤§å°é™åˆ¶ã€‚ | Default is 16kB.Values are integers, in bytes.é»˜è®¤å€¼æ˜¯16kBã€‚å€¼æ˜¯æ•´æ•°ï¼Œä»¥å­—èŠ‚ä¸ºå•ä½ã€‚ |

**5.5. Support**

Register for the NVIDIA Developer Program to report bugs,issues and make requests for feature enhancements. For more information, see:https://developer.nvidia.com/developer-program.

**Reference**

[1] https://blog.csdn.net/s_sunnyy/article/details/79023532    
[2] https://blog.csdn.net/s_sunnyy/article/details/79025262   



## ä¸‰ã€æ¡†æ¶

### 1. **æ¶æ„**

åœ¨æ¨¡å‹å¹¶è¡Œã€æ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œ&æ•°æ®å¹¶è¡Œçš„æ–¹å¼é€‰å®šåï¼Œæ¥ä¸‹æ¥è¦é€‰æ‹©ï¼Œ**å¤šGPUæœåŠ¡å™¨çš„ç»„ç»‡æ–¹å¼**ï¼ˆPS or Ringï¼‰å’Œ **å‚æ•°æ›´æ–°**ï¼ˆåŒæ­¥ or å¼‚æ­¥ï¼‰ã€‚

#### 1.1 PS or Ring

**1. å‚æ•°æœåŠ¡å™¨æ¶æ„**

å½“å¹¶è¡ŒSGDä½¿ç”¨å‚æ•°æœåŠ¡å™¨æ—¶ï¼Œç®—æ³•é¦–å…ˆå°†æ¨¡å‹å¹¿æ’­ç»™workersï¼ˆè®¾å¤‡ï¼‰ã€‚åœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼Œæ¯ä¸ªworkerä»mini-batchä¸­è¯»å–è‡ªå·±çš„éƒ¨åˆ†ï¼Œè®¡ç®—å…¶è‡ªå·±çš„æ¢¯åº¦ï¼Œå¹¶å°†è¿™äº›æ¢¯åº¦å‘é€åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªå‚æ•°æœåŠ¡å™¨ã€‚å‚æ•°æœåŠ¡å™¨æ±‡æ€»æ¥è‡ªworkerçš„æ‰€æœ‰æ¢¯åº¦ï¼Œå¹¶ç­‰åˆ°æ‰€æœ‰workerså®Œæˆä¹‹åï¼Œæ‰è®¡ç®—ä¸‹ä¸€æ¬¡è¿­ä»£çš„æ–°æ¨¡å‹ï¼Œç„¶åå°†å…¶å¹¿æ’­ç»™æ‰€æœ‰workersã€‚æ•°æ®æµå¦‚å›¾æ‰€ç¤ºã€‚

![img](imgs/53.png)
*åŒæ­¥éšæœºæ¢¯åº¦ä¸‹é™çš„å‚æ•°æœåŠ¡å™¨æ¶æ„ å›¾ç‰‡ç”±Jim Dowlingæä¾›ã€‚*

**2. Ring â€“ allreduceæ¶æ„**

åœ¨ring-allreduceæ¶æ„ä¸­ï¼Œæ²¡æœ‰ä¸­å¤®æœåŠ¡å™¨è´Ÿè´£èšåˆæ¥è‡ªworkersçš„æ¢¯åº¦ã€‚ç›¸åï¼Œåœ¨è®­ç»ƒè¿­ä»£ä¸­ï¼Œæ¯ä¸ªworkerè¯»å–å®ƒè‡ªå·±çš„mini-batchéƒ¨åˆ†ï¼Œè®¡ç®—å…¶æ¢¯åº¦ï¼Œå°†æ¢¯åº¦å‘é€åˆ°ç¯ä¸Šçš„åç»§é‚»å±…ï¼Œå¹¶ä»ç¯ä¸Šçš„å‰ä¸€ä¸ªé‚»å±…æ¥æ”¶æ¢¯åº¦ã€‚å¯¹äºå…·æœ‰Nä¸ªworkerçš„ç¯ï¼Œæ‰€æœ‰workerså°†åœ¨æ¯ä¸ªworkerå‘é€å’Œæ¥æ”¶N-1ä¸ªæ¢¯åº¦æ¶ˆæ¯ä¹‹åæ”¶åˆ°è®¡ç®—æ›´æ–°æ¨¡å‹æ‰€éœ€çš„æ¢¯åº¦ã€‚ Ring-allreduceæ˜¯å¸¦å®½æœ€ä¼˜åŒ–çš„ï¼Œå› ä¸ºå®ƒå¯ä»¥ç¡®ä¿æ¯ä¸ªä¸»æœºä¸Šå¯ç”¨çš„ä¸Šä¼ å’Œä¸‹è½½çš„ç½‘ç»œå¸¦å®½å¾—åˆ°å……åˆ†åˆ©ç”¨ï¼ˆä¸å‚æ•°æœåŠ¡å™¨æ–¹å¼ä¸åŒï¼‰ã€‚Ring-allreduceè¿˜å¯ä»¥å°†æ·±å±‚ç¥ç»ç½‘ç»œä¸­è¾ƒä½å±‚çš„æ¢¯åº¦è®¡ç®—ä¸é«˜å±‚æ¢¯åº¦çš„ä¼ è¾“é‡å ï¼Œä»è€Œè¿›ä¸€æ­¥ç¼©çŸ­è®­ç»ƒæ—¶é—´ã€‚æ•°æ®æµå¦‚å›¾æ‰€ç¤ºã€‚ 

![img](imgs/54.png)


ç›¸æ¯”PSæ¶æ„ï¼ŒRing-allreduceæ¶æ„æ˜¯å¸¦å®½ä¼˜åŒ–çš„ï¼Œå› ä¸ºé›†ç¾¤ä¸­æ¯ä¸ªèŠ‚ç‚¹çš„å¸¦å®½éƒ½è¢«å……åˆ†åˆ©ç”¨ã€‚æ­¤å¤–ï¼Œåœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®¡ç®—æ¢¯åº¦é‡‡ç”¨BPç®—æ³•ï¼Œå…¶ç‰¹ç‚¹æ˜¯åé¢å±‚çš„æ¢¯åº¦å…ˆè¢«è®¡ç®—ï¼Œè€Œå‰é¢å±‚çš„æ¢¯åº¦æ…¢äºå‰é¢å±‚ï¼ŒRing-allreduceæ¶æ„å¯ä»¥å……åˆ†åˆ©ç”¨è¿™ä¸ªç‰¹ç‚¹ï¼Œåœ¨å‰é¢å±‚æ¢¯åº¦è®¡ç®—çš„åŒæ—¶è¿›è¡Œåé¢å±‚æ¢¯åº¦çš„ä¼ é€’ï¼Œä»è€Œè¿›ä¸€æ­¥å‡å°‘è®­ç»ƒæ—¶é—´ã€‚åœ¨ç™¾åº¦çš„å®éªŒä¸­ï¼Œä»–ä»¬å‘ç°è®­ç»ƒé€Ÿåº¦åŸºæœ¬ä¸Šçº¿æ€§æ­£æ¯”äºGPUsæ•°ç›®ï¼ˆworkeræ•°ï¼‰ã€‚



ä¸€èˆ¬çš„å¤šå¡gpuè®­ç»ƒæœ‰ä¸€ä¸ªå¾ˆå¤§çš„ç¼ºé™·ï¼Œå°±æ˜¯å› ä¸ºæ¯æ¬¡éƒ½éœ€è¦ä¸€ä¸ªgpuï¼ˆcpuï¼‰ä»å…¶ä»–gpuä¸Šæ”¶é›†è®­ç»ƒçš„æ¢¯åº¦ï¼Œç„¶åå°†æ–°çš„æ¨¡å‹åˆ†å‘åˆ°å…¶ä»–gpuä¸Šã€‚è¿™æ ·çš„æ¨¡å‹æœ€å¤§çš„ç¼ºé™·æ˜¯gpu 0çš„é€šä¿¡æ—¶é—´æ˜¯éšç€gpuå¡æ•°çš„å¢é•¿è€Œçº¿æ€§å¢é•¿çš„ã€‚

æ‰€ä»¥å°±æœ‰äº†ring-allreduceï¼Œå¦‚ä¸‹å›¾ï¼š

![img](imgs/55.png)


ç®—æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯å–æ¶ˆReducerï¼Œè®©æ•°æ®åœ¨gpuå½¢æˆçš„ç¯å†…æµåŠ¨ï¼Œæ•´ä¸ªring-allreduceçš„è¿‡ç¨‹åˆ†ä¸ºä¸¤å¤§æ­¥ï¼Œç¬¬ä¸€æ­¥æ˜¯scatter-reduceï¼Œç¬¬äºŒæ­¥æ˜¯allgatherã€‚

å…ˆè¯´ç¬¬ä¸€æ­¥ï¼šé¦–å…ˆæˆ‘ä»¬æœ‰nå—gpuï¼Œé‚£ä¹ˆæˆ‘ä»¬æŠŠæ¯ä¸ªgpuä¸Šçš„æ•°æ®ï¼ˆå‡ç­‰çš„ï¼‰åˆ’åˆ†æˆnå—ï¼Œå¹¶ç»™æ¯ä¸ªgpuæŒ‡å®šå®ƒçš„å·¦å³é‚»å±…ï¼ˆå›¾ä¸­0å·gpuçš„å·¦é‚»å±…æ˜¯4å·ï¼Œå³é‚»å±…æ˜¯1å·ï¼Œ1å·gpuçš„å·¦é‚»å±…æ˜¯0å·ï¼Œå³é‚»å±…æ˜¯2å·â€¦â€¦ï¼‰ï¼Œç„¶åå¼€å§‹æ‰§è¡Œn-1æ¬¡æ“ä½œï¼Œåœ¨ç¬¬iæ¬¡æ“ä½œæ—¶ï¼Œgpu jä¼šå°†è‡ªå·±çš„ç¬¬(j - i)%nå—æ•°æ®å‘é€ç»™gpu j+1ï¼Œå¹¶æ¥å—gpu j-1çš„(j - i - 1)%nå—æ•°æ®ã€‚å¹¶å°†æ¥å—æ¥çš„æ•°æ®è¿›è¡Œreduceæ“ä½œï¼Œç¤ºæ„å›¾å¦‚ä¸‹ï¼š 

![img](imgs/56.png)


å½“n-1æ¬¡æ“ä½œå®Œæˆåï¼Œring-allreduceçš„ç¬¬ä¸€å¤§æ­¥scatter-reduceå°±å·²ç»å®Œæˆäº†ï¼Œæ­¤æ—¶ï¼Œç¬¬iå—gpuçš„ç¬¬(i + 1) % nå—æ•°æ®å·²ç»æ”¶é›†åˆ°äº†æ‰€æœ‰nå—gpuçš„ç¬¬(i + 1) % nå—æ•°æ®ï¼Œé‚£ä¹ˆï¼Œå†è¿›è¡Œä¸€æ¬¡allgatherå°±å¯ä»¥å®Œæˆç®—æ³•äº†ã€‚

ç¬¬äºŒæ­¥allgatheråšçš„äº‹æƒ…å¾ˆç®€å•ï¼Œå°±æ˜¯é€šè¿‡n-1æ¬¡ä¼ é€’ï¼ŒæŠŠç¬¬iå—gpuçš„ç¬¬(i + 1) % nå—æ•°æ®ä¼ é€’ç»™å…¶ä»–gpuï¼ŒåŒæ ·ä¹Ÿæ˜¯åœ¨iæ¬¡ä¼ é€’æ—¶ï¼Œgpu jæŠŠè‡ªå·±çš„ç¬¬(j - i - 1)%nå—æ•°æ®å‘é€ç»™å³é‚»å±…ï¼Œæ¥å—å·¦é‚»å±…çš„ç¬¬(j - i - 2) % næ•°æ®ï¼Œä½†æ˜¯æ¥å—æ¥çš„æ•°æ®ä¸éœ€è¦åƒç¬¬ä¸€æ­¥é‚£æ ·åšreduceï¼Œè€Œæ˜¯ç›´æ¥ç”¨æ¥å—æ¥çš„æ•°æ®ä»£æ›¿è‡ªå·±çš„æ•°æ®å°±å¥½äº†ã€‚

æœ€åæ¯ä¸ªgpuçš„æ•°æ®å°±å˜æˆäº†è¿™æ ·ï¼š 

![img](imgs/57.png)

é¦–å…ˆæ˜¯ç¬¬ä¸€æ­¥ï¼Œscatter-reduceï¼š
![img](imgs/58.png)



ç„¶åæ˜¯allgatherçš„ä¾‹å­ï¼š
![img](imgs/59.png)


Horovod æ˜¯ Uber å¼€æºçš„åˆä¸€ä¸ªæ·±åº¦å­¦ä¹ å·¥å…·ï¼Œå®ƒçš„å‘å±•å¸å–äº† Facebookã€Œä¸€å°æ—¶è®­ç»ƒ ImageNet è®ºæ–‡ã€(ã€ŠAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour ã€‹)ä¸ç™¾åº¦ Ring Allreduce çš„ä¼˜ç‚¹ï¼Œå¯ä¸ºç”¨æˆ·å®ç°åˆ†å¸ƒå¼è®­ç»ƒæä¾›å¸®åŠ©ã€‚æœ¬æ–‡å°†ç®€è¦ä»‹ç»è¿™ä¸€æ¡†æ¶çš„ç‰¹æ€§ã€‚
Deep Learning trainingè¯´ç™½äº†æ˜¯æµ®ç‚¹æ•°è¿ç®—ï¼Œéå¸¸é€‚åˆä»¥MPIä¸ºæ ¸å¿ƒçš„å¹¶è¡Œè®¡ç®—ã€‚ä¹‹å‰Googleï¼Œç™¾åº¦ï¼Œä»¥åŠFacebooké‚£ç¯‡ImageNet in one hourä¹Ÿç”¨çš„æ˜¯MPIã€‚

### 2. åŒæ­¥ä¸å¼‚æ­¥åˆ†å¸ƒå¼è®­ç»ƒ

éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰æ˜¯ç”¨äºå¯»æ‰¾æœ€ä¼˜å€¼çš„è¿­ä»£ç®—æ³•ï¼Œæ˜¯AIä¸­æœ€å—æ¬¢è¿çš„è®­ç»ƒç®—æ³•ä¹‹ä¸€ï¼Œå®ƒæ¶‰åŠå¤šè½®è®­ç»ƒï¼Œæ¯è½®çš„ç»“æœéƒ½æ›´æ–°åˆ°æ¨¡å‹ä¸­ï¼Œä»¥å¤‡ä¸‹ä¸€è½®è®­ç»ƒï¼Œæ¯è½®è®­ç»ƒå¯ä»¥åœ¨å¤šä¸ªè®¾å¤‡ä¸ŠåŒæ­¥æˆ–å¼‚æ­¥è¿è¡Œã€‚ 

![img](imgs/50.png)



æ¯æ¬¡SGDè¿­ä»£è¿è¡Œä¸€ä¸ªmini-batchçš„è®­ç»ƒæ ·æœ¬ï¼ˆFacebookæ‹¥æœ‰8,092å¼ å›¾åƒçš„å¤§å°ºå¯¸mini-batchï¼‰ã€‚åœ¨åŒæ­¥è®­ç»ƒä¸­ï¼Œæ‰€æœ‰è®¾å¤‡éƒ½ä½¿ç”¨å•ä¸ªï¼ˆå¤§å°ºå¯¸ï¼‰mini-batchæ•°æ®çš„ä¸åŒéƒ¨åˆ†æ¥è®­ç»ƒå…¶æœ¬åœ°æ¨¡å‹ï¼Œç„¶åå°†ä»–ä»¬æœ¬åœ°è®¡ç®—çš„æ¢¯åº¦ï¼ˆç›´æ¥æˆ–é—´æ¥ï¼‰ä¼ é€ç»™å…¶å®ƒæ‰€æœ‰è®¾å¤‡ï¼Œåªæœ‰åœ¨æ‰€æœ‰è®¾å¤‡æˆåŠŸè®¡ç®—å¹¶å‘é€äº†æ¢¯åº¦åï¼Œæ¨¡å‹æ‰ä¼šæ›´æ–°ã€‚ç„¶åå°†æ›´æ–°åçš„æ¨¡å‹å’Œä¸‹ä¸€ä¸ªmini-batchçš„æ‹†åˆ†ä¸€èµ·å‘é€åˆ°æ‰€æœ‰èŠ‚ç‚¹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè®¾å¤‡åœ¨mini-batchçš„éé‡å åˆ†å‰²çš„å­é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚

è™½ç„¶å¹¶è¡Œæœ‰å¾ˆå¤§çš„åŠ é€Ÿè®­ç»ƒçš„æ½œåŠ›ï¼Œä½†å®ƒè‡ªç„¶ä¼šå¼•å…¥å¼€é”€ï¼Œå¤§å‹æ¨¡å‹å’Œæ…¢é€Ÿç½‘ç»œä¼šå¢åŠ è®­ç»ƒæ—¶é—´ã€‚å¦‚æœæœ‰å¤±é€Ÿï¼ˆæ…¢é€Ÿè®¾å¤‡æˆ–ç½‘ç»œè¿æ¥ï¼‰ï¼Œè®­ç»ƒå¯èƒ½ä¼šå¤±é€Ÿã€‚æˆ‘ä»¬è¿˜å¸Œæœ›å‡å°‘è®­ç»ƒæ¨¡å‹æ‰€éœ€çš„è¿­ä»£æ¬¡æ•°ï¼Œå› ä¸ºæ¯æ¬¡è¿­ä»£éƒ½éœ€è¦å°†æ›´æ–°çš„æ¨¡å‹å¹¿æ’­åˆ°æ‰€æœ‰èŠ‚ç‚¹ã€‚å®é™…ä¸Šï¼Œè¿™æ„å‘³ç€å°½å¯èƒ½å¢åŠ mini-batchçš„å°ºå¯¸ï¼Œä»¥å…é™ä½è®­ç»ƒæ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

åœ¨ä»–ä»¬çš„è®ºæ–‡ä¸­ï¼ŒFacebookä»‹ç»äº†é’ˆå¯¹å­¦ä¹ ç‡çš„çº¿æ€§ç¼©æ”¾è§„åˆ™ï¼Œå¯ä»¥ç”¨å¤§å°ºå¯¸mini-batchè¿›è¡Œè®­ç»ƒï¼Œè¯¥è§„åˆ™è§„å®šâ€œå½“mini-batchå¤§å°ä¹˜ä»¥kæ—¶ï¼Œå°†å­¦ä¹ ç‡ä¹ŸåŒæ ·ä¹˜ä»¥kâ€ï¼Œä½†æ¡ä»¶æ˜¯åœ¨è¾¾åˆ°ç›®æ ‡å­¦ä¹ ç‡ä¹‹å‰ï¼Œå­¦ä¹ ç‡åº”è¯¥åœ¨å‡ ä¸ªepochså†…ç¼“æ…¢å¢åŠ ã€‚ åœ¨å¼‚æ­¥è®­ç»ƒä¸­ï¼Œæ²¡æœ‰è®¾å¤‡ç­‰å¾…æ¥è‡ªä»»ä½•å…¶ä»–è®¾å¤‡çš„æ¨¡å‹æ›´æ–°ã€‚è¿™äº›è®¾å¤‡å¯ä»¥ç‹¬ç«‹è¿è¡Œå¹¶ä¸å¯¹ç­‰è®¾å¤‡å…±äº«ç»“æœï¼Œæˆ–é€šè¿‡ä¸€ä¸ªæˆ–å¤šä¸ªç§°ä¸ºâ€œå‚æ•°â€æœåŠ¡å™¨çš„ä¸­å¤®æœåŠ¡å™¨è¿›è¡Œé€šä¿¡ã€‚åœ¨å¯¹ç­‰æ¶æ„ä¸­ï¼Œæ¯ä¸ªè®¾å¤‡è¿è¡Œä¸€ä¸ªå¾ªç¯ï¼Œè¯»å–æ•°æ®ï¼Œè®¡ç®—æ¢¯åº¦ï¼Œå°†å®ƒä»¬ï¼ˆç›´æ¥æˆ–é—´æ¥ï¼‰å‘é€åˆ°æ‰€æœ‰è®¾å¤‡ï¼Œå¹¶å°†æ¨¡å‹æ›´æ–°ä¸ºæœ€æ–°ç‰ˆæœ¬ã€‚åœ¨æ›´ä¸­å¿ƒåŒ–çš„æ¶æ„ä¸­ï¼Œè®¾å¤‡ä»¥æ¢¯åº¦çš„å½¢å¼å°†å…¶è¾“å‡ºå‘é€åˆ°å‚æ•°æœåŠ¡å™¨ï¼Œè¿™äº›æœåŠ¡å™¨æ”¶é›†å’Œèšåˆæ¢¯åº¦ã€‚åœ¨åŒæ­¥è®­ç»ƒä¸­ï¼Œå‚æ•°æœåŠ¡å™¨è®¡ç®—æ¨¡å‹æœ€è¿‘çš„æœ€æ–°ç‰ˆæœ¬ï¼Œå¹¶å°†å…¶å‘é€å›è®¾å¤‡ã€‚åœ¨å¼‚æ­¥è®­ç»ƒä¸­ï¼Œå‚æ•°æœåŠ¡å™¨å°†æ¢¯åº¦å‘é€åˆ°æœ¬åœ°è®¡ç®—æ–°æ¨¡å‹çš„è®¾å¤‡ã€‚åœ¨è¿™ä¸¤ç§æ¶æ„ä¸­ï¼Œå¾ªç¯é‡å¤ç›´åˆ°è®­ç»ƒç»“æŸã€‚å›¾2è¯´æ˜äº†å¼‚æ­¥å’ŒåŒæ­¥è®­ç»ƒä¹‹é—´çš„åŒºåˆ«ã€‚



![img](imgs/51.png)




![img](imgs/52.png)

