# max & argmax & ...

âŒšï¸: 2020å¹´8æœˆ9æ—¥

ğŸ“šå‚è€ƒ

---



åœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œé€šå¸¸éœ€è¦ä½¿ç”¨`max()`å‡½æ•°å¯¹`softmax`å‡½æ•°çš„è¾“å‡ºå€¼è¿›è¡Œæ“ä½œï¼Œæ±‚å‡ºé¢„æµ‹å€¼ç´¢å¼•ã€‚ä¸‹é¢è®²è§£ä¸€ä¸‹`torch.max()`å‡½æ•°çš„è¾“å…¥åŠè¾“å‡ºå€¼éƒ½æ˜¯ä»€ä¹ˆã€‚

## 1. torch.max(input, dim) å‡½æ•°

```
output = torch.max(input, dim)
```

> è¾“å…¥
>
> - `input`æ˜¯softmaxå‡½æ•°è¾“å‡ºçš„ä¸€ä¸ª`tensor`
> - `dim`æ˜¯maxå‡½æ•°ç´¢å¼•çš„ç»´åº¦`0/1`ï¼Œ`0`æ˜¯æ¯åˆ—çš„æœ€å¤§å€¼ï¼Œ`1`æ˜¯æ¯è¡Œçš„æœ€å¤§å€¼

> è¾“å‡º
>
> - å‡½æ•°ä¼šè¿”å›ä¸¤ä¸ª`tensor`ï¼Œç¬¬ä¸€ä¸ª`tensor`æ˜¯æ¯è¡Œçš„æœ€å¤§å€¼ï¼Œsoftmaxçš„è¾“å‡ºä¸­æœ€å¤§çš„æ˜¯1ï¼Œæ‰€ä»¥ç¬¬ä¸€ä¸ª`tensor`æ˜¯å…¨1çš„`tensor`ï¼›ç¬¬äºŒä¸ª`tensor`æ˜¯æ¯è¡Œæœ€å¤§å€¼çš„ç´¢å¼•ã€‚

æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå®ä¾‹å¯ä»¥æ›´å®¹æ˜“ç†è§£è¿™ä¸ªå‡½æ•°çš„ç”¨æ³•ã€‚



```python
import torch
a = torch.tensor([[1,5,62,54], [2,6,2,6], [2,65,2,6]])
print(a)
```

è¾“å‡ºï¼š

```python
tensor([[ 1,  5, 62, 54],
        [ 2,  6,  2,  6],
        [ 2, 65,  2,  6]])
```

ç´¢å¼•æ¯è¡Œçš„æœ€å¤§å€¼ï¼š

```python
torch.max(a, 1)
```

è¾“å‡ºï¼š

```python
torch.return_types.max(
values=tensor([62,  6, 65]),
indices=tensor([2, 3, 1]))
```

åœ¨è®¡ç®—å‡†ç¡®ç‡æ—¶ç¬¬ä¸€ä¸ªtensor `values`æ˜¯ä¸éœ€è¦çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€æå–ç¬¬äºŒä¸ªtensorï¼Œå¹¶å°†tensoræ ¼å¼çš„æ•°æ®è½¬æ¢æˆarrayæ ¼å¼ã€‚

```python
torch.max(a, 1)[1].numpy()
```

è¾“å‡ºï¼š

```cpp
array([2, 3, 1], dtype=int64)
```

*æ³¨ï¼šåœ¨æœ‰çš„åœ°æ–¹æˆ‘ä»¬ä¼šçœ‹åˆ°`torch.max(a, 1).data.numpy()`çš„å†™æ³•ï¼Œè¿™æ˜¯å› ä¸ºåœ¨æ—©æœŸçš„pytorchçš„ç‰ˆæœ¬ä¸­ï¼Œvariableå˜é‡å’Œtenosræ˜¯ä¸ä¸€æ ·çš„æ•°æ®æ ¼å¼ï¼Œvariableå¯ä»¥è¿›è¡Œåå‘ä¼ æ’­ï¼Œtensorä¸å¯ä»¥ï¼Œéœ€è¦å°†variableè½¬å˜æˆtensorå†è½¬å˜æˆnumpyã€‚ç°åœ¨çš„ç‰ˆæœ¬å·²ç»å°†variableå’Œtenosråˆå¹¶ï¼Œæ‰€ä»¥åªç”¨`torch.max(a,1).numpy()`å°±å¯ä»¥äº†ã€‚

### å‡†ç¡®ç‡çš„è®¡ç®—

```python
pred_y = torch.max(predict, 1)[1].numpy()
y_label = torch.max(label, 1)[1].data.numpy()
accuracy = (pred_y == y_label).sum() / len(y_label)
```

### **æ‹“å±•**

`torch.max()[0]`ï¼Œ åªè¿”å›æœ€å¤§å€¼çš„æ¯ä¸ªæ•°
`troch.max()[1]`ï¼Œ åªè¿”å›æœ€å¤§å€¼çš„æ¯ä¸ªç´¢å¼•
`torch.max()[1].data` åªè¿”å›variableä¸­çš„æ•°æ®éƒ¨åˆ†ï¼ˆå»æ‰Variable containing:ï¼‰
`torch.max()[1].data.numpy()` æŠŠæ•°æ®è½¬åŒ–æˆnumpy ndarry
`torch.max()[1].data.numpy().squeeze()` æŠŠæ•°æ®æ¡ç›®ä¸­ç»´åº¦ä¸º1 çš„åˆ é™¤æ‰

## 2. torch.argmaxå‡½æ•°

**argmaxå‡½æ•°**ï¼š`torch.argmax(input, dim=None, keepdim=False)`è¿”å›æŒ‡å®šç»´åº¦æœ€å¤§å€¼çš„åºå·ï¼Œ**dimç»™å®šçš„å®šä¹‰æ˜¯ï¼šthe demention to reduce**.ä¹Ÿå°±æ˜¯æŠŠdimè¿™ä¸ªç»´åº¦çš„ï¼Œå˜æˆè¿™ä¸ªç»´åº¦çš„æœ€å¤§å€¼çš„indexã€‚

1ï¼‰dimçš„ä¸åŒå€¼è¡¨ç¤ºä¸åŒç»´åº¦ã€‚ç‰¹åˆ«çš„åœ¨dim=0è¡¨ç¤ºäºŒç»´ä¸­çš„åˆ—ï¼Œdim=1åœ¨äºŒç»´çŸ©é˜µä¸­è¡¨ç¤ºè¡Œã€‚å¹¿æ³›çš„æ¥è¯´ï¼Œæˆ‘ä»¬ä¸ç®¡ä¸€ä¸ªçŸ©é˜µæ˜¯å‡ ç»´çš„ï¼Œæ¯”å¦‚ä¸€ä¸ªçŸ©é˜µç»´åº¦å¦‚ä¸‹ï¼š(d0,d1,...,dnâˆ’1) ï¼Œé‚£ä¹ˆdim=0å°±è¡¨ç¤ºå¯¹åº”åˆ°d0 ä¹Ÿå°±æ˜¯ç¬¬ä¸€ä¸ªç»´åº¦ï¼Œdim=1è¡¨ç¤ºå¯¹åº”åˆ°ä¹Ÿå°±æ˜¯ç¬¬äºŒä¸ªç»´åº¦ï¼Œä¸€æ¬¡ç±»æ¨ã€‚

2ï¼‰çŸ¥é“dimçš„å€¼æ˜¯ä»€ä¹ˆæ„æ€è¿˜ä¸è¡Œï¼Œè¿˜è¦çŸ¥é“å‡½æ•°ä¸­è¿™ä¸ªdimç»™å‡ºæ¥ä¼šå‘ç”Ÿä»€ä¹ˆã€‚ç»“åˆè¿™ä¸¤ä¸ªæ‰ä¼šçŸ¥é“dimåœ¨å‡½æ•°ä¸­çš„ä½œç”¨ã€‚ä¸‹é¢ä¸¾ä¸¤ä¸ªä¾‹å­è¯´æ˜ä¸Šé¢çš„ç¬¬äºŒç‚¹ã€‚

ä¾‹å­ä¸€ï¼štorch.argmax()å‡½æ•°ä¸­dimè¡¨ç¤ºè¯¥ç»´åº¦ä¼šæ¶ˆå¤±ã€‚

è¿™ä¸ªæ¶ˆå¤±æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿå®˜æ–¹è‹±æ–‡è§£é‡Šæ˜¯ï¼šdim (int) â€“ the dimension to reduce.
æˆ‘ä»¬çŸ¥é“argmaxå°±æ˜¯å¾—åˆ°æœ€å¤§å€¼çš„åºå·ç´¢å¼•ï¼Œå¯¹äºä¸€ä¸ªç»´åº¦ä¸º(d0,d1) çš„çŸ©é˜µæ¥è¯´ï¼Œæˆ‘ä»¬æƒ³è¦æ±‚æ¯ä¸€è¡Œä¸­æœ€å¤§æ•°çš„åœ¨è¯¥è¡Œä¸­çš„åˆ—å·ï¼Œæœ€åæˆ‘ä»¬å¾—åˆ°çš„å°±æ˜¯ä¸€ä¸ªç»´åº¦ä¸º(d0,1) çš„ä¸€çŸ©é˜µã€‚è¿™æ—¶å€™ï¼Œåˆ—å°±è¦æ¶ˆå¤±äº†ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬æƒ³è¦æ±‚æ¯ä¸€è¡Œæœ€å¤§çš„åˆ—æ ‡å·ï¼Œæˆ‘ä»¬å°±è¦æŒ‡å®šdim=1ï¼Œè¡¨ç¤ºæˆ‘ä»¬ä¸è¦åˆ—äº†ï¼Œä¿ç•™è¡Œçš„sizeå°±å¯ä»¥äº†ã€‚
å‡å¦‚æˆ‘ä»¬æƒ³æ±‚æ¯ä¸€åˆ—çš„æœ€å¤§è¡Œæ ‡ï¼Œå°±å¯ä»¥æŒ‡å®šdim=0ï¼Œè¡¨ç¤ºæˆ‘ä»¬ä¸è¦è¡Œäº†ã€‚
example 1

```python
import torch
a=torch.tensor(
              [
                  [1, 5, 5, 2],
                  [9, -6, 2, 8],
                  [-3, 7, -9, 1]
              ])
b=torch.argmax(a,dim=0)
print(b)
print(a.shape)
```

 \#ç»“æœï¼š

```html
tensor([1, 2, 0, 1])
torch.Size([3, 4])
```

dim=0ç»´åº¦ä¸Šä¸º3,å³åœ¨é‚£3ç»„æ•°æ®ä¸­ä½œæ¯”è¾ƒï¼Œæ±‚å¾—æ˜¯æ¯ä¸€åˆ—ä¸­çš„æœ€å¤§è¡Œæ ‡ï¼Œå› æ­¤ä¸º[1,2,0,4]

example2 åœ¨ä¸‰ç»´åæ ‡ä¸­

```python
import torch
a=torch.tensor([
              [
                  [1, 5, 5, 2],
                  [9, -6, 2, 8],
                  [-3, 7, -9, 1]
              ],
 
              [
                  [-1, 7, -5, 2],
                  [9, 6, 2, 8],
                  [3, 7, 9, 1]
              ]])
b=torch.argmax(a,dim=0)
print(b)
print(a.shape)
 
"""
tensor([[0, 1, 0, 1],
        [1, 1, 1, 1],
        [1, 1, 1, 1]])
torch.Size([2, 3, 4])"""
 
#dim=0,å³å°†ç¬¬ä¸€ä¸ªç»´åº¦æ¶ˆé™¤ï¼Œä¹Ÿå°±æ˜¯å°†ä¸¤ä¸ª[3*4]çŸ©é˜µåªä¿ç•™ä¸€ä¸ªï¼Œå› æ­¤è¦åœ¨ä¸¤ç»„ä¸­ä½œæ¯”è¾ƒï¼Œå³å°†ä¸Šä¸‹ä¸¤ä¸ª[3*4]çš„çŸ©é˜µåˆ†åˆ«åœ¨å¯¹åº”çš„ä½ç½®ä¸Šæ¯”è¾ƒ
 
b=torch.argmax(a,dim=1)
â€œâ€â€œ
tensor([[1, 2, 0, 1],
        [1, 2, 2, 1]])
torch.Size([2, 3, 4])â€â€œâ€
#dim=1ï¼Œå³å°†ç¬¬äºŒä¸ªç»´åº¦æ¶ˆé™¤,è¿™ä¹ˆç†è§£ï¼šçŸ©é˜µç»´åº¦å˜ä¸º[2*4];
"""[1, 5, 5, 2],
   [9, -6, 2, 8],
   [-3, 7, -9, 1];
çºµå‘å‹ç¼©æˆä¸€ç»´ï¼Œå› æ­¤å˜ä¸º[1,2,0,1];åŒç†å¾—åˆ°[1,2,2,1];"""
b=torch.argmax(a,dim=2)
"""
tensor([[2, 0, 1],
        [1, 0, 2]])
"""
#dim=2,å³å°†ç¬¬ä¸‰ä¸ªç»´åº¦æ¶ˆé™¤ï¼Œè¿™ä¹ˆç†è§£ï¼šçŸ©é˜µç»´åº¦å˜ä¸º[2*3]
"""
   [1, 5, 5, 2],
   [9, -6, 2, 8],
   [-3, 7, -9, 1];
æ¨ªå‘å‹ç¼©æˆä¸€ç»´
[2,0,1],åŒç†å¾—åˆ°ä¸‹é¢çš„â€œâ€â€œ

```

## 3. torch.size

torch.size ()ï¼šæŸ¥çœ‹å½“å‰Tensorçš„ç»´åº¦ï¼Œç”¨æ³•ä¹Ÿå¾ˆç®€å•ï¼š

ç»ˆç«¯è¿›å…¥Pythonç¯å¢ƒ

\>>>import torch
\>>>a = torch.Tensor([[1, 2, 3], [4, 5, 6]])
\>>>a.size()

(2, 3)



## 4. torch.clamp

> torch.clamp(input, min, max, out=None) â†’ Tensor

å°†è¾“å…¥`input`å¼ é‡æ¯ä¸ªå…ƒç´ çš„å¤¹ç´§åˆ°åŒºé—´ [min,max]ï¼Œå¹¶è¿”å›ç»“æœåˆ°ä¸€ä¸ªæ–°å¼ é‡ã€‚

æ“ä½œå®šä¹‰å¦‚ä¸‹ï¼š

```python
      | min, if x_i < min
y_i = | x_i, if min <= x_i <= max
      | max, if x_i > max
```

å¦‚æœè¾“å…¥æ˜¯FloatTensor or DoubleTensorç±»å‹ï¼Œåˆ™å‚æ•°`min` `max` å¿…é¡»ä¸ºå®æ•°ï¼Œå¦åˆ™é¡»ä¸ºæ•´æ•°ã€‚ã€è¯‘æ³¨ï¼šä¼¼ä¹å¹¶éå¦‚æ­¤ï¼Œæ— å…³è¾“å…¥ç±»å‹ï¼Œ`min`ï¼Œ `max`å–æ•´æ•°ã€å®æ•°çš†å¯ã€‚ã€‘

å‚æ•°ï¼š

- input (Tensor) â€“ è¾“å…¥å¼ é‡
- min (Number) â€“ é™åˆ¶èŒƒå›´ä¸‹é™
- max (Number) â€“ é™åˆ¶èŒƒå›´ä¸Šé™
- out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡

ä¾‹å­ï¼š

```python
>>> a = torch.randn(4)
>>> a
-1.4511
-0.6812
 0.3302
-1.7423

[torch.FloatTensor of size 4]

>>> torch.clamp(a, min=-0.5, max=0.5)
-0.5000
-0.5000
 0.3302
-0.5000

[torch.FloatTensor of size 4]
torch.clamp(input, *, min, out=None) â†’ Tensor


a.clamp_(min=-0.5,max=0.5) #å¦ä¸€ç§å®ç°æ–¹æ³•
-0.5000
-0.5000
 0.3302
-0.5000
[torch.FloatTensor of size 4]
```

å°†è¾“å…¥`input`å¼ é‡æ¯ä¸ªå…ƒç´ çš„é™åˆ¶åˆ°ä¸å°äº`min` ï¼Œå¹¶è¿”å›ç»“æœåˆ°ä¸€ä¸ªæ–°å¼ é‡ã€‚

å¦‚æœè¾“å…¥æ˜¯FloatTensor or DoubleTensorç±»å‹ï¼Œåˆ™å‚æ•° `min` å¿…é¡»ä¸ºå®æ•°ï¼Œå¦åˆ™é¡»ä¸ºæ•´æ•°ã€‚ã€è¯‘æ³¨ï¼šä¼¼ä¹å¹¶éå¦‚æ­¤ï¼Œæ— å…³è¾“å…¥ç±»å‹ï¼Œ`min`å–æ•´æ•°ã€å®æ•°çš†å¯ã€‚ã€‘

å‚æ•°ï¼š

- input (Tensor) â€“ è¾“å…¥å¼ é‡
- value (Number) â€“ é™åˆ¶èŒƒå›´ä¸‹é™
- out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡

ä¾‹å­ï¼š

```python
>>> a = torch.randn(4)
>>> a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

>>> torch.clamp(a, min=0.5)

 1.3869
 0.5000
 0.5000
 0.5000
[torch.FloatTensor of size 4]

```

`torch.clamp(input, *, max, out=None) â†’ Tensor`

å°†è¾“å…¥`input`å¼ é‡æ¯ä¸ªå…ƒç´ çš„é™åˆ¶åˆ°ä¸å¤§äº`max` ï¼Œå¹¶è¿”å›ç»“æœåˆ°ä¸€ä¸ªæ–°å¼ é‡ã€‚

å¦‚æœè¾“å…¥æ˜¯FloatTensor or DoubleTensorç±»å‹ï¼Œåˆ™å‚æ•° `max` å¿…é¡»ä¸ºå®æ•°ï¼Œå¦åˆ™é¡»ä¸ºæ•´æ•°ã€‚ã€è¯‘æ³¨ï¼šä¼¼ä¹å¹¶éå¦‚æ­¤ï¼Œæ— å…³è¾“å…¥ç±»å‹ï¼Œ`max`å–æ•´æ•°ã€å®æ•°çš†å¯ã€‚ã€‘

å‚æ•°ï¼š

- input (Tensor) â€“ è¾“å…¥å¼ é‡
- value (Number) â€“ é™åˆ¶èŒƒå›´ä¸Šé™
- out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡

ä¾‹å­ï¼š

```python
>>> a = torch.randn(4)
>>> a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

>>> torch.clamp(a, max=0.5)

 0.5000
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]
```

## 5. torch.sum()çš„ç”¨æ³•

torch.sum()å¯¹è¾“å…¥çš„tensoræ•°æ®çš„æŸä¸€ç»´åº¦æ±‚å’Œï¼Œä¸€å…±ä¸¤ç§ç”¨æ³•

```
ï¼‘ï¼torch.sum(input, dtype=None)
ï¼’ï¼torch.sum(input, list: dim, bool: keepdim=False, dtype=None) â†’ Tensor
ã€€
input:è¾“å…¥ä¸€ä¸ªtensor
dim:è¦æ±‚å’Œçš„ç»´åº¦ï¼Œå¯ä»¥æ˜¯ä¸€ä¸ªåˆ—è¡¨
keepdim:æ±‚å’Œä¹‹åè¿™ä¸ªdimçš„å…ƒç´ ä¸ªæ•°ä¸ºï¼‘ï¼Œæ‰€ä»¥è¦è¢«å»æ‰ï¼Œå¦‚æœè¦ä¿ç•™è¿™ä¸ªç»´åº¦ï¼Œåˆ™åº”å½“keepdim=True
#If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. 

```

ä¾‹å­ï¼š

```
a = torch.ones((2, 3))
print(a):
tensor([[1, 1, 1],
 		[1, 1, 1]])

a1 =  torch.sum(a)
a2 =  torch.sum(a, dim=0)
a3 =  torch.sum(a, dim=1)

print(a)
print(a1)
print(a2)

```

è¾“å‡ºç»“æœï¼š

```
tensor(6.)
tensor([2., 2., 2.])
tensor([3., 3.])

```

å¦‚æœåŠ ä¸Škeepdim=True, åˆ™ä¼šä¿æŒdimçš„ç»´åº¦ä¸è¢«squeeze

```
a1 =  torch.sum(a, dim=(0, 1), keepdim=True)
a2 =  torch.sum(a, dim=(0, ), keepdim=True)
a3 =  torch.sum(a, dim=(1, ), keepdim=True)

```

è¾“å‡ºç»“æœï¼š

```
tensor([[6.]])
tensor([[2., 2., 2.]])
tensor([[3., 3.]])
```

## 6. topkå‡½æ•°è¯¦è§£

å¬åå­—å°±çŸ¥é“è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥æ±‚tensorä¸­æŸä¸ªdimçš„å‰kå¤§æˆ–è€…å‰kå°çš„å€¼ä»¥åŠå¯¹åº”çš„indexã€‚

### ç”¨æ³•

`torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor)`



> inputï¼šä¸€ä¸ªtensoræ•°æ®
> kï¼šæŒ‡æ˜æ˜¯å¾—åˆ°å‰kä¸ªæ•°æ®ä»¥åŠå…¶index
> dimï¼š æŒ‡å®šåœ¨å“ªä¸ªç»´åº¦ä¸Šæ’åºï¼Œ é»˜è®¤æ˜¯æœ€åä¸€ä¸ªç»´åº¦
> largestï¼šå¦‚æœä¸ºTrueï¼ŒæŒ‰ç…§å¤§åˆ°å°æ’åºï¼› å¦‚æœä¸ºFalseï¼ŒæŒ‰ç…§å°åˆ°å¤§æ’åº
> sortedï¼šè¿”å›çš„ç»“æœæŒ‰ç…§é¡ºåºè¿”å›
> outï¼šå¯ç¼ºçœï¼Œä¸è¦



topkæœ€å¸¸ç”¨çš„åœºåˆå°±æ˜¯æ±‚ä¸€ä¸ªæ ·æœ¬è¢«ç½‘ç»œè®¤ä¸ºå‰kä¸ªæœ€å¯èƒ½å±äºçš„ç±»åˆ«ã€‚æˆ‘ä»¬å°±ç”¨è¿™ä¸ªåœºæ™¯ä¸ºä¾‹ï¼Œè¯´æ˜å‡½æ•°çš„ä½¿ç”¨æ–¹æ³•ã€‚
å‡è®¾ä¸€ä¸ªtensor$ F âˆˆ R ^{N Ã— D}$  ï¼ŒNæ˜¯æ ·æœ¬æ•°ç›®ï¼Œä¸€èˆ¬ç­‰äºbatch sizeï¼Œ Dæ˜¯ç±»åˆ«æ•°ç›®ã€‚æˆ‘ä»¬æƒ³çŸ¥é“æ¯ä¸ªæ ·æœ¬çš„æœ€å¯èƒ½å±äºçš„é‚£ä¸ªç±»åˆ«ï¼Œå…¶å®å¯ä»¥ç”¨torch.maxå¾—åˆ°ã€‚å¦‚æœè¦ä½¿ç”¨topkï¼Œåˆ™kåº”è¯¥è®¾ç½®ä¸º1ã€‚

```
import torch

pred = torch.randn((4, 5))
print(pred)
values, indices = pred.topk(1, dim=1, largest=True, sorted=True)
print(indices)


# ç”¨maxå¾—åˆ°çš„ç»“æœï¼Œè®¾ç½®keepdimä¸ºTrueï¼Œé¿å…é™ç»´ã€‚å› ä¸ºtopkå‡½æ•°è¿”å›çš„indexä¸é™ç»´ï¼Œshapeå’Œè¾“å…¥ä¸€è‡´ã€‚
_, indices_max = pred.max(dim=1, keepdim=True)
print(indices_max == indices)

# pred
tensor([[-0.1480, -0.9819, -0.3364,  0.7912, -0.3263],
        [-0.8013, -0.9083,  0.7973,  0.1458, -0.9156],
        [-0.2334, -0.0142, -0.5493,  0.0673,  0.8185],
        [-0.4075, -0.1097,  0.8193, -0.2352, -0.9273]])

# indices, shapeä¸º ã€4,1ã€‘,
tensor([[3],   #ã€0, 0ã€‘ä»£è¡¨ç¬¬ä¸€ä¸ªæ ·æœ¬æœ€å¯èƒ½å±äºç¬¬ä¸€ç±»åˆ«
        [2],   #ã€1, 0ã€‘ä»£è¡¨ç¬¬äºŒä¸ªæ ·æœ¬æœ€å¯èƒ½å±äºç¬¬äºŒç±»åˆ«
        [4],
        [2]])

# indices_maxç­‰äºindices
tensor([[True],
        [True],
        [True],
        [True]])
```


ç°åœ¨åœ¨å°è¯•ä¸€ä¸‹k=2

```
import torch

pred = torch.randn((4, 5))
print(pred)
values, indices = pred.topk(2, dim=1, largest=True, sorted=True)  # k=2
print(indices)

# pred

tensor([[-0.2203, -0.7538,  1.8789,  0.4451, -0.2526],
        [-0.0413,  0.6366,  1.1155,  0.3484,  0.0395],
        [ 0.0365,  0.5158,  1.1067, -0.9276, -0.2124],
        [ 0.6232,  0.9912, -0.8562,  0.0148,  1.6413]])

# indices

tensor([[2, 3],
        [2, 1],
        [2, 1],
        [4, 1]])
```


å¯ä»¥å‘ç°indicesçš„shapeå˜æˆäº†ã€4, kã€‘ï¼Œk=2ã€‚
å…¶ä¸­indices[0] = [2,3]ã€‚å…¶æ„ä¹‰æ˜¯è¯´æ˜ç¬¬ä¸€ä¸ªæ ·æœ¬çš„å‰ä¸¤ä¸ªæœ€å¤§æ¦‚ç‡å¯¹åº”çš„ç±»åˆ«åˆ†åˆ«æ˜¯ç¬¬3ç±»å’Œç¬¬4ç±»ã€‚

å¤§å®¶å¯ä»¥è‡ªè¡Œprintä¸€ä¸‹valuesã€‚å¯ä»¥å‘ç°valuesçš„shapeå’Œindicesçš„shapeæ˜¯ä¸€æ ·çš„ã€‚indicesæè¿°äº†åœ¨valuesä¸­å¯¹åº”çš„å€¼åœ¨predä¸­çš„ä½ç½®ã€‚

