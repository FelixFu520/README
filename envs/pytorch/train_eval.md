# Pytorchä¸­trainå’Œevalæ¨¡å¼çš„åŒºåˆ«

âŒšï¸: 2020å¹´8æœˆ9æ—¥

ðŸ“šå‚è€ƒ

---

## å‰è¨€ï¼š

åœ¨ä½¿ç”¨Pytorhchæ¡†æž¶æ—¶æ€»ä¼šçœ‹è§åœ¨æ¨¡åž‹è®­ç»ƒå‰ä¼šåŠ ä¸Šmodel.trian(), è€Œåœ¨æ¨¡åž‹æµ‹è¯•æˆ–è€…éªŒè¯ä¹‹å‰åˆ™ä¼šåŠ ä¸Šmodel.eval(), é‚£è¿™ä¸¤è€…ä¹‹é—´æœ‰ä»€ä¹ˆåŒºåˆ«äº†ï¼Ÿï¼Ÿ

## model.eval()

æˆ‘ä»¬æ¥çœ‹çœ‹å®˜æ–¹çš„è§£é‡Šï¼šç”±äºŽåœ¨éªŒè¯æˆ–è€…æµ‹è¯•æ—¶ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ¨¡åž‹ä¸­çš„æŸäº›å±‚èµ·ä½œç”¨ï¼ˆæ¯”å¦‚:Dropoutå±‚ï¼‰ï¼Œä¹Ÿä¸å¸Œæœ›æŸäº›å±‚çš„å‚æ•°è¢«æ”¹å˜ï¼ˆi.e. BatchNormçš„å‚æ•°ï¼‰ï¼Œè¿™æ—¶å°±éœ€è¦è®¾ç½®æˆ**model.eval()**æ¨¡å¼

## model.train()

ä½†æ˜¯åœ¨è®­ç»ƒæ¨¡åž‹çš„æ—¶å€™åˆå¸Œæœ›è¿™äº›å±‚èµ·ä½œç”¨ï¼Œæ‰€ä»¥åˆè¦é‡æ–°å°†è¿™äº›å±‚è®¾ç½®å›žæ¥ï¼Œè¿™æ—¶å€™å°±éœ€è¦ç”¨åˆ°**model.train()**æ¨¡å¼

## torch.no_grad()

åœ¨æ¨¡åž‹æµ‹è¯•æˆ–è€…éªŒè¯æ—¶è¿˜éœ€è¦ä½¿ç”¨åˆ°ä¸€ä¸ªå‡½æ•°ï¼štorch.no_grad()ã€‚

ä½œç”¨ï¼š
ç¦ç”¨æ¢¯åº¦è®¡ç®—çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚

è§£é‡Šï¼š
å½“åœ¨æ¨¡åž‹æŽ¨æ–­ï¼ˆval/testï¼‰æ—¶ï¼Œæˆ‘ä»¬ä¸ä¼šè°ƒç”¨åå‘ä¼ æ’­ã€‚è¿™æ—¶ç¦æ­¢è®¡ç®—æ¢¯åº¦ï¼Œ å®ƒå°†å‡å°‘åŽŸæœ¬éœ€è¦require_grad = Trueçš„è®¡ç®—çš„å†…å­˜æ¶ˆè€—ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œå³ä½¿è¾“å…¥å…·æœ‰require_grad = Trueï¼Œæ¯æ¬¡è®¡ç®—çš„ç»“æžœä¹Ÿå°†å…·æœ‰require_grad = Falseã€‚

ä»£ç ç¤ºä¾‹ï¼š

>x = torch.tensor([1], requires_grad=True)
>with torch.no_grad():
>...   y = x * 2
>y.requires_grad
>False
>@torch.no_grad()  #ç”¨ä½œè£…é¥°å™¨
>... def doubler(x):
>...     return x * 2
>z = doubler(x)
>z.requires_grad
>False



## torch.enable_grad()

ä½œç”¨ï¼š
ä¸Žtorch.no_grad()çš„ä½œç”¨ç›¸åï¼Œå¦‚æžœæ¢¯åº¦è®¡ç®—torch.no_grad()æˆ–è€…torch.set_grad_enabled()ç¦æ­¢äº†ï¼Œ ä½¿ç”¨torch.enable_grad()å°†ä¼šå…è®¸æ¢¯åº¦è®¡ç®—çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚
ä»£ç ç¤ºä¾‹:

>x = torch.tensor([1], requires_grad=True)
>with torch.no_grad():
>...   with torch.enable_grad():
>...     y = x * 2
>y.requires_grad
>True
>y.backward()
>x.grad
>@torch.enable_grad()
>... def doubler(x):
>...     return x * 2
>with torch.no_grad():
>...     z = doubler(x)
>z.requires_grad
>True

