# NLPå­¦ä¹ è·¯çº¿

âŒšï¸: 2021-07-21

ğŸ“šå‚è€ƒ

- [NLPé¡¹ç›®æµç¨‹](https://github.com/TD-4/DeepLearning)ã€ä¸»è¦ã€‘
- [å·©å›ºçŸ¥è¯†çš„åšå®¢-1](https://codeantenna.com/a/t1gY0liLBh)
- [å·©å›ºçŸ¥è¯†çš„åšå®¢-2](https://zhuanlan.zhihu.com/p/346191907)
- [å·©å›ºçŸ¥è¯†çš„åšå®¢-3](https://www.cnblogs.com/jiangxinyang/p/11114993.html)
- [å·©å›ºçŸ¥è¯†çš„åšå®¢-4](https://blog.csdn.net/golfbears/article/details/109074901)
- [å·©å›ºçŸ¥è¯†çš„åšå®¢-5](https://zhuanlan.zhihu.com/p/54743941)
- [Transformer & CNN](https://www.163.com/dy/article/FVTM8E540511ABV6.html)
- [Word Embedding->ELMO->GPT->Bert](https://zhuanlan.zhihu.com/p/49271699)

---

NLPå­¦ä¹ è·¯çº¿æ˜¯å‚è€ƒ[ç‹æ ‘æ£®è§†é¢‘](https://github.com/TD-4/DeepLearning)æ•´ç†çš„ï¼Œä»¥NLP(Natural Language Processing)ä¸ºä¾‹ï¼Œä»‹ç»äº†ä»RNN->LSTM->Attention->Self-Attention->Transformer->BERTã€GPTã€...ç­‰å†…å®¹ï¼Œç„¶åå†ç®€å•ä»‹ç»ViT(Vision Transformer).



## 1. æ•°æ®å¤„ç†

å‚è€ƒ[NLPé¡¹ç›®æµç¨‹](https://github.com/TD-4/DeepLearning)ä¸­çš„è¯¾æ—¶1å’Œè¯¾æ—¶2.

1. Tokenization(åˆ†è¯)
2. Build Dictionaryï¼ˆå»ºç«‹å­—å…¸ï¼‰
3. One-hot encodingï¼ˆçƒ­ç¼–ç ï¼‰
4. Word Embeddingï¼ˆåµŒå…¥å¼ç¼–ç ï¼‰

## 2. RNN

[![image-20211213173439148](imgs/image-20211213173439148.png)](https://www.bilibili.com/video/BV1Zi4y1L7LL/?spm_id_from=333.788.recommend_more_video.-1)

æœ‰å¾ˆå¤štext, speech, time seriesçš„æ•°æ®ï¼Œæ— æ³•ä½¿ç”¨FCï¼Œ CNNï¼ˆå½“æ—¶ï¼‰æ¥å¤„ç†ï¼Œæ‰€ä»¥äººä»¬è®¾è®¡å‡ºRNNæ¥å¤„ç†æ—¶é—´åºåˆ—æ•°æ®ã€‚

ä½†æ˜¯RNNä¸èƒ½è®°å¿†é•¿æ—¶é—´å†…å®¹ã€‚

## 3. LSTM

[![image-20211213173903960](imgs/image-20211213173903960.png)](https://www.bilibili.com/video/BV1gy4y1q7M5/?spm_id_from=333.788.recommend_more_video.0)

RNNä¸èƒ½è®°å¿†é•¿æ—¶é—´å†…å®¹ï¼Œæ‰€ä»¥æœ‰äº†LSTMæ¨¡å‹ï¼Œä½†æ˜¯LSTMåªæ˜¯é•¿çŸ­è®°å¿†æ¨¡å‹ï¼Œï¼Œå¤ªé•¿çš„åºåˆ—æ—¶é—´ä¹Ÿæ˜¯ä¸å¯ä»¥çš„ã€‚

## 3. Effective RNNs

ä¸ºäº†æé«˜RNNçš„æ€§èƒ½ï¼Œäººä»¬æå‡ºäº†å¾ˆæ”¹è¿›æ–¹æ³•ã€‚

### 3.1 Stacked RNN

![image-20211214105046938](imgs/image-20211214105046938.png)

### 3.2 Bidirectional RNN

![image-20211214105203786](imgs/image-20211214105203786.png)

Ytä¼šé—å¿˜X1çš„å†…å®¹ï¼Œæ‰€ä»¥æœ‰äº†åŒå‘RNNï¼ŒY1ä¼šé—å¿˜Xtå†…å®¹ï¼Œä¸¤è€…äº’è¡¥ï¼Œæ•ˆæœä¼šå¥½å¾ˆå¤šã€‚

## 4. Text Generation

![image-20211214105624723](imgs/image-20211214105624723.png)

## 5. Seq2Seq

![image-20211214112416202](imgs/image-20211214112416202.png)

![image-20211214112630455](imgs/image-20211214112630455.png)



![image-20211214112654642](imgs/image-20211214112654642.png)



![image-20211214112712843](imgs/image-20211214112712843.png)

![image-20211214112735321](imgs/image-20211214112735321.png)



![image-20211214112912296](imgs/image-20211214112912296.png)

![image-20211214112939028](imgs/image-20211214112939028.png)

å¦‚ä½•æé«˜Seq2Seqçš„æ€§èƒ½

- **Bi-LSTM instead of LSTM** **(Encoder only!)**
-  **Word-Level Tokenization**
- **Multi-Task Learning**
- Attention!	(Next lecture.)

Seq2Seqçš„ç¼ºç‚¹ï¼š

- æœ€åçš„çŠ¶æ€ä¸èƒ½è®°å¿†é•¿æ—¶é—´å†…å®¹

## 6. Attention

[æˆ‘è®¤ä¸ºAttentionæœºåˆ¶å®é™…ä¸Šæ˜¯ä¸€ç§ç›¸å½“æ™®é€‚çš„æ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿç›´æ¥åµŒå…¥åŸç½‘ç»œä¸­åŠ å¼ºå¯¹ä¸­å¿ƒç‰¹å¾çš„é€‰æ‹©ã€‚](https://zhuanlan.zhihu.com/p/346191907)

[![image-20211213174245983](imgs/image-20211213174245983.png)](https://www.bilibili.com/video/BV1G64y1S7bc)



![image-20211214113457104](imgs/image-20211214113457104.png)



### 6.1 Seq2Seq Model with **Attention**

- â€¢ Attention tremendously improves Seq2Seq model.
- â€¢ With attention, Seq2Seq model does not forget source input.
- â€¢ With attention, the decoder knows where to focus.
- â€¢ Downside: much more computation.

![image-20211214113804856](imgs/image-20211214113804856.png)

![image-20211214113822716](imgs/image-20211214113822716.png)



![image-20211214113850546](imgs/image-20211214113850546.png)

![image-20211214113928504](imgs/image-20211214113928504.png)

![image-20211214130222258](imgs/image-20211214130222258.png)



![image-20211214130427355](imgs/image-20211214130427355.png)

![image-20211214131452343](imgs/image-20211214131452343.png)

![image-20211214131513858](imgs/image-20211214131513858.png)

![image-20211214131602901](imgs/image-20211214131602901.png)

![image-20211214131809080](imgs/image-20211214131809080.png)

### 6.2 Self-Attention

![image-20211214132340282](imgs/image-20211214132340282.png)

![image-20211214134912401](imgs/image-20211214134912401.png)

![image-20211214134938208](imgs/image-20211214134938208.png)

å…¶ä¸­ï¼Œh0æ˜¯å…¨0å‘é‡ã€‚

![image-20211214135414378](imgs/image-20211214135414378.png)

![image-20211214135435882](imgs/image-20211214135435882.png)

![image-20211214135502278](imgs/image-20211214135502278.png)

![image-20211214135522007](imgs/image-20211214135522007.png)

## 7. Transformer

[![image-20210721201512490](imgs/image-20210721201512490.png)](https://www.bilibili.com/video/BV1Zz4y127h1)



## 8. BERT

Bidirectional Encoder Representations from Transformers.ç”¨æ¥é¢„è®­ç»ƒTransformerä¸­çš„Encoderæ¨¡å‹ã€‚

[![image-20210721203146931](imgs/image-20210721203146931.png)](https://www.bilibili.com/video/BV11N41197nq/?spm_id_from=trigger_reload)



## 9. GPT

[![image-20210721203426655](imgs/image-20210721203426655.png)](https://www.bilibili.com/video/BV1Jv411a7RB/?spm_id_from=trigger_reload)

[ELMO, Bert, GPTæå®æ¯…è§†é¢‘](https://www.youtube.com/watch?v=UYPa347-DdE)



## 10. ViT

[ç‹æ ‘æ£®ViTè§†é¢‘](https://www.youtube.com/watch?v=BbzOZ9THriY)