

# 权重初始化

⌚️: 2020年8月9日

📚参考

---

## 一、概览

那么为什么会有这么多初始化策略呢？深度学习算法的训练通常是迭代的，因此要求使用者给一些开始迭代的初始点，而有些深度模型会受到初始点的影响，使得算法遭遇数值困难，并完全失败。此外初始点可以决定学习收敛的多快，以及是否收敛到一个代价高或低的点，更何况代价相近的点也可能有极大的泛化差别。**不同的网络结构和激活函数需要适配不同的初始化方法**。目前常用的初始化方法包含随机均匀初始化、正态分布初始化、Xavier初始化、He初始化、预训练等。

一个好的初始化方法要求各层激活值不会出现饱和现象,同时各层得激活值不为0.    

![](imgs/6.png)





