# BN/LN/IN/GN/SN

Batch Normalizationã€Layer Normalizationã€Instance Normalizationã€Group Normalizationã€Switchable Normalizationæ¯”è¾ƒ

âŒšï¸: 2020å¹´10æœˆ22æ—¥

ğŸ“šå‚è€ƒ

- [åŸæ–‡-1](https://www.cnblogs.com/wanghui-garcia/p/10877700.html)

- [åŸæ–‡-2](https://www.cnblogs.com/LXP-Never/p/11566064.html)

---

æ·±åº¦ç¥ç»ç½‘ç»œéš¾è®­ç»ƒä¸€ä¸ªé‡è¦çš„åŸå› å°±æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œæ¶‰åŠå¾ˆå¤šå±‚çš„å åŠ ï¼Œæ¯ä¸€å±‚çš„å‚æ•°å˜åŒ–éƒ½ä¼šå¯¼è‡´ä¸‹ä¸€å±‚è¾“å…¥æ•°æ®åˆ†å¸ƒçš„å˜åŒ–ï¼Œéšç€å±‚æ•°çš„å¢åŠ ï¼Œé«˜å±‚è¾“å…¥æ•°æ®åˆ†å¸ƒå˜åŒ–ä¼šéå¸¸å‰§çƒˆï¼Œè¿™å°±ä½¿å¾—é«˜å±‚éœ€è¦ä¸æ–­é€‚åº”ä½å±‚çš„å‚æ•°æ›´æ–°ã€‚ä¸ºäº†è®­ç»ƒå¥½æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦è°¨æ…åˆå§‹åŒ–ç½‘ç»œæƒé‡ï¼Œè°ƒæ•´å­¦ä¹ ç‡ç­‰ã€‚

æœ¬ç¯‡åšå®¢æ€»ç»“å‡ ç§å½’ä¸€åŒ–åŠæ³•ï¼Œå¹¶ç»™å‡ºç›¸åº”è®¡ç®—å…¬å¼å’Œä»£ç ã€‚

å½’ä¸€åŒ–å±‚ï¼Œç›®å‰ä¸»è¦æœ‰è¿™å‡ ä¸ªæ–¹æ³•ï¼Œ[Batch Normalization](https://arxiv.org/pdf/1502.03167.pdf)ï¼ˆ2015å¹´ï¼‰ã€[Layer Normalization](https://arxiv.org/pdf/1607.06450v1.pdf)ï¼ˆ2016å¹´ï¼‰ã€[Instance Normalization](https://arxiv.org/pdf/1607.08022.pdf)ï¼ˆ2017å¹´ï¼‰ã€[Group Normalization](https://arxiv.org/pdf/1803.08494.pdf)ï¼ˆ2018å¹´ï¼‰ã€[Switchable Normalization](https://arxiv.org/pdf/1806.10779.pdf)ï¼ˆ2018å¹´ï¼‰ï¼›

å°†è¾“å…¥çš„å›¾åƒshapeè®°ä¸º[**N**, **C**hannel, **H**eight, **W**idth]ï¼Œè¿™å‡ ä¸ªæ–¹æ³•ä¸»è¦çš„åŒºåˆ«å°±æ˜¯åœ¨ï¼Œ

- **batch Norm**ï¼šåœ¨batchä¸Šï¼Œå¯¹NHWåšå½’ä¸€åŒ–ï¼Œå¯¹å°batchsizeæ•ˆæœä¸å¥½ï¼›
- **layer Norm**ï¼šåœ¨é€šé“æ–¹å‘ä¸Šï¼Œå¯¹CHWå½’ä¸€åŒ–ï¼Œä¸»è¦å¯¹RNNä½œç”¨æ˜æ˜¾ï¼›
- **instance Norm**ï¼šåœ¨å›¾åƒåƒç´ ä¸Šï¼Œå¯¹HWåšå½’ä¸€åŒ–ï¼Œç”¨åœ¨é£æ ¼åŒ–è¿ç§»ï¼›
- **Group Norm**ï¼šå°†channelåˆ†ç»„ï¼Œç„¶åå†åšå½’ä¸€åŒ–ï¼›
- **Switchable Norm**ï¼šå°†BNã€LNã€INç»“åˆï¼Œèµ‹äºˆæƒé‡ï¼Œè®©ç½‘ç»œè‡ªå·±å»å­¦ä¹ å½’ä¸€åŒ–å±‚åº”è¯¥ä½¿ç”¨ä»€ä¹ˆæ–¹æ³•ã€‚

![img](imgs/1433301-20191126171358402-795814566.png)

é‚£æˆ‘ä»¬å°±çœ‹çœ‹ä¸‹é¢çš„ä¸¤ä¸ªåŠ¨å›¾, è¿™å°±æ˜¯åœ¨æ¯å±‚ç¥ç»ç½‘ç»œæœ‰æ—  batch normalization çš„åŒºåˆ«

![img](imgs/1433301-20191126193305308-30880230.png)

![img](imgs/1433301-20191126193319613-292877789.png)

æ²¡æœ‰normalization çš„è¾“å‡ºæ•°æ®å¾ˆå¤šéƒ½ç­‰äº0ï¼Œå¯¼è‡´åé¢çš„ç¥ç»å…ƒâ€œæ­»æ‰â€ï¼Œèµ·ä¸åˆ°ä»»ä½•ä½œç”¨ã€‚

## 1. Batch Normalization

ã€€ã€€é¦–å…ˆï¼Œåœ¨è¿›è¡Œè®­ç»ƒä¹‹å‰ï¼Œä¸€èˆ¬è¦å¯¹æ•°æ®åšå½’ä¸€åŒ–ï¼Œä½¿å…¶åˆ†å¸ƒä¸€è‡´ï¼Œä½†æ˜¯åœ¨æ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä»¥é€å…¥ç½‘ç»œçš„æ¯ä¸€ä¸ªbatchè®­ç»ƒï¼Œè¿™æ ·æ¯ä¸ªbatchå…·æœ‰ä¸åŒçš„åˆ†å¸ƒï¼›è€Œä¸”åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ•°æ®åˆ†å¸ƒä¼šå‘ç”Ÿå˜åŒ–ï¼Œå¯¹ä¸‹ä¸€å±‚ç½‘ç»œçš„å­¦ä¹ å¸¦æ¥å›°éš¾ã€‚

ã€€ã€€batch normalizationå°±æ˜¯å¼ºè¡Œ**å°†æ•°æ®æ‹‰å›åˆ°å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„æ­£å¤ªåˆ†å¸ƒä¸Šï¼Œè¿™æ ·ä¸ä»…æ•°æ®åˆ†å¸ƒä¸€è‡´ï¼Œè€Œä¸”é¿å…å‘ç”Ÿæ¢¯åº¦æ¶ˆå¤±**ã€‚ä¿è¯æ¯ä¸€æ¬¡æ•°æ®ç»è¿‡å½’ä¸€åŒ–åè¿˜ä¿ç•™åŸæœ‰å­¦ä¹ æ¥çš„ç‰¹å¾ï¼ŒåŒæ—¶åˆèƒ½å®Œæˆå½’ä¸€åŒ–æ“ä½œï¼ŒåŠ é€Ÿè®­ç»ƒã€‚ 

![image-20201022100326749](imgs/image-20201022100326749.png)

## 2. Layer Normalizaiton

batch normalizationå­˜åœ¨ä»¥ä¸‹ç¼ºç‚¹ï¼š

- å¯¹batch sizeçš„å¤§å°æ¯”è¾ƒæ•æ„Ÿï¼Œç”±äºæ¯æ¬¡è®¡ç®—å‡å€¼å’Œæ–¹å·®æ˜¯åœ¨ä¸€ä¸ªbatchä¸Šï¼Œæ‰€ä»¥å¦‚æœbatch sizeå¤ªå°ï¼Œåˆ™è®¡ç®—çš„å‡å€¼ã€æ–¹å·®ä¸è¶³ä»¥ä»£è¡¨æ•´ä¸ªæ•°æ®åˆ†å¸ƒï¼›
- BNå®é™…ä½¿ç”¨æ—¶éœ€è¦è®¡ç®—å¹¶ä¸”ä¿å­˜æŸä¸€å±‚ç¥ç»ç½‘ç»œbatchçš„å‡å€¼å’Œæ–¹å·®ç­‰ç»Ÿè®¡ä¿¡æ¯ï¼Œå¯¹äºå¯¹ä¸€ä¸ªå›ºå®šæ·±åº¦çš„å‰å‘ç¥ç»ç½‘ç»œï¼ˆDNNï¼ŒCNNï¼‰ä½¿ç”¨BNï¼Œå¾ˆæ–¹ä¾¿ï¼›ä½†å¯¹äºRNNæ¥è¯´ï¼Œsequenceçš„é•¿åº¦æ˜¯ä¸ä¸€è‡´çš„ï¼Œæ¢å¥è¯è¯´RNNçš„æ·±åº¦ä¸æ˜¯å›ºå®šçš„ï¼Œä¸åŒçš„time-stepéœ€è¦ä¿å­˜ä¸åŒçš„staticsç‰¹å¾ï¼Œå¯èƒ½å­˜åœ¨ä¸€ä¸ªç‰¹æ®Šsequenceæ¯”å…¶ä»–sequenceé•¿å¾ˆå¤šï¼Œè¿™æ ·trainingæ—¶ï¼Œè®¡ç®—å¾ˆéº»çƒ¦ã€‚

LNæ˜¯é’ˆå¯¹æ·±åº¦ç½‘ç»œçš„æŸä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒçš„è¾“å…¥æŒ‰ä»¥ä¸‹å…¬å¼è¿›è¡Œnormalizeæ“ä½œã€‚

![image-20201022100516632](imgs/image-20201022100516632.png)



**BNä¸LNçš„åŒºåˆ«åœ¨äº**ï¼š

- LNä¸­åŒå±‚ç¥ç»å…ƒè¾“å…¥æ‹¥æœ‰ç›¸åŒçš„å‡å€¼å’Œæ–¹å·®ï¼Œä¸åŒçš„è¾“å…¥æ ·æœ¬æœ‰ä¸åŒçš„å‡å€¼å’Œæ–¹å·®ï¼›
- BNä¸­åˆ™é’ˆå¯¹ä¸åŒç¥ç»å…ƒè¾“å…¥è®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼ŒåŒä¸€ä¸ªbatchä¸­çš„è¾“å…¥æ‹¥æœ‰ç›¸åŒçš„å‡å€¼å’Œæ–¹å·®ã€‚

æ‰€ä»¥ï¼ŒLNä¸ä¾èµ–äºbatchçš„å¤§å°å’Œè¾“å…¥sequenceçš„æ·±åº¦ï¼Œå› æ­¤å¯ä»¥ç”¨äºbatchsizeä¸º1å’ŒRNNä¸­å¯¹è¾¹é•¿çš„è¾“å…¥sequenceçš„normalizeæ“ä½œã€‚

LNç”¨äºRNNæ•ˆæœæ¯”è¾ƒæ˜æ˜¾ï¼Œä½†æ˜¯åœ¨CNNä¸Šï¼Œä¸å¦‚BNã€‚

tf.keras.layers.LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True)

å‚æ•°

- axisï¼šæƒ³è¦è§„èŒƒåŒ–çš„è½´ï¼ˆé€šå¸¸æ˜¯ç‰¹å¾è½´ï¼‰
- epsilonï¼šå°†è¾ƒå°çš„æµ®ç‚¹æ•°æ·»åŠ åˆ°æ–¹å·®ä»¥é¿å…è¢«é›¶é™¤ã€‚
- centerï¼šå¦‚æœä¸ºTrueï¼Œåˆ™å°†çš„åç§»`beta`é‡æ·»åŠ åˆ°æ ‡å‡†åŒ–å¼ é‡ã€‚
- `scale`ï¼šå¦‚æœä¸ºTrueï¼Œåˆ™ä¹˜ä»¥`gamma`

è¿”å›

- shapeä¸è¾“å…¥å½¢çŠ¶ç›¸åŒçš„å€¼

## 3. Instance Normalization

ã€€ã€€BNæ³¨é‡å¯¹æ¯ä¸ªbatchè¿›è¡Œå½’ä¸€åŒ–ï¼Œä¿è¯æ•°æ®åˆ†å¸ƒä¸€è‡´ï¼Œå› ä¸ºåˆ¤åˆ«æ¨¡å‹ä¸­ç»“æœå–å†³äºæ•°æ®æ•´ä½“åˆ†å¸ƒã€‚

ã€€ã€€ä½†æ˜¯å›¾åƒé£æ ¼åŒ–ä¸­ï¼Œç”Ÿæˆç»“æœä¸»è¦ä¾èµ–äºæŸä¸ªå›¾åƒå®ä¾‹ï¼Œæ‰€ä»¥å¯¹æ•´ä¸ªbatchå½’ä¸€åŒ–ä¸é€‚åˆå›¾åƒé£æ ¼åŒ–ä¸­ï¼Œå› è€Œå¯¹HWåšå½’ä¸€åŒ–ã€‚å¯ä»¥åŠ é€Ÿæ¨¡å‹æ”¶æ•›ï¼Œå¹¶ä¸”ä¿æŒæ¯ä¸ªå›¾åƒå®ä¾‹ä¹‹é—´çš„ç‹¬ç«‹ã€‚

![image-20201022100823319](imgs/image-20201022100823319.png)

[`tfa.layers.normalizations.InstanceNormalization`](https://www.tensorflow.org/addons/api_docs/python/tfa/layers/InstanceNormalization)

è¾“å…¥ï¼šä»…åœ¨è¯¥å±‚åªæœ‰ä¸€ä¸ªè¾“å…¥ï¼ˆå³ï¼Œå®ƒè¿æ¥åˆ°ä¸€ä¸ªä¼ å…¥å±‚ï¼‰æ—¶é€‚ç”¨ã€‚

è¿”å›ï¼šè¾“å…¥å¼ é‡æˆ–è¾“å…¥å¼ é‡åˆ—è¡¨ã€‚

```
def Instancenorm(x, gamma, beta):

    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5

    x_mean = np.mean(x, axis=(2, 3), keepdims=True)
    x_var = np.var(x, axis=(2, 3), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta
    return results
```

## 4. Group Normalization

ä¸»è¦æ˜¯é’ˆå¯¹Batch Normalizationå¯¹å°batchsizeæ•ˆæœå·®ï¼ŒGNå°†channelæ–¹å‘åˆ†groupï¼Œç„¶åæ¯ä¸ªgroupå†…åšå½’ä¸€åŒ–ï¼Œç®—`(C//G)*H*W`çš„å‡å€¼ï¼Œè¿™æ ·ä¸batchsizeæ— å…³ï¼Œä¸å—å…¶çº¦æŸã€‚

![image-20201022100919712](imgs/image-20201022100919712.png)

```
def GroupNorm(x, gamma, beta, G=16):

    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5
    x = np.reshape(x, (x.shape[0], G, x.shape[1]/16, x.shape[2], x.shape[3]))

    x_mean = np.mean(x, axis=(2, 3, 4), keepdims=True)
    x_var = np.var(x, axis=(2, 3, 4), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta
    return results
```

## 5. Switchable Normalization

æœ¬ç¯‡è®ºæ–‡ä½œè€…è®¤ä¸ºï¼Œ

- ç¬¬ä¸€ï¼Œå½’ä¸€åŒ–è™½ç„¶æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼Œç„¶è€Œå½’ä¸€åŒ–å±‚çš„æ“ä½œæ˜¯äººå·¥è®¾è®¡çš„ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè§£å†³ä¸åŒçš„é—®é¢˜åŸåˆ™ä¸Šéœ€è¦è®¾è®¡ä¸åŒçš„å½’ä¸€åŒ–æ“ä½œï¼Œå¹¶æ²¡æœ‰ä¸€ä¸ªé€šç”¨çš„å½’ä¸€åŒ–æ–¹æ³•èƒ½å¤Ÿè§£å†³æ‰€æœ‰åº”ç”¨é—®é¢˜ï¼›
- ç¬¬äºŒï¼Œä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œå¾€å¾€åŒ…å«å‡ åä¸ªå½’ä¸€åŒ–å±‚ï¼Œé€šå¸¸è¿™äº›å½’ä¸€åŒ–å±‚éƒ½ä½¿ç”¨åŒæ ·çš„å½’ä¸€åŒ–æ“ä½œï¼Œå› ä¸ºæ‰‹å·¥ä¸ºæ¯ä¸€ä¸ªå½’ä¸€åŒ–å±‚è®¾è®¡æ“ä½œéœ€è¦è¿›è¡Œå¤§é‡çš„å®éªŒã€‚

å› æ­¤ä½œè€…æå‡ºè‡ªé€‚é…å½’ä¸€åŒ–æ–¹æ³•â€”â€”Switchable Normalizationï¼ˆSNï¼‰æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚ä¸å¼ºåŒ–å­¦ä¹ ä¸åŒï¼ŒSNä½¿ç”¨å¯å¾®åˆ†å­¦ä¹ ï¼Œä¸ºä¸€ä¸ªæ·±åº¦ç½‘ç»œä¸­çš„æ¯ä¸€ä¸ªå½’ä¸€åŒ–å±‚ç¡®å®šåˆé€‚çš„å½’ä¸€åŒ–æ“ä½œã€‚

![image-20201022101218514](imgs/image-20201022101218514.png)

```
def SwitchableNorm(x, gamma, beta, w_mean, w_var):
    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5

    mean_in = np.mean(x, axis=(2, 3), keepdims=True)
    var_in = np.var(x, axis=(2, 3), keepdims=True)

    mean_ln = np.mean(x, axis=(1, 2, 3), keepdims=True)
    var_ln = np.var(x, axis=(1, 2, 3), keepdims=True)

    mean_bn = np.mean(x, axis=(0, 2, 3), keepdims=True)
    var_bn = np.var(x, axis=(0, 2, 3), keepdims=True)

    mean = w_mean[0] * mean_in + w_mean[1] * mean_ln + w_mean[2] * mean_bn
    var = w_var[0] * var_in + w_var[1] * var_ln + w_var[2] * var_bn

    x_normalized = (x - mean) / np.sqrt(var + eps)
    results = gamma * x_normalized + beta
    return results
```

ç»“æœæ¯”è¾ƒ

![img](imgs/1433301-20191126171803696-808831184.png)

## 6.Pytorchå¸¸ç”¨normalizationå‡½æ•° 

### 1.BN

batchNormæ˜¯åœ¨batchä¸Šï¼Œå¯¹NHWåšå½’ä¸€åŒ–;å³æ˜¯å°†åŒä¸€ä¸ªbatchä¸­çš„æ‰€æœ‰æ ·æœ¬çš„åŒä¸€å±‚ç‰¹å¾å›¾æŠ½å‡ºæ¥ä¸€èµ·æ±‚meanå’Œvariance

åŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼Œå…è®¸ç½‘ç»œä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡ã€‚å¯ä½œä¸ºä¸€ä¸ªæ­£åˆ™åŒ–å™¨ï¼Œå‡å°‘å¯¹dropoutçš„éœ€æ±‚

ä½†æ˜¯å½“batch sizeè¾ƒå°æ—¶(å°äº16æ—¶)ï¼Œæ•ˆæœä¼šå˜å·®ï¼Œè¿™æ—¶ä½¿ç”¨group normå¯èƒ½å¾—åˆ°çš„æ•ˆæœä¼šæ›´å¥½

 

**class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)**

å¯¹å°æ‰¹é‡(mini-batch)3dæ•°æ®ç»„æˆçš„4dè¾“å…¥è¿›è¡Œæ‰¹æ ‡å‡†åŒ–(Batch Normalization)æ“ä½œ

![img](imgs/1446032-20190428104355372-782882130.png)

è¿›è¡Œäº†ä¸¤æ­¥æ“ä½œï¼šå¯è§Batch Normalizationçš„è§£é‡Š

- å…ˆå¯¹è¾“å…¥è¿›è¡Œå½’ä¸€åŒ–ï¼ŒE(x)ä¸ºè®¡ç®—çš„å‡å€¼ï¼ŒVar(x)ä¸ºè®¡ç®—çš„æ–¹å·®
- ç„¶åå¯¹å½’ä¸€åŒ–çš„ç»“æœè¿›è¡Œç¼©æ”¾å’Œå¹³ç§»ï¼Œè®¾ç½®affine=Trueï¼Œå³æ„å‘³ç€weight(Î³)å’Œbias(Î²)å°†è¢«ä½¿ç”¨

åœ¨æ¯ä¸€ä¸ªå°æ‰¹é‡ï¼ˆmini-batchï¼‰æ•°æ®ä¸­ï¼Œè®¡ç®—è¾“å…¥å„ä¸ªç»´åº¦çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚Î³ä¸Î²æ˜¯å¯å­¦ä¹ çš„å¤§å°ä¸ºCçš„å‚æ•°å‘é‡ï¼ˆCä¸ºè¾“å…¥å¤§å°)ã€‚é»˜è®¤Î³å–å€¼ä¸ºU(0,1)ï¼ŒÎ²è®¾ç½®ä¸º0

åŒæ ·ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œåœ¨è®­ç»ƒæœŸé—´ï¼Œè¯¥å±‚å°†è¿è¡Œå…¶è®¡ç®—çš„å¹³å‡å€¼å’Œæ–¹å·®çš„ä¼°è®¡å€¼ï¼Œç„¶ååœ¨éªŒè¯æœŸé—´ä½¿ç”¨è¿™äº›ä¼°è®¡å€¼ï¼ˆå³è®­ç»ƒæ±‚å¾—çš„å‡å€¼/æ–¹å·®ï¼‰è¿›è¡Œæ ‡å‡†åŒ–ã€‚è¿è¡Œä¼°è®¡(running statistics)æ—¶ä¿æŒé»˜è®¤momentumä¸º0.1ã€‚

å¦‚æœtrack_running_statsè¢«è®¾ç½®ä¸ºFalseï¼Œé‚£ä¹ˆè¿™ä¸ªå±‚å°±ä¸ä¼šç»§ç»­è¿è¡ŒéªŒè¯ï¼Œå¹¶ä¸”åœ¨éªŒè¯æœŸé—´ä¹Ÿä¼šä½¿ç”¨æ‰¹å¤„ç†ç»Ÿè®¡ä¿¡æ¯ã€‚

 

âš ï¸è¿™ä¸ªmomentumå‚æ•°ä¸åŒäºä¼˜åŒ–å™¨optimizerç±»ä¸­ä½¿ç”¨çš„momentumå‚æ•°å’Œmomentumçš„ä¼ ç»Ÿæ¦‚å¿µã€‚ä»æ•°å­¦ä¸Šè®²ï¼Œè¿™é‡Œè¿è¡Œç»Ÿè®¡æ•°æ®çš„æ›´æ–°è§„åˆ™æ˜¯ :

- xæ˜¯ä¼°è®¡çš„æ•°æ®
- xtæ˜¯æ–°çš„è§‚å¯Ÿåˆ°çš„æ•°æ®

xnew = (1-momentum) * x + momentum * xt

 

å› ä¸ºæ‰¹å¤„ç†è§„èŒƒåŒ–æ˜¯åœ¨Cç»´(channelé€šé“ç»´åº¦)ä¸Šå®Œæˆçš„ï¼Œè®¡ç®—(N,H,W)ç‰‡ä¸Šçš„ç»Ÿè®¡ä¿¡æ¯ï¼Œæ‰€ä»¥é€šå¸¸å°†å…¶ç§°ä¸ºç©ºé—´æ‰¹å¤„ç†è§„èŒƒåŒ–ã€‚

**å‚æ•°ï¼š**

- **num_featuresï¼š** Cæ¥è‡ªæœŸå¾…çš„è¾“å…¥å¤§å°(N,C,H,W)
- **epsï¼š** å³ä¸Šé¢å¼å­ä¸­åˆ†æ¯çš„Îµ ï¼Œä¸ºä¿è¯æ•°å€¼ç¨³å®šæ€§ï¼ˆåˆ†æ¯ä¸èƒ½è¶‹è¿‘æˆ–å–0ï¼‰,ç»™åˆ†æ¯åŠ ä¸Šçš„å€¼ã€‚é»˜è®¤ä¸º1e-5ã€‚
- **momentumï¼š** åŠ¨æ€å‡å€¼å’ŒåŠ¨æ€æ–¹å·®æ‰€ä½¿ç”¨çš„åŠ¨é‡ã€‚é»˜è®¤ä¸º0.1ã€‚
- **affineï¼š** ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå½“è®¾ä¸ºtrueï¼Œç»™è¯¥å±‚æ·»åŠ å¯å­¦ä¹ çš„ä»¿å°„å˜æ¢å‚æ•°ï¼Œå³Î³ä¸Î²ã€‚
- **track_running_stats**ï¼šä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå½“è®¾ç½®ä¸ºTrueæ—¶ï¼Œè¯¥æ¨¡å—è·Ÿè¸ªè¿è¡Œçš„å¹³å‡å€¼å’Œæ–¹å·®ï¼Œå½“è®¾ç½®ä¸ºFalseæ—¶ï¼Œè¯¥æ¨¡å—ä¸è·Ÿè¸ªæ­¤ç±»ç»Ÿè®¡æ•°æ®ï¼Œå¹¶ä¸”å§‹ç»ˆåœ¨trainå’Œevalæ¨¡å¼ä¸­ä½¿ç”¨æ‰¹å¤„ç†ç»Ÿè®¡æ•°æ®ã€‚é»˜è®¤å€¼:True

**Shapeï¼š** 

è¾“å…¥ï¼šï¼ˆN, Cï¼ŒH, W) 

è¾“å‡ºï¼šï¼ˆN, C, H, Wï¼‰ï¼ˆè¾“å…¥è¾“å‡ºç›¸åŒï¼‰

 

ä¸¾ä¾‹ï¼š

å½“affine=Trueæ—¶

```
import torch
from torch import nn

m = nn.BatchNorm2d(2,affine=True)
print(m.weight)
print(m.bias)

input = torch.randn(1,2,3,4)
print(input)
output = m(input)
print(output)
print(output.size())
```

è¿”å›ï¼š

```
Parameter containing:
tensor([0.5247, 0.4397], requires_grad=True)
Parameter containing:
tensor([0., 0.], requires_grad=True)
tensor([[[[ 0.8316, -1.6250,  0.9072,  0.2746],
          [ 0.4579, -0.2228,  0.4685,  1.2020],
          [ 0.8648, -1.2116,  1.0224,  0.7295]],

         [[ 0.4387, -0.8889, -0.8999, -0.2775],
          [ 2.4837, -0.4111, -0.6032, -2.3912],
          [ 0.5622, -0.0770, -0.0107, -0.6245]]]])
tensor([[[[ 0.3205, -1.1840,  0.3668, -0.0206],
          [ 0.0916, -0.3252,  0.0982,  0.5474],
          [ 0.3409, -0.9308,  0.4373,  0.2580]],

         [[ 0.2664, -0.2666, -0.2710, -0.0211],
          [ 1.0874, -0.0747, -0.1518, -0.8697],
          [ 0.3160,  0.0594,  0.0860, -0.1604]]]],
       grad_fn=<NativeBatchNormBackward>)
torch.Size([1, 2, 3, 4])
```



å½“affine=Falseæ—¶

```
import torch
from torch import nn

m = nn.BatchNorm2d(2,affine=False)
print(m.weight)
print(m.bias)

input = torch.randn(1,2,3,4)
print(input)
output = m(input)
print(output)
print(output.size())
```

è¿”å›ï¼š

```
None
None
tensor([[[[-1.5365,  0.2642,  1.0482,  2.0938],
          [-0.0906,  1.8446,  0.7762,  1.2987],
          [-2.4138, -0.5368, -1.2173,  0.2574]],

         [[ 0.2518, -1.9633, -0.0487, -0.0317],
          [-0.9511,  0.2488,  0.3887,  1.4182],
          [-0.1422,  0.4096,  1.4740,  0.5241]]]])
tensor([[[[-1.2739,  0.0870,  0.6795,  1.4698],
          [-0.1811,  1.2814,  0.4740,  0.8689],
          [-1.9368, -0.5183, -1.0326,  0.0819]],

         [[ 0.1353, -2.3571, -0.2028, -0.1837],
          [-1.2182,  0.1320,  0.2894,  1.4478],
          [-0.3080,  0.3129,  1.5106,  0.4417]]]])
torch.Size([1, 2, 3, 4])
```

 

###  2.InstanceNorm2dï¼ˆå½“mini-batchæ—¶ä½¿ç”¨ï¼‰

instanceNormåœ¨å›¾åƒåƒç´ ä¸Šï¼Œå¯¹HWåšå½’ä¸€åŒ–ï¼›å³æ˜¯å¯¹batchä¸­çš„å•ä¸ªæ ·æœ¬çš„æ¯ä¸€å±‚ç‰¹å¾å›¾æŠ½å‡ºæ¥ä¸€å±‚å±‚æ±‚meanå’Œvarianceï¼Œä¸batch sizeæ— å…³ã€‚è‹¥ç‰¹å¾å±‚ä¸º1ï¼Œå³C=1ï¼Œå‡†åˆ™instance normçš„å€¼ä¸ºè¾“å…¥æœ¬èº«

```
CLASS torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
```

åœ¨4Dè¾“å…¥ä¸Šåº”ç”¨instance Normalization(å¸¦æœ‰é¢å¤–channelç»´åº¦çš„mini-batch 2Dè¾“å…¥),å³shapeä¸º[N,C,H,W]

![img](imgs/1446032-20190516184605609-1686955189.png)

åœ¨mini-batchä¸­çš„å¯¹è±¡çš„å‡å€¼å’Œæ ‡å‡†å·®æ˜¯æ¯ä¸ªç»´åº¦åˆ†å¼€è®¡ç®—çš„ã€‚å¦‚æœaffine=True,åˆ™Î³å’ŒÎ²è¿™ä¸¤ä¸ªå¯å­¦ä¹ çš„å‚æ•°å‘é‡ï¼Œå¤§å°ä¸ºCï¼ŒCä¸ºè¾“å…¥å¤§å°ã€‚

è¿™ä¸€å±‚ä½¿ç”¨ä»è®­ç»ƒå’Œè¯„ä¼°æ¨¡å¼çš„è¾“å…¥æ•°æ®è®¡ç®—å¾—åˆ°çš„instaceæ•°æ®ã€‚

 

å¦‚æœtrack_running_statsè¢«è®¾ç½®ä¸ºTrueï¼Œé‚£ä¹ˆåœ¨è®­ç»ƒæœŸé—´ï¼Œè¯¥å±‚å°†ç»§ç»­è¿è¡Œè®¡ç®—å‡å€¼å’Œæ–¹å·®çš„ä¼°è®¡ï¼Œå¾—åˆ°çš„å‡å€¼å’Œæ–¹å·®å°†ä½¿ç”¨åˆ°è¯„ä¼°(eval)æ—¶çš„normalizationä¸­ã€‚è¿è¡Œä¼°è®¡æ—¶ä¿æŒé»˜è®¤momentumä¸º0.1ã€‚

 

âš ï¸è¿™ä¸ªmomentumå‚æ•°ä¸åŒäºä¼˜åŒ–å™¨optimizerç±»ä¸­ä½¿ç”¨çš„momentumå‚æ•°å’Œmomentumçš„ä¼ ç»Ÿæ¦‚å¿µã€‚ä»æ•°å­¦ä¸Šè®²ï¼Œè¿™é‡Œè¿è¡Œç»Ÿè®¡æ•°æ®çš„æ›´æ–°è§„åˆ™æ˜¯ :

- xæ˜¯ä¼°è®¡çš„æ•°æ®
- xtæ˜¯æ–°çš„è§‚å¯Ÿåˆ°çš„æ•°æ®

xnew = (1-momentum) * x + momentum * xt

 

âš ï¸

InstanceNorm2då’ŒLayerNorméå¸¸ç›¸ä¼¼ï¼Œä½†æ˜¯æœ‰ä¸€äº›ç»†å¾®çš„å·®åˆ«ã€‚InstanceNorm2dåº”ç”¨äºRGBå›¾åƒç­‰ä¿¡é“æ•°æ®çš„æ¯ä¸ªä¿¡é“ï¼Œè€ŒLayerNormé€šå¸¸åº”ç”¨äºæ•´ä¸ªæ ·æœ¬ï¼Œå¹¶ä¸”é€šå¸¸ç”¨äºNLPä»»åŠ¡ã€‚æ­¤å¤–ï¼ŒLayerNormåº”ç”¨å…ƒç´ ä»¿å°„å˜æ¢ï¼Œè€ŒInstanceNorm2dé€šå¸¸ä¸åº”ç”¨ä»¿å°„å˜æ¢ã€‚

**å‚æ•°ï¼š**

- **num_featuresï¼š** Cæ¥è‡ªæœŸå¾…çš„è¾“å…¥å¤§å°(N,C,H,W)
- **epsï¼š** å³ä¸Šé¢å¼å­ä¸­åˆ†æ¯çš„Îµ ï¼Œä¸ºä¿è¯æ•°å€¼ç¨³å®šæ€§ï¼ˆåˆ†æ¯ä¸èƒ½è¶‹è¿‘æˆ–å–0ï¼‰,ç»™åˆ†æ¯åŠ ä¸Šçš„å€¼ã€‚é»˜è®¤ä¸º1e-5ã€‚
- **momentumï¼š** åŠ¨æ€å‡å€¼å’ŒåŠ¨æ€æ–¹å·®æ‰€ä½¿ç”¨çš„åŠ¨é‡ã€‚é»˜è®¤ä¸º0.1ã€‚
- **affineï¼š** ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå½“è®¾ä¸ºtrueï¼Œç»™è¯¥å±‚æ·»åŠ å¯å­¦ä¹ çš„ä»¿å°„å˜æ¢å‚æ•°ï¼Œå³Î³ä¸Î²ã€‚
- **track_running_stats**ï¼šä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå½“è®¾ç½®ä¸ºTrueæ—¶ï¼Œè¯¥æ¨¡å—è·Ÿè¸ªè¿è¡Œçš„å¹³å‡å€¼å’Œæ–¹å·®ï¼Œå½“è®¾ç½®ä¸ºFalseæ—¶ï¼Œè¯¥æ¨¡å—ä¸è·Ÿè¸ªæ­¤ç±»ç»Ÿè®¡æ•°æ®ï¼Œå¹¶ä¸”å§‹ç»ˆåœ¨trainå’Œevalæ¨¡å¼ä¸­ä½¿ç”¨æ‰¹å¤„ç†ç»Ÿè®¡æ•°æ®ã€‚é»˜è®¤å€¼:False

**Shapeï¼š** 

è¾“å…¥ï¼šï¼ˆN, Cï¼ŒH, W) 

è¾“å‡ºï¼šï¼ˆN, C, H, Wï¼‰ï¼ˆè¾“å…¥è¾“å‡ºç›¸åŒï¼‰

 

ä¸¾ä¾‹ï¼š

```
import torch
input = torch.randn(2,3,2,2)
input
```

è¿”å›ï¼š

```
tensor([[[[-0.9262,  0.1619],
          [ 2.3522,  1.2739]],

         [[-2.1725,  1.3967],
          [ 1.4407,  1.3133]],

         [[-0.8386, -1.1728],
          [-3.0443, -0.3651]]],


        [[[ 0.9468, -0.9257],
          [ 0.5376,  0.4858]],

         [[ 1.1766,  0.4704],
          [ 0.8294, -0.3892]],

         [[ 0.2836,  0.5864],
          [-0.3070,  0.3229]]]])
```



```
import torch.nn as nn
#å£°æ˜ä»¿å°„å˜æ¢è¦å†™æˆ
#m = nn.InstanceNorm2d(3, affine=True)
m = nn.InstanceNorm2d(3)#featureæ•°é‡ï¼Œå³channel number = 3
output = m(input)
output
```

è¿”å›ï¼š

```
tensor([[[[-1.3413, -0.4523],
          [ 1.3373,  0.4563]],

         [[-1.7313,  0.5856],
          [ 0.6141,  0.5315]],

         [[ 0.5082,  0.1794],
          [-1.6616,  0.9740]]],


        [[[ 0.9683, -1.6761],
          [ 0.3904,  0.3173]],

         [[ 1.1246, -0.0883],
          [ 0.5283, -1.5646]],

         [[ 0.1903,  1.1173],
          [-1.6182,  0.3106]]]])
```



### 3.LayerNormï¼ˆå½“mini-batchæ—¶ä½¿ç”¨ï¼‰

layerNormåœ¨é€šé“æ–¹å‘ä¸Šï¼Œå¯¹CHWå½’ä¸€åŒ–ï¼›å³æ˜¯å°†batchä¸­çš„å•ä¸ªæ ·æœ¬çš„æ¯ä¸€å±‚ç‰¹å¾å›¾æŠ½å‡ºæ¥ä¸€èµ·æ±‚ä¸€ä¸ªmeanå’Œvarianceï¼Œä¸batch sizeæ— å…³ï¼Œä¸åŒé€šé“æœ‰ç€ç›¸åŒçš„å‡å€¼å’Œæ–¹å·®

```
CLASS torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True)
```

å¹³å‡å€¼å’Œæ ‡å‡†åå·®åˆ†åˆ«è®¡ç®—åœ¨æœ€åå‡ ä¸ªç»´æ•°ä¸Šï¼Œè¿™äº›ç»´æ•°å¿…é¡»æ˜¯normalized_shapeæŒ‡å®šçš„å½¢çŠ¶ã€‚å¦‚æœelementwise_affine=True,åˆ™Î³å’ŒÎ²ä¸ºä¸¤ä¸ªå¯å­¦ä¹ çš„ä»¿å°„å˜æ¢å‚æ•°å‘é‡ï¼Œå¤§å°ä¸ºnormalized_shape

âš ï¸ä¸batch normalizationå’Œinstance normalizationä¸åŒï¼Œbatch normalizationä½¿ç”¨affineé€‰é¡¹ä¸ºæ¯ä¸ªé€šé“/å¹³é¢åº”ç”¨æ ‡é‡å°ºåº¦Î³å’Œåå·®Î²ï¼Œè€Œlayer normalizationä½¿ç”¨elementwise_affineå‚æ•°ä¸ºæ¯ä¸ªå…ƒç´ åº”ç”¨å°ºåº¦å’Œåå·®ã€‚

 

è¿™ä¸€å±‚ä½¿ç”¨ä»è®­ç»ƒå’Œè¯„ä¼°æ¨¡å¼çš„è¾“å…¥æ•°æ®è®¡ç®—å¾—åˆ°çš„ç»Ÿè®¡æ•°æ®ã€‚

**å‚æ•°ï¼š**

- **normalized_shape** ([*int*](https://docs.python.org/3/library/functions.html#int) *or* [*list*](https://docs.python.org/3/library/stdtypes.html#list) *or* *torch.Size*)ï¼š

  æ¥è‡ªæœŸå¾…è¾“å…¥å¤§å°çš„è¾“å…¥å½¢çŠ¶![img](imgs/1446032-20190516195723628-1662461555.png)

  å¦‚æœä½¿ç”¨å•ä¸ªæ•´æ•°ï¼Œåˆ™å°†å…¶è§†ä¸ºä¸€ä¸ªå•ä¾‹åˆ—è¡¨ï¼Œå¹¶ä¸”æ­¤æ¨¡å—å°†åœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šè¿›è¡Œè§„èŒƒåŒ–ï¼Œè€Œæœ€åä¸€ä¸ªç»´åº¦åº”è¯¥å…·æœ‰ç‰¹å®šçš„å¤§å°ã€‚

- **epsï¼š** å³ä¸Šé¢å¼å­ä¸­åˆ†æ¯çš„Îµ ï¼Œä¸ºä¿è¯æ•°å€¼ç¨³å®šæ€§ï¼ˆåˆ†æ¯ä¸èƒ½è¶‹è¿‘æˆ–å–0ï¼‰,ç»™åˆ†æ¯åŠ ä¸Šçš„å€¼ã€‚é»˜è®¤ä¸º1e-5ã€‚

- ***\*elementwise_affine\**ï¼š** ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå½“è®¾ç½®ä¸ºTrueæ—¶ï¼Œæ­¤æ¨¡å—å…·æœ‰å¯å­¦ä¹ çš„å…ƒç´ ä»¿å°„å‚æ•°ï¼ŒÎ³åˆå§‹åŒ–ä¸º1(è¡¨ç¤ºæƒé‡)å’ŒÎ²åˆå§‹åŒ–ä¸º0(è¡¨ç¤ºåå·®)ã€‚é»˜è®¤å€¼:Trueã€‚

**Shapeï¼š** 

è¾“å…¥ï¼šï¼ˆN, *)

è¾“å‡ºï¼šï¼ˆN, *ï¼‰ï¼ˆè¾“å…¥è¾“å‡ºç›¸åŒï¼‰

 

ä¸¾ä¾‹ï¼š

```
import torch
input = torch.randn(2,3,2,2)
input
```

è¿”å›ï¼š

```
tensor([[[[-0.9262,  0.1619],
          [ 2.3522,  1.2739]],

         [[-2.1725,  1.3967],
          [ 1.4407,  1.3133]],

         [[-0.8386, -1.1728],
          [-3.0443, -0.3651]]],


        [[[ 0.9468, -0.9257],
          [ 0.5376,  0.4858]],

         [[ 1.1766,  0.4704],
          [ 0.8294, -0.3892]],

         [[ 0.2836,  0.5864],
          [-0.3070,  0.3229]]]])
```

 

```
import torch.nn as nn
#å–æ¶ˆä»¿å°„å˜æ¢è¦å†™æˆ
#m = nn.LayerNorm(input.size()[1:], elementwise_affine=False)
m1 = nn.LayerNorm(input.size()[1:])#input.size()[1:]ä¸ºtorch.Size([3, 2, 2])
output1 = m1(input)
output1
```

è¿”å›ï¼š

```
tensor([[[[-0.5555,  0.1331],
          [ 1.5192,  0.8368]],

         [[-1.3442,  0.9146],
          [ 0.9423,  0.8618]],

         [[-0.5001, -0.7116],
          [-1.8959, -0.2004]]],


        [[[ 1.0599, -2.1829],
          [ 0.3512,  0.2616]],

         [[ 1.4578,  0.2348],
          [ 0.8565, -1.2537]],

         [[-0.0887,  0.4357],
          [-1.1115, -0.0206]]]], grad_fn=<AddcmulBackward>)
```

 

```
#åªnormalizeåä¸¤ä¸ªç»´åº¦
m2 = nn.LayerNorm([2,2])
output2 = m2(input)
output2
```

è¿”å›ï¼š

```
tensor([[[[-1.3413, -0.4523],
          [ 1.3373,  0.4563]],

         [[-1.7313,  0.5856],
          [ 0.6141,  0.5315]],

         [[ 0.5082,  0.1794],
          [-1.6616,  0.9740]]],


        [[[ 0.9683, -1.6761],
          [ 0.3904,  0.3173]],

         [[ 1.1246, -0.0883],
          [ 0.5283, -1.5646]],

         [[ 0.1903,  1.1173],
          [-1.6182,  0.3106]]]], grad_fn=<AddcmulBackward>)
```

 

```
#åªnormalizeæœ€åä¸€ä¸ªç»´åº¦
m3 = nn.LayerNorm(2)
output3 = m3(input)
output3
```

è¿”å›ï¼š

```
tensor([[[[-1.0000,  1.0000],
          [ 1.0000, -1.0000]],

         [[-1.0000,  1.0000],
          [ 0.9988, -0.9988]],

         [[ 0.9998, -0.9998],
          [-1.0000,  1.0000]]],


        [[[ 1.0000, -1.0000],
          [ 0.9926, -0.9926]],

         [[ 1.0000, -1.0000],
          [ 1.0000, -1.0000]],

         [[-0.9998,  0.9998],
          [-0.9999,  0.9999]]]], grad_fn=<AddcmulBackward>)
```



### 4.GroupNormï¼ˆå½“mini-batchæ—¶ä½¿ç”¨ï¼‰

GroupNormå°†channelåˆ†ç»„ï¼›å³æ˜¯å°†batchä¸­çš„å•ä¸ªæ ·æœ¬çš„Gå±‚ç‰¹å¾å›¾æŠ½å‡ºæ¥ä¸€èµ·æ±‚meanå’Œvarianceï¼Œä¸batch sizeæ— å…³

å½“batch sizeè¾ƒå°æ—¶(å°äº16æ—¶)ï¼Œä½¿ç”¨è¯¥normalizationæ–¹æ³•æ•ˆæœæ›´å¥½

```
CLASS torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True)
```

![img](imgs/asdf.png)

è¾“å…¥é€šé“è¢«åˆ†æˆnum_groupsç»„ï¼Œæ¯ä¸ªç»„åŒ…å«num_channels / num_groupsä¸ªé€šé“ã€‚æ¯ç»„çš„å‡å€¼å’Œæ ‡å‡†å·®åˆ†å¼€è®¡ç®—ã€‚å¦‚æœaffine=True,åˆ™Î³å’ŒÎ²è¿™ä¸¤ä¸ªå¯å­¦ä¹ çš„é€šé“ä»¿å°„å˜æ¢å‚æ•°å‘é‡çš„å¤§å°ä¸ºnum_channelsã€‚

è¿™ä¸€å±‚ä½¿ç”¨ä»è®­ç»ƒå’Œè¯„ä¼°æ¨¡å¼çš„è¾“å…¥æ•°æ®è®¡ç®—å¾—åˆ°çš„ç»Ÿè®¡æ•°æ®ã€‚

 

**å‚æ•°ï¼š**

- **num_features(int)ï¼š** å°†é€šé“åˆ†æˆçš„ç»„çš„æ•°é‡
- **num_channels(int)ï¼šè¾“å…¥æœŸå¾…çš„é€šé“æ•°**
- **epsï¼š** å³ä¸Šé¢å¼å­ä¸­åˆ†æ¯çš„Îµ ï¼Œä¸ºä¿è¯æ•°å€¼ç¨³å®šæ€§ï¼ˆåˆ†æ¯ä¸èƒ½è¶‹è¿‘æˆ–å–0ï¼‰,ç»™åˆ†æ¯åŠ ä¸Šçš„å€¼ã€‚é»˜è®¤ä¸º1e-5ã€‚
- **affineï¼š** ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå½“è®¾ä¸ºtrueï¼Œç»™è¯¥å±‚æ·»åŠ å¯å­¦ä¹ çš„ä»¿å°„å˜æ¢å‚æ•°ï¼Œå³Î³ä¸Î²ã€‚

**Shapeï¼š** 

è¾“å…¥ï¼šï¼ˆN, Cï¼Œ*) ï¼ŒC = ***\*num_channels\****

è¾“å‡ºï¼šï¼ˆN, C, *ï¼‰ï¼ˆè¾“å…¥è¾“å‡ºç›¸åŒï¼‰

 

 ä¸¾ä¾‹ï¼š

```
import torch
input = torch.randn(2,4,3,3)
input
```

è¿”å›ï¼š

```
tensor([[[[-0.9154,  0.7312,  1.0657],
          [ 0.1783,  1.4014,  1.3043],
          [-0.7661, -0.6346,  0.7620]],

         [[ 0.9533,  2.1763,  0.4636],
          [ 0.0624, -0.0880,  1.2591],
          [ 0.5080,  0.2156,  0.0312]],

         [[ 0.2077, -0.2373,  0.2203],
          [-0.0628, -0.4680, -0.0094],
          [ 0.8615,  0.8549,  0.4138]],

         [[ 1.2188, -0.6487,  1.9315],
          [-1.0211, -0.1721,  0.6426],
          [-0.8192,  1.1049,  0.3663]]],


        [[[ 1.7522, -0.5378, -0.6105],
          [ 0.0658, -0.5731,  0.8737],
          [-0.2006,  0.3185,  0.6959]],

         [[ 0.5581, -1.5815,  0.3467],
          [-1.7975,  1.1900, -0.0935],
          [-0.7640, -0.7520, -1.2672]],

         [[-0.3703,  1.8731, -0.4689],
          [ 0.3615,  1.7101,  0.7305],
          [-0.0244, -0.5019,  0.3259]],

         [[-0.1413, -0.7416, -0.0747],
          [-0.6557,  0.5025, -0.0574],
          [ 0.2727,  2.2837,  1.6237]]]])
```



 

```
import torch.nn as nn
#å°†4ä¸ªé€šé“åˆ†ä¸º2ç»„
m1 = nn.GroupNorm(2,4)
output1 = m1(input)
output1
```

è¿”å›ï¼š

```
tensor([[[[-1.7640,  0.3119,  0.7336],
          [-0.3852,  1.1568,  1.0344],
          [-1.5757, -1.4099,  0.3508]],

         [[ 0.5919,  2.1338, -0.0254],
          [-0.5312, -0.7208,  0.9774],
          [ 0.0305, -0.3381, -0.5706]],

         [[-0.0478, -0.6420, -0.0310],
          [-0.4090, -0.9500, -0.3377],
          [ 0.8251,  0.8163,  0.2273]],

         [[ 1.3022, -1.1914,  2.2539],
          [-1.6886, -0.5550,  0.5328],
          [-1.4190,  1.1501,  0.1639]]],


        [[[ 2.0315, -0.4375, -0.5158],
          [ 0.2133, -0.4755,  1.0844],
          [-0.0739,  0.4858,  0.8927]],

         [[ 0.7441, -1.5628,  0.5162],
          [-1.7956,  1.4254,  0.0415],
          [-0.6814, -0.6685, -1.2239]],

         [[-0.8227,  1.6729, -0.9325],
          [-0.0087,  1.4915,  0.4018],
          [-0.4380, -0.9692, -0.0482]],

         [[-0.5680, -1.2358, -0.4939],
          [-1.1402,  0.1482, -0.4747],
          [-0.1075,  2.1296,  1.3954]]]], grad_fn=<AddcmulBackward>)
```



 

```
#å°†4ä¸ªé€šé“åˆ†ä¸º4ç»„,ç­‰ä»·äºInstance Norm
m2 = nn.GroupNorm(4,4)
output2 = m2(input)
output2
```

è¿”å›ï¼š

```
tensor([[[[-1.4648,  0.4451,  0.8332],
          [-0.1962,  1.2226,  1.1099],
          [-1.2916, -1.1390,  0.4809]],

         [[ 0.4819,  2.2510, -0.2265],
          [-0.8068, -1.0243,  0.9242],
          [-0.1623, -0.5852, -0.8520]],

         [[ 0.0230, -1.0124,  0.0523],
          [-0.6064, -1.5490, -0.4821],
          [ 1.5439,  1.5284,  0.5023]],

         [[ 0.9624, -0.9711,  1.7004],
          [-1.3567, -0.4777,  0.3659],
          [-1.1476,  0.8445,  0.0798]]],


        [[[ 2.0642, -0.9777, -1.0742],
          [-0.1760, -1.0246,  0.8973],
          [-0.5298,  0.1598,  0.6611]],

         [[ 1.0550, -1.1571,  0.8364],
          [-1.3803,  1.7083,  0.3813],
          [-0.3119, -0.2995, -0.8321]],

         [[-0.9221,  1.7498, -1.0396],
          [-0.0506,  1.5556,  0.3889],
          [-0.5102, -1.0789, -0.0929]],

         [[-0.4993, -1.1290, -0.4294],
          [-1.0388,  0.1761, -0.4113],
          [-0.0650,  2.0445,  1.3521]]]], grad_fn=<AddcmulBackward>)
```



 

```
#å°†4ä¸ªé€šé“åˆ†ä¸º4ç»„,ç­‰ä»·äºlayer Norm
m3 = nn.GroupNorm(4,4)
output3 = m3(input)
output3
```

è¿”å›ï¼š

```
tensor([[[[-1.4648,  0.4451,  0.8332],
          [-0.1962,  1.2226,  1.1099],
          [-1.2916, -1.1390,  0.4809]],

         [[ 0.4819,  2.2510, -0.2265],
          [-0.8068, -1.0243,  0.9242],
          [-0.1623, -0.5852, -0.8520]],

         [[ 0.0230, -1.0124,  0.0523],
          [-0.6064, -1.5490, -0.4821],
          [ 1.5439,  1.5284,  0.5023]],

         [[ 0.9624, -0.9711,  1.7004],
          [-1.3567, -0.4777,  0.3659],
          [-1.1476,  0.8445,  0.0798]]],


        [[[ 2.0642, -0.9777, -1.0742],
          [-0.1760, -1.0246,  0.8973],
          [-0.5298,  0.1598,  0.6611]],

         [[ 1.0550, -1.1571,  0.8364],
          [-1.3803,  1.7083,  0.3813],
          [-0.3119, -0.2995, -0.8321]],

         [[-0.9221,  1.7498, -1.0396],
          [-0.0506,  1.5556,  0.3889],
          [-0.5102, -1.0789, -0.0929]],

         [[-0.4993, -1.1290, -0.4294],
          [-1.0388,  0.1761, -0.4113],
          [-0.0650,  2.0445,  1.3521]]]], grad_fn=<AddcmulBackward>)
```

 

pix2pixä»£ç ä¸­è¯¥éƒ¨åˆ†çš„ä½¿ç”¨ï¼š

```
class Identity(nn.Module):
    def forward(self, x):
        return x


def get_norm_layer(norm_type='instance'):
    """è¿”å›æ ‡å‡†åŒ–å±‚

    Parameters:
        norm_type (str) -- æ ‡å‡†åŒ–å±‚çš„åå­—ï¼Œæœ‰: batch | instance | none

    å¯¹äºBatchNormï¼Œæˆ‘ä»¬ä½¿ç”¨å¯å­¦ä¹ çš„ä»¿å°„å‚æ•°å¹¶è¿½è¸ªè¿è¡Œæ•°æ®(mean/stddev)
    å¯¹äºInstanceNormï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨å¯å­¦ä¹ çš„ä»¿å°„å‚æ•°ä¹Ÿä¸è¿½è¸ªè¿è¡Œæ•°æ®
    """
    if norm_type == 'batch':
        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)
    elif norm_type == 'instance':
        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)
    elif norm_type == 'none':
        norm_layer = lambda x: Identity()
    else:
        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)
    return norm_layer
```



 